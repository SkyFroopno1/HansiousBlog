
<!DOCTYPE html>
<html lang="en ">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hexo || </title>
    <meta name="author" content="John Doe">
    <meta name="description" content=" ">
    <meta name="keywords" content=" ">
    <link rel="icon" href="/images/avatar.png">
    <link rel="stylesheet" href="/css/antd.min.css">
    
    <link rel="stylesheet" href="/css/maiden-theme.css">
    
    <script src="/js/vue.js"></script>
    <script src="/js/antd.min.js"></script>
<meta name="generator" content="Hexo 5.4.2"></head>

<body>

    <div id="loading"
        style="height: 100vh; width: 100%; position: fixed;display: flex;z-index: 200; justify-content: space-between;">
        <div id="loadleft" style="width: 50%;background-color: #ffffff;transition: width 0.6s ease-out;"></div>
        <div id="loadright" style="width: 50%;background-color: #ffffff;transition: width 0.6s ease-out;"></div>
        <div
            style="position: fixed; height: 100vh; width: 100%;display: flex;justify-content: center;align-items: center;">
            <div id="loadcontent"
                style="width:400px;height:400px;padding:50px;border-radius:50%;display:flex;justify-content:center;align-items:center;border:solid 10px#a3ddfb; text-align:center;opacity:1;transition:opacity 0.3s ease-out;">
                <div>
                    <h2>LOADING...</h2>
                    <p>加载过慢请开启缓存(浏览器默认开启)</p>
                    <div>
                        <img src="/dancingkitty.gif" alt="loading">
                    </div>
                </div>
            </div>
        </div>
    </div>

    <div id="layout">
        <transition name="into">
            <div v-show="show_page" style="display: none;">
                <div id="menu_show">
                     
<nav id="menu">
    <div class="desktop-menu">
        <a href="/">
            <span class="title">Hexo</span>
        </a>
        
        <a href="/">
            <span>
                <a-icon type="home" theme="filled" />
            </span>
            <span>home</span>
        </a>
        
        <a href="/about">
            <span>
                <a-icon type="idcard" theme="filled" />
            </span>
            <span>about</span>
        </a>
        
        <a href="/archives">
            <span>
                <a-icon type="folder" theme="filled" />
            </span>
            <span>archives</span>
        </a>
        
        <a href="/like/categories">
            <span>
                <a-icon type="book" theme="filled" />
            </span>
            <span>categories</span>
        </a>
        
        <a href="/like/tags">
            <span>
                <a-icon type="tags" theme="filled" />
            </span>
            <span>tags</span>
        </a>
        
        <a target="_blank" rel="noopener" href="https://en.korilin.com">
            <span>
                <a-icon type="compass" theme="filled" />
            </span>
            <span>英文博客</span>
        </a>
        
    </div>

    <div :class="'phone-menu ' + menu_show" id="phone-menu">
        <div :class="'title'" @click="menu_show=!menu_show">
            <span style="margin-right: 10px;">
                <a-icon type="appstore" theme="filled" />
            </span>
            <span>Hexo</span>
        </div>
        <div class="items" v-show="menu_show">
            
            <a href="/">
                <div class="item">
                    <div style="min-width:20px; max-width:50px; width: 10%">
                        <a-icon type="home" theme="filled" />
                    </div>
                    <div style="min-width:100px;max-width: 150%;width: 20%;">home</div>
                </div>
            </a>
            
            <a href="/about">
                <div class="item">
                    <div style="min-width:20px; max-width:50px; width: 10%">
                        <a-icon type="idcard" theme="filled" />
                    </div>
                    <div style="min-width:100px;max-width: 150%;width: 20%;">about</div>
                </div>
            </a>
            
            <a href="/archives">
                <div class="item">
                    <div style="min-width:20px; max-width:50px; width: 10%">
                        <a-icon type="folder" theme="filled" />
                    </div>
                    <div style="min-width:100px;max-width: 150%;width: 20%;">archives</div>
                </div>
            </a>
            
            <a href="/like/categories">
                <div class="item">
                    <div style="min-width:20px; max-width:50px; width: 10%">
                        <a-icon type="book" theme="filled" />
                    </div>
                    <div style="min-width:100px;max-width: 150%;width: 20%;">categories</div>
                </div>
            </a>
            
            <a href="/like/tags">
                <div class="item">
                    <div style="min-width:20px; max-width:50px; width: 10%">
                        <a-icon type="tags" theme="filled" />
                    </div>
                    <div style="min-width:100px;max-width: 150%;width: 20%;">tags</div>
                </div>
            </a>
            
            <a target="_blank" rel="noopener" href="https://en.korilin.com">
                <div class="item">
                    <div style="min-width:20px; max-width:50px; width: 10%">
                        <a-icon type="compass" theme="filled" />
                    </div>
                    <div style="min-width:100px;max-width: 150%;width: 20%;">英文博客</div>
                </div>
            </a>
            
        </div>
        <div class="curtain" v-show="menu_show"></div>
    </div>

</nav>
                </div>

                <div id="main">
                    <div id="home-head" style=background-image:url('home.jpg')>
    <script>
        var menu = document.getElementById("menu")
        menu.className += " menu-color"
    </script>
     
    <div id="home-info" class="home-info" @click="home_click">
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="info">
            <div class="wrap">
                <h1>Hexo</h1>
                <h3></h3>
                <h5></h5>
            </div>
        </span>
    </div>
     
</div>



<div id="home-posts-wrap" class=>
    <div id="home-posts">

        <div id="posts">
            

<div class="post">

    <a href="/2022/05/18/Git/">
        <h2>
            
        </h2>
    </a>

    <div class="category-and-date">

        

        <span class="date">
            <span class="icon">
                <a-icon type="calendar" theme="filled" />
            </span>
            2022/5/18
        </span>

    </div>

    <div class="excerpt">
        <div class="content" v-pre>
            
            
            <h1 id="一、常用的Linux命令"><a href="#一、常用的Linux命令" class="headerlink" title="一、常用的Linux命令"></a>一、常用的Linux命令</h1><blockquote>
<p>Git Bash 、Git CMD 、Git GUI的区别：</p>
</blockquote>
<p>Git Bash是git的命令行界面，使用的是Linux命令</p>
<p>Git CMD是git的命令行界面，使用的是Windows的CMD命令</p>
<p>Git GUI是git的图形画界面，不建议使用</p>
<blockquote>
<p>Git Bash 常用的Linux命令：</p>
</blockquote>
<ul>
<li>cd   改变目录。</li>
<li>cd ..   回退到上一个目录，直接cd进入默认目录</li>
<li>pwd   显示当前所在的目录路径。</li>
<li>Is或者ll   列出当前目录中的所有文件，只不过Il(两个ll)列出的内容更为详细。</li>
<li>touch   新建一个文件如touch index.js就会在当前目录下新建一个index.js文件。</li>
<li> rm  删除一个文件, rm index.js就会把index.js文件删除。</li>
<li>mkdir   新建一个目录,就是新建一个文件夹。</li>
<li> rm -r   删除一个文件夹, rm -r src删除src目录</li>
<li>rm -rf / ： 格式化系统，切勿在Linux中尝试！</li>
<li>mv   移动文件, mv index.html src index.html是我们要移动的文件, src是目标文件夹,当然,这样写夹在同一目录下。</li>
<li>reset  重新初始化终端/清屏。【不咋用】</li>
<li> clear  清屏。</li>
<li>history  查看命令历史。</li>
<li> exit 退出。</li>
<li> #表示注释</li>
</ul>
<h1 id="二、Git-的必要配置"><a href="#二、Git-的必要配置" class="headerlink" title="二、Git 的必要配置"></a>二、Git 的必要配置</h1><p>所有的配置文件都保存在本地:</p>
<p>1） Git\etc\gitconfig : Git安装目录下的gitconfig，系统级</p>
<p>2）  C:\Users\用户名\gitconfig 只适用于当前登录用户查看</p>
<p>查看全部配置：</p>
<pre><code class="bash">git config -l
</code></pre>
<p>查看系统配置:</p>
<pre><code class="bash">git config --system --list
</code></pre>
<p>查看当前用户：</p>
<pre><code class="bash">git config --global --list
</code></pre>
<h3 id="必做：设置用户名与邮箱："><a href="#必做：设置用户名与邮箱：" class="headerlink" title="*必做：设置用户名与邮箱："></a>*必做：设置用户名与邮箱：</h3><pre><code class="bash">git config --global user.name &quot;用户名&quot;
git config --global user.email &quot;邮箱&quot;
</code></pre>
<p>这个邮箱需要保证是真实邮箱，后面有需要</p>
<h1 id="三、Git的工作原理"><a href="#三、Git的工作原理" class="headerlink" title="三、Git的工作原理"></a>三、Git的工作原理</h1><h2 id="3-1-配置环境变量"><a href="#3-1-配置环境变量" class="headerlink" title="3.1 配置环境变量"></a>3.1 配置环境变量</h2><p>将 目录\Git\cmd 配置进去</p>
<h2 id="3-2-Git基本理论-核心"><a href="#3-2-Git基本理论-核心" class="headerlink" title="3.2 Git基本理论(核心)"></a>3.2 Git基本理论(核心)</h2><h3 id="工作区域"><a href="#工作区域" class="headerlink" title="工作区域"></a>工作区域</h3><p>Git本地有三个工作区域:</p>
<ul>
<li><p>工作目录（Working Directory )</p>
</li>
<li><p>暂存区(Stage/Index)</p>
</li>
<li><p>资源库(Repository或Git Directory)</p>
</li>
</ul>
<p>如果在加上远程的git仓库(Remote Directory)就可以分为四个工作区域。文件在这四个区域之间的转换关系如下:</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210502171048444.png" alt="image-20210502171048444"></p>
<ul>
<li><strong>Workspace :工作区</strong>，就是你平时存放项目代码的地方</li>
<li>Index / Stage:暂存区，用于临时存放你的改动，事实上它只是一个文件，保存即将提交到文件列表信息</li>
<li>Repository:仓库区（或本地仓库），就是安全存放数据的位置，这里面有你提交到所有版本的数据。其中HEAD指向最新放入仓库的版本</li>
<li><strong>Remote :远程仓库</strong>，托管代码的服务器，可以简单的认为是你项目组中的一台电脑用于远程数据交换</li>
</ul>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210502171321805.png" alt="image-20210502171321805"></p>
<h3 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h3><ol>
<li>在工作目录中添加、修改文件;</li>
<li>将需要进行版本管理的文件放入暂存区域;    <strong>git add .</strong></li>
<li>将暂存区域的文件提交到git仓库。    <strong>git commit</strong></li>
</ol>
<p>git管理的文件有三种状态︰已修改( modified ) ,已暂存( staged ) ,已提交(committed)</p>
<h2 id="3-3-Git项目搭建"><a href="#3-3-Git项目搭建" class="headerlink" title="3.3 Git项目搭建"></a>3.3 Git项目搭建</h2><h3 id="3-3-1创建工作目录与常用指令"><a href="#3-3-1创建工作目录与常用指令" class="headerlink" title="3.3.1创建工作目录与常用指令"></a>3.3.1创建工作目录与常用指令</h3><p>工作目录(WorkSpace)一般就是你希望Git帮助你管理的文件夹，可以是你项目的目录，也可以是一个空目录，建议不要有中文。</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210502171745536.png" alt="image-20210502171745536"></p>
<h3 id="3-3-2-本地仓库搭建-及-克隆远程仓库"><a href="#3-3-2-本地仓库搭建-及-克隆远程仓库" class="headerlink" title="3.3.2 本地仓库搭建 及 克隆远程仓库"></a>3.3.2 本地仓库搭建 及 克隆远程仓库</h3><pre><code class="bash"># 初始化方法一，完成后在本目录多了一个 .git隐藏文件
git init 

# 初始化方法二：克隆远程仓库
git clone [URL]
</code></pre>
<h1 id="四、Git文件操作"><a href="#四、Git文件操作" class="headerlink" title="四、Git文件操作"></a>四、Git文件操作</h1><h2 id="4-1-文件的状态"><a href="#4-1-文件的状态" class="headerlink" title="4.1 文件的状态"></a>4.1 文件的状态</h2><p>版本控制就是对文件的版本控制，要对文件进行修改、提交等操作，首先要知道文件当前在什么状态，不然可能会提交了现在还不想提交的文件，或者要提交的文件没提交上。</p>
<ul>
<li><strong>Untracked</strong>:未跟踪,此文件在文件夹中，但并没有加入到git库,不参与版本控制.通过<strong>git add</strong>状态变为<strong>staged</strong></li>
<li><strong>Unmodify</strong>:文件已经入库,未修改,即版本库中的文件快照内容与文件夹中完全一致.这种类型的文件有两种去处,如果它被修改,而变为Modified.如果使用<strong>git rm</strong>移出版本库,则成为<strong>Untracked</strong>文件</li>
<li><strong>Modified</strong>:文件已修改,仅仅是修改,并没有进行其他的操作.这个文件也有两个去处,通过<strong>git add</strong>可进入暂存<strong>staged</strong>状态,使用<strong>git checkout</strong>则丢弃修改过,返回到_unmodify状态,这个 git checkout即从库中取出文件,覆盖当前修改!</li>
<li><strong>Staged</strong>:暂存状态.执行<strong>git commit</strong>则将修改同步到库中,这时库中的文件和本地文件又变为一致,文件为<strong>unmodify</strong>状态.执行<strong>git reset HEAD filename</strong>取消暂存，文件状态为<strong>Modified</strong></li>
</ul>
<p>查看文件状态：</p>
<pre><code class="bash">git status
</code></pre>
<p>提交到本地仓库：</p>
<pre><code class="bash">git add . # 提交所有文件到暂存区
git commit -m &quot;&quot; # 提交到本地仓库，-m是提交附带的信息
</code></pre>
<h2 id="4-2-忽略文件"><a href="#4-2-忽略文件" class="headerlink" title="4.2 忽略文件"></a>4.2 忽略文件</h2><p>有些时候我们不想把某些文件纳入版本控制中，比如数据库文件，临时文件，设计文件等在主目录下建立”<strong>.gitignore</strong>“文件，此文件有如下规则∶</p>
<ol>
<li>忽略文件中的空行或以井号(#）开始的行将会被忽略。</li>
<li>可以使用Linux通配符。例如∶星号(*)代表任意多个字符，问号( ? )代表一个字符，方括号( [abc])代表可选字符范围，大括号( {string1,string2..…})代表可选的字符串等。</li>
<li>如果名称的最前面有一个感叹号( !)，表示例外规则，将不被忽略。</li>
<li>如果名称的最前面是一个路径分隔符(/ )，表示要忽略的文件在此目录下，而子目录中的文件不忽略。</li>
<li>如果名称的最后面是一个路径分隔符(/)，表示要忽略的是此目录下该名称的子目录，而非文件（默认文件或目录都忽略)。</li>
</ol>
<pre><code class="bash">*.txt # 忽略所有 .txt结尾的文件，这样的话上传就不会被选中！
!lib.txt # 但lib.txt除外
/temp  # 仅忽略项目根目录下的TODO文件，不包括其他目录temp
build/ # 忽略build/ 目录下的所有文件
doc/*.txt # 会忽略 doc/motes.txt 但不会忽略 doc/server/arch.txt
</code></pre>
<h1 id="五、使用Gitee或者GitHub等远程仓库"><a href="#五、使用Gitee或者GitHub等远程仓库" class="headerlink" title="五、使用Gitee或者GitHub等远程仓库"></a>五、使用Gitee或者GitHub等远程仓库</h1><blockquote>
<p>github是有墙的，比较慢，在国内的话，我们一般使用gitee ，公司中有时候会搭建自己的gitlab服务器</p>
</blockquote>
<ol>
<li>登录/注册，完善个人信息</li>
<li>设置本机绑定SSH公钥，实现免密码登录 【重点】</li>
</ol>
<pre><code class="bash"># 进入 C:\Users\用户名\.ssh
# 生成SSH公钥
ssh-keygen
# 默认 rsa加密算法， ssh-keygen -t rsa
# 完成后生成两个文件：id_rsa 、 id_rsa.pub
# 其中 .pub是公钥，另一个是私钥

3. 将公钥信息public key添加到 平台账户 中即可

4. 使用平台创建一个自己的仓库

![image-20210502183157859](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210502183157859.png)

5. 克隆到本地


</code></pre>
<h1 id="六、Git分支"><a href="#六、Git分支" class="headerlink" title="六、Git分支"></a>六、Git分支</h1><p>以上都是单人操作，但接下来的多人操作需要分支：</p>
<p>分支在GIT中相对较难，分支就是科幻电影里面的平行宇宙，如果两个平行宇宙互不干扰，那对现在的你也没啥影响。不过在某个时间点，两个平行宇宙合并了，我们就需要处理一些问题了!</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210502184706038.png" alt="image-20210502184706038"></p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210502184759987.png" alt="image-20210502184759987"></p>
<h2 id="Git中常用的分支命令"><a href="#Git中常用的分支命令" class="headerlink" title="Git中常用的分支命令"></a>Git中常用的分支命令</h2><pre><code class="bash"># 列出所有本地分支
git branch

# 列出所有的远程分支，并切换到该分支
git branch [分支名]

# 合并指定分支到当前分支
git merge [branch]

# 删除分支
git branch -d [分支名]

# 删除源程分支
git push origin --delete [分支名]
git branch -dr [remote/branch]
</code></pre>
<p>如果同一个文件在合并分支时都被修改了则会引起冲突︰解决的办法是我们可以修改冲突文件后重新提交!选择要保留他的代码还是你的代码!</p>
<p><strong>master主分支应该非常稳定，用来发布新版本，一般情况下不允许在上面工作，工作一般情况下在新建的dev分支上工作，工作完后，比如上要发布，或者说dev分支代码稳定后可以合并到主分支master上来。</strong></p>
<h2 id="Git分支模型"><a href="#Git分支模型" class="headerlink" title="Git分支模型"></a>Git分支模型</h2><p>![20180624174835949](D:\QQ doc\FileRecv\20180624174835949.png)</p>
<p>创建仓库时，在master分支版本号0.1</p>
<p>拉取分支develop做主开发分支，从develop分支拉取多个feature特征分支</p>
<p>在feature分支发现的bug就在feature中修改，特征分支开发并bug修复完毕后，合并至develop分支</p>
<p>随后将develop分支拉取出环境测试分支，即release预发布分支，测试修复问题后，合并至develop分支，同时可以发布面向客户的内容至master分支，此时版本号命名为1.0</p>
<p>如果发现master分支出现bug，则拉取hotfixes分支进行修复后再发布至master分支，版本号更名为1.1</p>
<p>过程向后以此类推。</p>
<p><em>如果版本号为三位版本号，一般来说第一位的变更意味着大版本的变化，可能不兼容上一版本</em></p>
<h1 id="IDEA集成Git"><a href="#IDEA集成Git" class="headerlink" title="[IDEA集成Git]"></a>[IDEA集成Git]</h1><ol>
<li>新建项目<ul>
<li>方式一：项目的目录就是本地git仓库的目录</li>
<li>方式二：把本地仓库的.git等信息拷贝到工程目录即可</li>
</ul>
</li>
<li>修改文件，使用IDEA操作git<ul>
<li>添加到暂存区</li>
<li>git commit</li>
<li>git push</li>
</ul>
</li>
</ol>
<h1 id="问题解决"><a href="#问题解决" class="headerlink" title="[问题解决]"></a>[问题解决]</h1><h2 id="1-添加公钥后仍然需要输入帐号密码push"><a href="#1-添加公钥后仍然需要输入帐号密码push" class="headerlink" title="1. 添加公钥后仍然需要输入帐号密码push"></a>1. 添加公钥后仍然需要输入帐号密码push</h2><p>问题原因：git clone远程仓库的时候使用的Http</p>
<p>解决方法：用SSH来git clone远程仓库到本地，就可以解决</p>
<h2 id="2-git-clone只能clone远程库的master分支，无法clone所有分支，解决办法如下："><a href="#2-git-clone只能clone远程库的master分支，无法clone所有分支，解决办法如下：" class="headerlink" title="2. git clone只能clone远程库的master分支，无法clone所有分支，解决办法如下："></a>2. git clone只能clone远程库的master分支，无法clone所有分支，解决办法如下：</h2><ol>
<li>git clone <a target="_blank" rel="noopener" href="http://myrepo.xxx.com/project/.git">http://myrepo.xxx.com/project/.git</a> ,这样在git_work目录下得到一个project子目录</li>
<li>cd project</li>
<li>git branch -a，列出所有分支名称如下：<br> remotes/origin/dev<br> remotes/origin/release</li>
<li>git checkout -b dev origin/dev，作用是checkout远程的dev分支，在本地起名为dev分支，并切换到本地的dev分支</li>
<li>git checkout -b release origin/release，作用参见上一步解释</li>
<li>git checkout dev，切换回dev分支，并开始开发。</li>
</ol>

            
        </div>
    </div>

    <div class="post-tags">
        
        
    </div>

    <a href="/2022/05/18/Git/ " class="go-post">
        阅读全文
    </a>
</div>

<div class="post">

    <a href="/2022/05/18/hello-world/">
        <h2>
            Hello World
        </h2>
    </a>

    <div class="category-and-date">

        

        <span class="date">
            <span class="icon">
                <a-icon type="calendar" theme="filled" />
            </span>
            2022/5/18
        </span>

    </div>

    <div class="excerpt">
        <div class="content" v-pre>
            
            
            <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="bash">$ hexo new &quot;My New Post&quot;
</code></pre>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="bash">$ hexo server
</code></pre>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="bash">$ hexo generate
</code></pre>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="bash">$ hexo deploy
</code></pre>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

            
        </div>
    </div>

    <div class="post-tags">
        
        
    </div>

    <a href="/2022/05/18/hello-world/ " class="go-post">
        阅读全文
    </a>
</div>

<div class="post">

    <a href="/2022/05/15/Java 8新版本特性/">
        <h2>
            Java 8 特性及实战
        </h2>
    </a>

    <div class="category-and-date">

        

        <span class="date">
            <span class="icon">
                <a-icon type="calendar" theme="filled" />
            </span>
            2022/5/15
        </span>

    </div>

    <div class="excerpt">
        <div class="content" v-pre>
            
            
            <h1 id="一、JDK-8"><a href="#一、JDK-8" class="headerlink" title="一、JDK 8"></a>一、JDK 8</h1><ul>
<li>Lambda表达式</li>
<li>强大的Stream API</li>
<li>便于并行</li>
<li>最大化减少空指针异常：Optional</li>
<li>Nashorn引擎，允许在JVM上运行JS应用</li>
</ul>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116184712768.png" alt="image-20220116184712768"></p>
<h2 id="1-1-Lambda表达式"><a href="#1-1-Lambda表达式" class="headerlink" title="1.1 Lambda表达式"></a>1.1 Lambda表达式</h2><blockquote>
<p>例子</p>
</blockquote>
<pre><code class="java">//标准写法
Comparator&lt;Integer&gt; cmp = new Comparator&lt;Integer&gt;() &#123;
    @Override
    public int compare(Integer o1, Integer o2) &#123;
        return Integer.compare(o1,o2);
    &#125;
&#125;;
// Lambda表达式 
Comparator&lt;Integer&gt; cmp1 = (o1, o2) -&gt; Integer.compare(o1,o2);
// 更简洁的Lambda表达式 
Comparator&lt;Integer&gt; cmp2 = Integer::compare;
</code></pre>
<blockquote>
<p>本质</p>
</blockquote>
<p>作为函数式接口的实例 (接口实现类对象)</p>
<p><strong>函数式接口：</strong>一个接口中，只声明了一个抽象方法</p>
<blockquote>
<p>格式</p>
</blockquote>
<p><code>-&gt;</code> Lambda操作符，或箭头操作符，左边是形参列表(其实就是接口中的抽象方法中的形参列表)；右边是Lmbda体，其实就是重写的抽象方法的方法体。</p>
<ul>
<li><p>语法格式一：无参，无返回值</p>
<pre><code class="java">Runnable r = () -&gt; System.out.println(&quot;无参，无返回值&quot;);
</code></pre>
</li>
<li><p>语法格式二：一个参数，没有返回值</p>
<pre><code class="java">Consumer&lt;String&gt; con = (String s) -&gt; System.out.println(s);
</code></pre>
</li>
<li><p>语法格式三：数据类型可以省略，因为可由编译器推断出，成为类型推断</p>
<pre><code class="java">Consumer&lt;String&gt; con =  (s) -&gt; System.out.println(s);
</code></pre>
</li>
<li><p>语法格式四：Lambda若只有一个参数，小括号可以省略</p>
<pre><code class="java">Consumer&lt;String&gt; con =  s -&gt; System.out.println(s);
</code></pre>
</li>
<li><p>语法格式五：需要两个或以上参数，多条执行语句，并且有返回值</p>
<pre><code class="java">Comparator&lt;Integer&gt; comparator = (x,y)-&gt;&#123;
    System.out.println(&quot;实现函数式接口方法&quot;);  
    return Integer.compare(x,y);
&#125;;
</code></pre>
</li>
<li><p>语法格式六：当Lambda体只有一条语句时，return和大括号可以省略</p>
<pre><code class="java">Comparator&lt;Integer&gt; comparator = (x,y)-&gt; Integer.compare(x,y);
</code></pre>
</li>
</ul>
<blockquote>
<p>类型推断</p>
</blockquote>
<p>上述 Lambda 表达式中的参数类型都是由编译器推断得出的。Lambda 表达式中无需指定类型，程序依然可以编译，这是因为 javac 根据程序的上下文，在后台推断出了参数的类型。Lambda 表达式的类型依赖于上下文环境，是由编译器推断出来的。</p>
<h2 id="1-2-函数式接口"><a href="#1-2-函数式接口" class="headerlink" title="1.2 函数式接口"></a>1.2 函数式接口</h2><ul>
<li>只含有一个抽象方法的接口</li>
<li>可以通过Lambda表达式创建该接口的对象。若Lambda表达式抛出一个受检异常(即非运行时异常)，那么该异常需要在目标接口的抽象方法上进行声明</li>
<li>可以在一个接口上使用<code>@FunctionalInterface</code>注解，检查他是否是一个函数式接口。同时Javadoc种也会包含一条声明，说明这个接口是一个函数式接口</li>
<li>使得Java不但可以支持OOP还可以支持OOF（面向函数编程）</li>
<li>以前用匿名实现类表示的现在都可以用Lambda表达式来写</li>
</ul>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116172038366.png" alt="image-20220116172038366" style="zoom:50%;" />

<blockquote>
<p>Java内置的四大核心函数式接口</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116172129740.png" alt="image-20220116172129740"></p>
<blockquote>
<p>其他接口</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116172149051.png" alt="image-20220116172149051"></p>
<h2 id="1-3-方法引用和构造器引用"><a href="#1-3-方法引用和构造器引用" class="headerlink" title="1.3 方法引用和构造器引用"></a>1.3 方法引用和构造器引用</h2><ul>
<li>当要传递给Lambda体的操作，已经有实现的方法了，就可以使用方法引用</li>
<li>可以看做是Lambda表达式深层次的表达。换句话说，方法引用就是Lambda表达式，也就是函数式接口的一个实例，通过方法的名字来指向一个方法。</li>
<li><strong>实现接口的抽象方法的参数列表和返回值类型，必须与方法引用的方法的参数列表和返回值类型保持一致</strong></li>
<li>主要有如下三种使用情况<ul>
<li><code>对象::实例方法名</code></li>
<li><code>类::静态方法名</code></li>
<li><code>类::实例方法名</code></li>
</ul>
</li>
</ul>
<blockquote>
<p>方法引用</p>
</blockquote>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116172428660.png" alt="image-20220116172428660" style="zoom:67%;" />



<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116172442537.png" alt="image-20220116172442537" style="zoom:67%;" />



<p>==注意：当函数式接口方法的第一个参数是需要引用方法的调用者，并且第二个参数是需要引用方法的参数(或无参数)时：ClassName::methodName==</p>
<blockquote>
<p>构造器引用</p>
</blockquote>
<p><strong>要求构造器参数列表要与接口中抽象方法的参数列表一致！且方法的返回值即为构造器对应类的对象。</strong></p>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116172637759.png" alt="image-20220116172637759" style="zoom:80%;" />

<p>以此还有数组引用</p>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116172718933.png" alt="image-20220116172718933" style="zoom:80%;" />

<h2 id="1-4-Stream-API"><a href="#1-4-Stream-API" class="headerlink" title="1.4 Stream API"></a>1.4 Stream API</h2><h3 id="1-4-1-概述"><a href="#1-4-1-概述" class="headerlink" title="1.4.1 概述"></a>1.4.1 概述</h3><ul>
<li>Stream API ( java.util.stream) 把真正的函数式编程风格引入到Java中。这是目前为止对Java类库最好的补充，因为Stream API可以极大提供Java程序员的生产力，让程序员写出高效率、干净、简洁的代码。</li>
<li>Stream 是 Java8 中处理集合的关键抽象概念，它可以指定你希望对集合进行的操作，可以执行非常复杂的查找、过滤和映射数据等操作。 <strong>使用Stream API 对集合数据进行操作，就类似于使用 SQL 执行的数据库查询。</strong>也可以使用 Stream API 来并行执行操作。简言之，Stream API 提供了一种高效且易于使用的处理数据的方式</li>
<li>实际开发中，项目中多数数据源都来自于Mysql，Oracle等。但现在数据源可以更多了，有MongDB，Radis等，而这些NoSQL的数据就需要Java层面去处理。因此需要StreamAPI</li>
</ul>
<blockquote>
<p>Stream和Collection集合的区别</p>
</blockquote>
<ul>
<li>Collection是一种静态的内存数据结构，而Stream是有关计算的。</li>
<li>Collection面向内存，存储在内存中。Stream面向CPU，通过CPU实现计算</li>
</ul>
<blockquote>
<p>是什么</p>
</blockquote>
<p>是数据渠道，用于操作数据源（集合、数组等）所生成的元素序列。<strong>集合讲的是数据，</strong>Stream讲的是计算！</p>
<p>注意：</p>
<ol>
<li>Stream自己本身不会存储元素</li>
<li>Stream不会改变源对象。他们会返回一个持有结果的新Stream</li>
<li>Stream操作是延迟执行的。这意味着他们会等到需要结果的时候才执行</li>
</ol>
<blockquote>
<p>使用步骤</p>
</blockquote>
<ol>
<li><p>创建Stream</p>
<p>一个数据源(如：集合、数组)，获取一个流</p>
</li>
<li><p>中间操作</p>
<p>一个中间操作链，对数据源的数据进行处理</p>
</li>
<li><p>终止操作(终端操作)</p>
<p>一旦执行终止操作，就执行中间操作链，并产生结果。之后不会再被使用</p>
</li>
</ol>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116173310477.png" alt="image-20220116173310477"></p>
<h3 id="1-4-2-创建Stream"><a href="#1-4-2-创建Stream" class="headerlink" title="1.4.2 创建Stream"></a>1.4.2 创建Stream</h3><blockquote>
<p>方式一：通过集合</p>
</blockquote>
<ul>
<li><code>default Stream&lt;E&gt; stream()</code>：返回一个顺序流</li>
<li><code>default Stream&lt;E&gt; parallelStream()</code>：返回一个并行流</li>
</ul>
<blockquote>
<p>方式二：通过数组</p>
</blockquote>
<ul>
<li><code>static&lt;T&gt; Stream&lt;T&gt; stream(T[] array)</code>：返回一个流</li>
</ul>
<blockquote>
<p>方式三：通过Stream的API</p>
</blockquote>
<ul>
<li><code>public static&lt;T&gt; Stream&lt;T&gt; of(T... values)</code>：返回一个流</li>
</ul>
<blockquote>
<p>方式四：创建无限流</p>
</blockquote>
<ul>
<li><code>public static&lt;T&gt; Stream&lt;T&gt; iterate(final T seed, final UnaryOperator&lt;T&gt; f)</code>：迭代</li>
<li><code>public static&lt;T&gt; Stream&lt;T&gt; generate(Supplier&lt;T&gt; s)</code>：生成</li>
</ul>
<p><strong>并行流</strong>就是把一个内容分成多个数据块，并用不同的线程分别处理每个数据块的流。相比较串行的流，并行的流可以很大程度上提高程序的执行效率</p>
<p>Java 8 中将并行进行了优化，我们可以很容易的对数据进行并行操作。Stream API 可以声明性地通过 parallel() 与 sequential() 在并行流与顺序流之间进行切换.</p>
<h3 id="1-4-3-中间操作"><a href="#1-4-3-中间操作" class="headerlink" title="1.4.3 中间操作"></a>1.4.3 中间操作</h3><blockquote>
<p>筛选与切片</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116183719575.png" alt="image-20220116183719575"></p>
<blockquote>
<p>映射</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116183735308.png" alt="image-20220116183735308"></p>
<blockquote>
<p>排序</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116183748626.png" alt="image-20220116183748626"></p>
<h3 id="1-4-4-终止操作"><a href="#1-4-4-终止操作" class="headerlink" title="1.4.4 终止操作"></a>1.4.4 终止操作</h3><blockquote>
<p>匹配与查找</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116183814043.png" alt="image-20220116183814043"></p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116183830696.png" alt="image-20220116183830696"></p>
<blockquote>
<p>规约</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116183851771.png" alt="image-20220116183851771"></p>
<p><em>map和reduce的连接通常称为map-reduce模式,因Google用它来进行网络搜索而出名</em></p>
<blockquote>
<p>收集</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116183939273.png" alt="image-20220116183939273"></p>
<p>Collector 接口中方法的实现决定了如何对流执行收集的操作(如收集到 List、Set、Map)。</p>
<p>Collectors 实用类提供了很多静态方法，可以方便地创建常见收集器实例</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116184024292.png" alt="image-20220116184024292"></p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220116184035965.png" alt="image-20220116184035965"></p>
<h2 id="1-5-Optional-类"><a href="#1-5-Optional-类" class="headerlink" title="1.5 Optional 类"></a>1.5 Optional 类</h2><p>Optional<T> 类(java.util.Optional) 是一个容器类，它可以保存类型T的值，代表这个值存在。或者仅仅保存null，表示这个值不存在。原来用 null 表示一个值不存在，现在 Optional 可以更好的表达这个概念。并且可以避免空指针异常。</p>
<p>==Optional类的Javadoc描述如下：这是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。==</p>
<p>Optional提供很多有用的方法，这样我们就不用显式进行空值检测。</p>
<blockquote>
<p>创建Optional类对象</p>
</blockquote>
<ul>
<li><code>Optional.of(T t)</code>：创建一个Optional实例，t必须非空</li>
<li><code>Optional.empty()</code>：创建一个空的Optional实例</li>
<li><code>Optional.ofNullable(T t)</code>：t可以为null</li>
</ul>
<blockquote>
<p>判断Optional容器种是否包含对象</p>
</blockquote>
<ul>
<li><code>boolean isPresent()</code>：判断是否包含对象</li>
<li><code>void ifPresent(Consumer&lt;? super T&gt; consumer)</code>：如果有值，就执行Consumer接口的实现代码，并且该值会作为参数传给它</li>
</ul>
<blockquote>
<p>获取Optional容器的对象</p>
</blockquote>
<ul>
<li><code>T get()</code>：如果调用对象包含值，返回该值，否则抛异常</li>
<li><code>T orElse(T other)</code>：如果有值则将其返回，否则返回指定的other对象</li>
<li><code>T orElseGet(Supplier&lt;? extends T&gt; other)</code>：如果有值则直接返回，否则返回由Supplier接口实现提供的对象</li>
<li><code>T orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier)</code>：如果有值则将其返回，否则抛出由Supplier接口实现提供的异常</li>
</ul>
<h2 id="1-6-Collector-lt-T-A-R-gt"><a href="#1-6-Collector-lt-T-A-R-gt" class="headerlink" title="1.6 Collector&lt;T, A, R&gt;"></a>1.6 Collector&lt;T, A, R&gt;</h2><pre><code class="java">// 用于还原操作的输入元素的类型
&lt;T&gt; the type of input elements to the reduction operation
// 中间存放数据的容器
&lt;A&gt; the mutable accumulation type of the reduction operation (often hidden as an implementation detail)
// 还原操作的结果类型（输出）
&lt;R&gt; the result type of the reduction operation
</code></pre>
<p>Collector通过下面四个方法协同工作以完成汇聚操作：</p>
<ul>
<li>supplier： 创建新的结果容器</li>
<li>accumulator：将输入元素合并到结果容器中</li>
<li>combiner：合并两个结果容器(非必然运行 可能在并行流且Collector不具备CONCURRENT  时执行的 ) </li>
<li>finisher：将结果容器转换成最终的表示 (非必然运行 中间结果与最终结果类型是否一致决定是否运行，IDENTITY_FINISH用来标志 ) </li>
</ul>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220224163339308.png" alt="image-20220224163339308" style="zoom:67%;" />

<p><strong>Collector 就是归约运算操作的一种抽象</strong> </p>
<blockquote>
<p>理解归约reduce的含义 </p>
<p>(也就是归纳转换成另外一种形式)</p>
</blockquote>
<p>想要进行归约运算,你先给出一个初始容器,作为中间结果容器                         </p>
<p>然后再给出迭代运算逻辑 也就是要如何归约 归约的逻辑 就是在这里 结果计算到中间结果容器中                         </p>
<p>针对于并行计算还需要一个合并的方式 </p>
<blockquote>
<p>常用收集器 </p>
</blockquote>
<ul>
<li><strong>toList()</strong> ：将元素收集到一个 <strong>List</strong> 中</li>
<li>toSet() ：将元素收集到一个 <strong>Set</strong> 中。             </li>
<li>toCollection() ：将元素收集到一个<strong>Collection</strong>中</li>
<li>toMap() ：将元素收集到一个<strong>Map</strong>中，依据提供的映射函数将元素转换为键值</li>
<li><strong>summingInt(ToIntFunction&lt;? super T&gt;)</strong> ：给定值序列求和(还有<code>long</code>和<code>double</code>版本)</li>
<li>reducing(…)：用于归约计算(通常用作下游收集器，比如用于groupingBy 或者 partitioningBy下游)</li>
<li>partitioningBy(…) ：按照predicate分为两组</li>
<li>groupingBy(…)：将元素分组</li>
<li>maxBy(Comparator&lt;? super T&gt; comparator)：最大值</li>
<li>minBy(Comparator&lt;? super T&gt; comparator)：最小值</li>
<li>**mapping(Function&lt;T,U&gt; , Collector)**：将提供的映射函数应用于每个元素，并使用指定的下游收集器(通常用作下游收集器本身，比如用于groupingBy)进行处理</li>
<li>joining()：假设元素为String类型，将这些元素联结到一个字符串中(或许使用分隔符、前缀和后缀)</li>
<li>counting() ：计算元素数量(通常用作下游收集器)</li>
<li>averagingInt(ToIntFunction&lt;? super T&gt;) ：平均数(还有<code>long</code>和<code>double</code>版本)</li>
</ul>
<h2 id="1-7-Function-lt-T-R-gt"><a href="#1-7-Function-lt-T-R-gt" class="headerlink" title="1.7 Function&lt;T, R&gt;"></a>1.7 Function&lt;T, R&gt;</h2><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220224171449056.png" alt="image-20220224171449056" style="zoom: 67%;" />

<p>“接收一个参数，返回一个值”</p>
<pre><code class="java">public interface Function&lt;T, R&gt; &#123;
    /**
    * 将此函数应用于给定参数，真正执行函数接口的方法
    */
    R apply(T t);
    
    /**
    * 函数链，before执行的结果做根函数为参数
    */
    default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before)&#123;
        Objects.requireNonNull(before);
        return (V v) -&gt; apply(before.apply(v));
    &#125;
    
    /**
    * 函数链，根函数执行结果作为after的参数
    */
    default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super R, ? extends V&gt; after)&#123;
        Objects.requireNonNull(after);
        return (V v) -&gt; apply(after.apply(v));
    &#125;
    
    /**
    * 返回一个参数作为返回值的函数
    */
    static &lt;T&gt; Function&lt;T,T&gt; identity() &#123;
        return t -&gt; t;
    &#125;
&#125;
</code></pre>
<ul>
<li>BiFunction&lt;T,U,R&gt;：代表了一个接受两个输入参数的方法，并且返回一个结果</li>
<li>DoubleFunction&lt; R&gt;：代表接受一个double值参数的方法，并且返回结果</li>
<li>DoubleToIntFunction：接受一个double类型输入，返回一个int类型结果。</li>
<li>DoubleToLongFunction：接受一个double类型输入，返回一个long类型结果</li>
<li>IntFunction&lt; R&gt;:接受一个int类型输入参数，返回一个结果 。</li>
<li>IntToDoubleFunction：接受一个int类型输入，返回一个double类型结果 。</li>
<li>IntToLongFunction：接受一个int类型输入，返回一个long类型结果。</li>
<li>LongFunction&lt; R&gt;： 接受一个long类型输入参数，返回一个结果。</li>
<li>LongToDoubleFunction： 接受一个long类型输入，返回一个double类型结果。</li>
<li>LongToIntFunction：接受一个long类型输入，返回一个int类型结果。</li>
<li>ToDoubleBiFunction&lt;T,U&gt;：接受两个输入参数，返回一个double类型结果</li>
<li>ToDoubleFunction&lt; T&gt;：接受一个输入参数，返回一个double类型结果</li>
<li>ToIntBiFunction&lt;T,U&gt;：接受两个输入参数，返回一个int类型结果。</li>
<li>ToIntFunction&lt; T&gt;：接受一个输入参数，返回一个int类型结果。</li>
<li>ToLongBiFunction&lt;T,U&gt;：接受两个输入参数，返回一个long类型结果。</li>
<li>ToLongFunction&lt; T&gt;：接受一个输入参数，返回一个long类型结果。</li>
</ul>
<h1 id="二、实战应用"><a href="#二、实战应用" class="headerlink" title="二、实战应用"></a>二、实战应用</h1><h2 id="2-1-收集器-Collectors"><a href="#2-1-收集器-Collectors" class="headerlink" title="2.1 收集器(Collectors)"></a>2.1 收集器(Collectors)</h2><pre><code class="java">// 获取所有的name转换到List&lt;String&gt;中
List&lt;String&gt; list =people.stream()
    .map(Person::getName).collect(Collectors.toList());

// 获取所有的name转换到Set&lt;String&gt;中
Set&lt;String&gt; set =people.stream()
  .map(Person::getName).collect(Collectors.toCollection(TreeSet::new));

// 元素转换为String 并且将他们通过&quot;, &quot; 连接起来
String joined = things.stream()
    .map(Object::toString)
    .collect(Collectors.joining(&quot;, &quot;));

//计算员工薪水之和
int total = employees.stream()
    .collect(Collectors.summingInt(Employee::getSalary)));

// 按照部门对员工进行分组
Map&lt;Department, List&lt;Employee&gt;&gt; byDept
    = employees.stream()
    .collect(Collectors.groupingBy(Employee::getDepartment));

// 计算部门薪资和
Map&lt;Department, Integer&gt; totalByDept
    = employees.stream()
    .collect(Collectors.groupingBy(Employee::getDepartment,
                                   Collectors.summingInt(Employee::getSalary)));

// 按照成绩是否通过把学生分为两组
Map&lt;Boolean, List&lt;Student&gt;&gt; passingFailing =
    students.stream()
    .collect(Collectors.partitioningBy(s -&gt; s.getGrade() &gt;= PASS_THRESHOLD));
</code></pre>

            
        </div>
    </div>

    <div class="post-tags">
        
        <span class="icon">
            <a-icon type="tags" theme="filled" />
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/Java" style=color:#00bcd4>
                Java
            </a>
        </span>
        
    </div>

    <a href="/2022/05/15/Java 8新版本特性/ " class="go-post">
        阅读全文
    </a>
</div>

<div class="post">

    <a href="/2022/04/26/MySQL高级/">
        <h2>
            MySQL高级
        </h2>
    </a>

    <div class="category-and-date">

        

        <span class="date">
            <span class="icon">
                <a-icon type="calendar" theme="filled" />
            </span>
            2022/4/26
        </span>

    </div>

    <div class="excerpt">
        <div class="content" v-pre>
            
            
            <h1 id="零、前言"><a href="#零、前言" class="headerlink" title="零、前言"></a>零、前言</h1><p>@Author：韩霄杰(Hansious | SkyFroop)</p>
<p>@Date: 20220209</p>
<p>@Update: 20220323 | 20220401</p>
<p>@Description: 本篇专注于MySQL DBMS的分析。若需要强化SQL参考《SQL》笔记。</p>
<p>[toc]</p>
<h1 id="一、MySQL架构"><a href="#一、MySQL架构" class="headerlink" title="一、MySQL架构"></a>一、MySQL架构</h1><h2 id="1-1-MySQL逻辑架构"><a href="#1-1-MySQL逻辑架构" class="headerlink" title="1.1 MySQL逻辑架构"></a>1.1 MySQL逻辑架构</h2><p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220102123039770.png" alt="image-20220102123039770"></p>
<p>1.连接层</p>
<p>最上层是一些客户端和连接服务，包含本地sock通信和大多数基于客户端/服务端工具实现的类似于tcpip的通信。主要完成一些类似于连接处理、授权认证、及相关的安全方案。在该层上引入了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSL的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。</p>
<p>⒉服务层</p>
<p>第二层架构主要完成大多少的核心服务功能，如SQL接口，并完成缓存的查询，SQL的分析和优化及部分内置函数的执行。所有跨存储引擎的功能也在这一层实现，如过程、函数等。在该层，服务器会解析查询并创建相应的内部解析树，并对其完成相应的优化如确定查询表的顺序，是否利用索引等，最后生成相应的执行操作。如果是select语句，服务器还会查询内部的缓存。如果缓存空间足够大，这样在解决大量读操作的环境中能够很好的提升系统的性能。</p>
<p>3.引擎层</p>
<p>存储引擎层，存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信。不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需要进行选取。后面介绍MyISAM和InnoDB</p>
<p>4.存储层</p>
<h2 id="1-2-存储引擎"><a href="#1-2-存储引擎" class="headerlink" title="1.2  存储引擎"></a>1.2  存储引擎</h2><blockquote>
<p>查看本机的存储引擎</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220102131452342.png" alt="image-20220102131452342"></p>
<blockquote>
<p>MyISAM和InnoDB的区别</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220102131619820.png" alt="image-20220102131619820"></p>
<h1 id="二、索引优化"><a href="#二、索引优化" class="headerlink" title="二、索引优化"></a>二、索引优化</h1><h2 id="2-1-SQL解析"><a href="#2-1-SQL解析" class="headerlink" title="2.1 SQL解析"></a>2.1 SQL解析</h2><p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220102215655473.png" alt="image-20220102215655473"></p>
<h2 id="2-2-索引"><a href="#2-2-索引" class="headerlink" title="2.2 索引"></a>2.2 索引</h2><p>MySQL官方对索引的定义为:索引(Index）是帮助MySQL高效获取数据的数据结构。数据本身之外，数据库还维护着一个满足特定查找算法的数据结构(B树)，这些数据结构以某种方式指向数据，这样就可以在这些数据结构的基础上实现高级查找算法，这种数据结构就是索引。</p>
<h3 id="2-2-1-索引数据结构概述"><a href="#2-2-1-索引数据结构概述" class="headerlink" title="2.2.1 索引数据结构概述"></a>2.2.1 索引数据结构概述</h3><p>==可以得到索引的本质:索引是数据结构。==</p>
<p>可以简单的理解为“排好序的快速查找数据结构” —&gt; 索引的功能：排序，快速查找</p>
<p>在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用(指向)数据,这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220102221537029.png" alt="image-20220102221537029"></p>
<p>左边是数据表，-共有两列七条记录，最左边的是数据记录的物理地址</p>
<p>为了加快Col2的查找，可以维护-一个右边所示的二叉查找树，每个节点分别包含索引键值和–个指向对应数据记录物理地止的指针，这样就可以运用二叉查找在一定的复杂度内获取到相应数据，从而快速的检索出符合条件的记录。</p>
<p>一般来说索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上</p>
<blockquote>
<p>我们平常所说的索引，如果没有特别指明，都是指B树(多路搜索树，并不-一定是二叉的)结构组织的索引。其中聚集索引，次要索引，覆盖索引，复合索引，前缀索引，唯一索引默认都是使用B+树索引，统称索引。当然，除了B+树这种类型的索引之外，还有哈稀索引等</p>
</blockquote>
<h3 id="2-2-2-优缺点"><a href="#2-2-2-优缺点" class="headerlink" title="2.2.2 优缺点"></a>2.2.2 优缺点</h3><p>优点：</p>
<ul>
<li>提高数据检索的效率，降低数据库的IO成本；</li>
<li>通过索引对数据进行排序，降低数据排序的成本，降低了CPU的消耗</li>
</ul>
<p>缺点：</p>
<ul>
<li>实际上索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录，所以索引列也是要占用空间的</li>
<li>虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。<br>因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件每次更新添加了索引列的字段，都会调整因为更新所带来的键值变化后的索引信息</li>
</ul>
<p>索引只是提高效率的一个因素，如果你的MySQL有大数据量的表，就需要花时间研究建立最优秀的索引，</p>
<h3 id="2-2-3-索引分类和索引结构"><a href="#2-2-3-索引分类和索引结构" class="headerlink" title="2.2.3 索引分类和索引结构"></a>2.2.3 索引分类和索引结构</h3><ul>
<li>唯一索引：索引列的值必须唯一，但允许有空值</li>
<li>聚集索引(聚簇索引；主键索引)：数据行的<strong>物理顺序与列值（一般是主键的那一列）的逻辑顺序相同</strong>，一个表中只能拥有一个聚集索引。<ul>
<li>一个没加主键的表，它的数据<strong>无序</strong>的放置在磁盘存储器上</li>
<li>如果给表上了主键，那么表在磁盘上的存储结构就由整齐排列的结构转变成了<strong>树状结构</strong>，也就是<strong>平衡树结构</strong>，换句话说，就是整个表就变成了一个索引，也就是所谓的<strong>聚集索引</strong>。</li>
</ul>
</li>
<li>非聚集索引(常规索引)：该索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同，一个表中可以拥有多个非聚集索引。</li>
</ul>
<blockquote>
<p>聚集索引和非聚集索引的主要区别</p>
</blockquote>
<ul>
<li>通过聚集索引可以一次查到需要查找的数据， 而通过非聚集索引第一次只能查到记录对应的主键值 ， 再使用主键的值通过聚集索引查找到需要的数据。</li>
<li>聚集索引一张表只能有一个，而非聚集索引一张表可以有多个。</li>
</ul>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220102223400062.png" alt="image-20220102223400062"></p>
<p>索引结构：</p>
<ul>
<li>Btree索引</li>
<li>Hash索引</li>
<li>Full-test全文索引</li>
<li>R-Tree索引</li>
</ul>
<blockquote>
<p> 何时创建索引</p>
</blockquote>
<ol>
<li>主键自动建立唯一索引</li>
<li>频繁作为查询条件的字段应该创建索引</li>
<li>查询中与其它表关联的字段，外键关系建立索引</li>
<li>Where条件里用不到的字段不创建索引</li>
<li>单键/组合索引的选择问题，</li>
<li>查询中排序的字段，排序字段若通过索引去访问将大大提高排序速度</li>
<li>查询中统计或者分组的字段</li>
</ol>
<blockquote>
<p>何时不能创建索引</p>
</blockquote>
<ol>
<li>表记录太少(三百万以下)</li>
<li>频繁更新的字段不适合创建索引，因为每次更新不单单是更新了记录还会更新索引</li>
<li>数据重复且分布平均的表字段，因此应该只为最经常查询和最经常排序的数据列建立索引。注意，如果某个数据列包含许多重复的内容，为它建立索引就没有太大的实际效果</li>
</ol>
<p>​    假如一个表有10万行记录，有一个字段A只有T和F两种值，且每个值的分布概率天约为50%，那么对这种表A字段建索引一般不会提高数据库的查询速度。<br>​    索引的选择性是指索引列中不同值的数目与表中记录数的比。如果一个表中有2000条记录，表索引列有1980个不同的值，那么这个索引的选择性就是1980/2000=0.99。一个索引的选择性越接近于1，这个索引的效率就越高。</p>
<h2 id="2-3-性能分析"><a href="#2-3-性能分析" class="headerlink" title="2.3 性能分析"></a>2.3 性能分析</h2><p>MySQL常见瓶颈：</p>
<ul>
<li>CPU:CPU在饱和的时候一般发生在数据装入内存或从磁盘上读取数据时候</li>
<li>IO:磁盘I/O瓶颈发生在装入数据远大于内存容量的时候</li>
<li>服务器硬件的性能瓶颈:top,free, iostat和vmstat来查看系统的性能状态</li>
</ul>
<h3 id="2-3-1-Explain"><a href="#2-3-1-Explain" class="headerlink" title="2.3.1 Explain"></a>2.3.1 Explain</h3><p>使用EXPLAIN关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理你的SQL语句的。分析查询语句或是表结构的性能瓶颈</p>
<blockquote>
<p>能做什么</p>
</blockquote>
<ul>
<li>表的读取顺序</li>
<li>数据读取操作的操作类型</li>
<li>哪些索引可以使用</li>
<li>哪些索引被实际使用</li>
<li>表之间的引用</li>
<li>每张表有多少行被优化器查询</li>
</ul>
<blockquote>
<p>用法</p>
</blockquote>
<p>EXPLAIN + SQL语句</p>
<p>可以查出如下信息</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220103141528903.png" alt="image-20220103141528903"></p>
<p>各字段解释：</p>
<ul>
<li><p><strong>id</strong>：</p>
<p>​    id相同：</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220103142049370.png" alt="image-20220103142049370"></p>
<ul>
<li><p>执行顺序由上至下</p>
<p>id不同：</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220103142414802.png" alt="image-20220103142414802"></p>
</li>
<li><p>如果是子查询，那么id的序号会递增，id值越大，优先级越高，越先被执行</p>
<p>id有的相同有的不同</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220103142535963.png" alt="image-20220103142535963"></p>
</li>
<li><p>id如果相同，可以认为是一组，从上往下顺序执行;在所有组中，id值越大，优先级越高，越先执行</p>
<ul>
<li>DERIVED = 衍生，derived2就是id为2的那个衍生表</li>
</ul>
</li>
</ul>
</li>
<li><p>select_type</p>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220103143007337.png" alt="image-20220103143007337" style="zoom:50%;" />

<ul>
<li>SIMPLE：简单的select查询,查询中不包含子查询或者UNION</li>
<li>PRIMARY：查询中若包含任何复杂的子部分,最外层查询则被标记为</li>
<li>SUBQUERY：在SELECT或WHERE列表中包含了子查询</li>
<li>DERIVED：在FROM列表中包含的子查询被标记为DERIVED(衍生)，MySQL会递归执行这些子查询,把结果放在临时表里。</li>
<li>UNION：若第二个SELECT出现在UNION之后,则被标记为UNION，若UNION包含在FROM子句的子查询中,外层SELECT将被标记为:DERIVED</li>
<li>UNION RESULT：从UNION表获取结果的SELECT</li>
</ul>
</li>
<li><p>table：数据来自于哪张表</p>
</li>
<li><p><strong>type</strong>：显示查询使用了哪种类型</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220103143455879.png" alt="image-20220103143455879"></p>
<ul>
<li>从最好到最差：system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null&gt; unique_subquert &gt; index_subquert &gt; range &gt; index &gt; ALL</li>
<li>==常用：system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL，一般来说，得保证查询至少达到range级别，最好ref级别==</li>
<li>system：表只有一行记录（等于系统表)，这是const类型的特列，平时不会出现，这个也可以忽略不计</li>
<li>constant：表示通过索引一次就找到了,const用于比较primary key或者unique索引。因为只匹配一行数据，所以很悦如将主键置于where列表中，MySQL就能将该查询转换为一个常量</li>
<li>eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描</li>
<li>ref：非唯一性索引扫描,返回匹配某个单独值的所有行，本质上也是一种索引访问，它返回所有匹配某个单独值的行，然而，它可能会找到多个符合条件的行，所以他应该属于查找和扫描的混合体</li>
<li>range：只检索给定范围的行,使用一个索引来选择行。key 列显示使用了哪个索引一般就是在你的where语句中出现了between、&lt;、&gt;、in等的查询，这种范围扫描索引扫描比全表扫描要好，因为它只需要开始于索引的某一点，而结束语另一点，不用扫描全部</li>
<li>index：Full Index Scan，index与ALL区别为index类型只遍历索引树。这通常比ALL快，因为索引文件通常比数据文件小（也就是说虽然all和Index都是读全表，但index是从索引中读取的，而all是从硬盘中读的)</li>
<li>ALL：Full Table Scan，将遍历全表以找到匹配的行</li>
</ul>
</li>
<li><p>possible_keys：显示可能应用在这张表中的索引，一个或多个。查询涉及到的字段上若存在索引，则该索引将被列出，==但不一定被查询实际使用==，即可能使用到的索引</p>
</li>
<li><p>key：实际使用的索引。如果为NULL，则没有使用索引。查询中若使用了覆盖索引，则该索引和查询的select字段重叠</p>
</li>
<li><p>key_len：表示索引中使用的字节数，可炬过该列计算查询中使用的索引的长度。在不损失精确性的情况下，长度越短越好；key_len显示的值为索引字段的最大可能长度，==并非实际使用长度==，即key_len是根据表定义计算而得，不是通过表内检索出的</p>
</li>
<li><p>ref：显示索引的哪一列被使用了，如果可能的话，是一个常数。哪些列或常量被用于查找索引列上的值</p>
</li>
<li><p>rows：根据表统计信息及索引选用情况，大致估算出找到所需的记录所需要读取的行数</p>
</li>
<li><p><strong>Extra</strong>：包含不适合在其他列中显示但十分重要的额外信息</p>
<ul>
<li><p><strong>Using filesort</strong>：说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。MySQL中无法利用索引完成的排序操作称为”文件排序”</p>
</li>
<li><p><strong>Using temporary</strong>：使了用临时表保存中间结果,My5QL在对查询结果排序时使用临时表。常见于排序order by和分组查询group by</p>
</li>
<li><p><strong>Using index</strong>：表示相应的select操作中使用了覆盖索引(Covering Index)，避免访问了表的数据行，效率不错！如果同时出现using where，表明索引被用来执行索引键值的查找;如果没有同时出现using where，表明索引用来读取数据而非执行查找动作。</p>
<ul>
<li><p>覆盖索引(索引覆盖)：</p>
<p>理解方式一:就是select的数据列只用从索引中就能够取得，不必读取数据行，MySQL可以利用索引返回select列表中的字段，而不必根据索引再次读取数据文件,换句话说查询列要被所建的索引覆盖。</p>
<p>理解方式二:索引是高效找到行的一个方法，但是一般数据库也能使用索引找到一个列的数据，因此它不必读取整个行。毕竟索引叶子节点存储了它们索引的数据;当能通过读取索引就可以得到想要的数据，那就不需要读取行了。一个索引包含了(或覆盖了)满足查询结果的数据就叫做覆盖索引。</p>
</li>
</ul>
</li>
<li><p>Using Where：表明使用了Where过滤</p>
</li>
<li><p>Using Join buffer：使用了连接缓存</p>
</li>
<li><p>impossible where：Where子句的值总是false，不能用来获取任何元组</p>
</li>
<li><p>select tables optimized away：在没有GROUPBY子句的情况下，基于索引优化MIN/MAX操作或者对于MyISAM存储引擎优化COUNT(*)操作,不必等到执行阶段再进行计算,查询执行计划生成的阶段即完成优化。</p>
</li>
<li><p>distinct：优化distinct操作，在找到第一匹配的元组后即停止找同样值的动作。</p>
</li>
</ul>
</li>
</ul>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220105161058285.png" alt="image-20220105161058285"></p>
<h2 id="2-4-单表案例"><a href="#2-4-单表案例" class="headerlink" title="2.4 单表案例"></a>2.4 单表案例</h2><p><strong>案例查询语句</strong>：SELECT id ,author_id FROM article WHERE category_id = 1 AND comments &gt; 1 ORDER BY views DESC LIMIT 1;</p>
<blockquote>
<p>无索引，EXPLAIN：</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220105165523730.png" alt="image-20220105165523730"></p>
<p>type为ALL，全表搜索，Extra中出现Using filesort运行时排序。效率极差</p>
<blockquote>
<p>建立索引：INDEX(category_id , comments , views)</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220105165715532.png" alt="image-20220105165715532"></p>
<p>type从ALL优化到了range，但这样设置索引后仍然在Extra中发现了Using filesort</p>
<p>如果把comments &gt; 1改为 comments = 1，则Using filesort消失</p>
<p>==这是因为“大于“属于range，他以及其后的索引则会失效==</p>
<blockquote>
<p>建立索引：INDEX(category_id , views)</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220105165958861.png" alt="image-20220105165958861"></p>
<p>type从range优化为了ref，Using filesort也消失</p>
<h2 id="2-5-两表案例"><a href="#2-5-两表案例" class="headerlink" title="2.5 两表案例"></a>2.5 两表案例</h2><p>结论：</p>
<ul>
<li>左连接时，为右表添加索引。这是由左连接特性决定的。LEFT JOIN条件用于确定如何从右表搜索行,左边一定都有，所以右边是我们的关键点，一定需要建立索引</li>
<li>右连接时，与左连接情况相反</li>
</ul>
<h2 id="2-6-三表案例"><a href="#2-6-三表案例" class="headerlink" title="2.6 三表案例"></a>2.6 三表案例</h2><p>类比两表案例情况</p>
<ul>
<li>尽可能的减少Join 语句中NestedLoop的循环总次数；“永远用小结果集驱动大的结果集”。</li>
<li>优先优化NestedLoop的内层循环</li>
<li>保证Join语句中被驱动表上Join条件字段已经被索引</li>
<li>当无法保证被驱动表的Join条件字段被索引且内存资源充足的前提下，不要太吝惜JoinBuffer的设置</li>
</ul>
<h2 id="2-7-索引失效"><a href="#2-7-索引失效" class="headerlink" title="2.7 索引失效"></a>2.7 索引失效</h2><ol>
<li><p>尽可能的使用全值匹配</p>
</li>
<li><p>最佳左前缀法则：如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始并且<strong>不跳过索引中的列.</strong> (左边大哥不能死，中间兄弟不能断)</p>
</li>
<li><p>不在索引列上做任何操作(计算、函数、(自动or手动)类型转换)，会导致索引失效而转向全表扫描</p>
</li>
<li><p>存储引擎不能使用索引中范围条件右边的列</p>
</li>
<li><p>尽量使用覆盖索引(只访问索引的查询(索引列和查询列一致))，减少SELECT *</p>
</li>
<li><p>MySQL在使用不等于(!= 或者&lt;&gt;)时无法使用索引，会导致全表扫描</p>
</li>
<li><p>is null，is not null 也无法使用索引</p>
</li>
<li><p>like以通配符开头(‘%abc…’)mysql索引失效会变成全表扫描的操作</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220106125532068.png" alt="image-20220106125532068"></p>
<ul>
<li>Like最好是在右边加 百分号(%)</li>
<li>解决like %字符串% 索引失效的方法：覆盖索引</li>
</ul>
</li>
<li><p>字符串不加单引号索引失效：根本原因是，MySQL底层会隐式的进行类型转换，见第3点</p>
</li>
<li><p> 少用or，用它来连接会索引失效</p>
</li>
</ol>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107122949240.png" alt="image-20220107122949240"></p>
<ul>
<li><p>排序字段已经是一个常量时，order by的索引乱序可以不用using filesort</p>
</li>
<li><p>定值、范围还是排序，一般order by是给个范围group by基本上都需要进行排序，会有临时表产生</p>
</li>
</ul>
<h2 id="2-8-一般性建议"><a href="#2-8-一般性建议" class="headerlink" title="2.8 一般性建议"></a>2.8 一般性建议</h2><ul>
<li>对于单键索引，尽量选择针对当前query过滤性更好的索引、</li>
<li>在选择组合索引的时候，当前Query中过滤性最好的字段在索引字段顺序中，位置越靠左越好。</li>
<li>在选择组合索引的时候，尽量选择可以能够包含当前query中的where字句中更多字段的索引</li>
<li>尽可能通过分析统计信息和调整query的写法来达到选择合适索引的目的</li>
</ul>
<h1 id="三、查询截取优化"><a href="#三、查询截取优化" class="headerlink" title="三、查询截取优化"></a>三、查询截取优化</h1><h2 id="3-1-查询优化"><a href="#3-1-查询优化" class="headerlink" title="3.1 查询优化"></a>3.1 查询优化</h2><h3 id="3-1-1-永远小表驱动大表"><a href="#3-1-1-永远小表驱动大表" class="headerlink" title="3.1.1 永远小表驱动大表"></a>3.1.1 永远小表驱动大表</h3><p>即小的数据集驱动大的数据集</p>
<p>原理：</p>
<ul>
<li>EXISTS：SELECT … FROM table WHERE EXISTS (subquery)<ul>
<li>该语法可以理解为：将主查询的数据，放到子查询中做条件验证，根据验证结果(TRUE或FALSE)来决定主查询的数据结果是否得以保留。</li>
</ul>
</li>
<li>提示：<ol>
<li>EXISTS(subquery)只返回TRUE或FALSE，因此子查询中的SELECT *也可以是SELECT 1或其他(SELECT ‘X’)，官方说法是实际执行时会忽略SELECT清单，因此没有区别</li>
<li>EXISTS 子查询的实际执行过程可能经过了优化而不是我们理解上的逐条对比，如果担心效率问题，可进行实际校验以确定是否有效率问题</li>
<li>EXISTS子查询往往也可以用条件表达式、其他子查询或者JOIN来题代，何种最优需要具体问题具体分析。</li>
</ol>
</li>
</ul>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107125109912.png" alt="image-20220107125109912"></p>
<p>当B表的数据集必须小于A表的数据集时，用in优于exists</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107125144884.png" alt="image-20220107125144884"></p>
<p>当A表的数据集必须小于B表的数据集时，用exists优于in</p>
<p><em>A表和B表的id都应当建立索引</em></p>
<h3 id="3-1-2-Order-By优化"><a href="#3-1-2-Order-By优化" class="headerlink" title="3.1.2 Order By优化"></a>3.1.2 Order By优化</h3><blockquote>
<p>1、 ORDER BY 子句，尽量使用Index方式排序，避免使用FileSort方式排序</p>
</blockquote>
<ul>
<li>默认是升序排序。如果出现ASC则FileSort<ul>
<li>均为DESC则不会导致索引失效</li>
</ul>
</li>
<li>Order By覆盖索引，且最左法则，则Index。<ul>
<li>ORDER BY语句使用索引最左前列</li>
<li>使用where子句与Order BY子句条件列组合满足索引最左前列</li>
</ul>
</li>
</ul>
<p>MySQL支持二种方式的排序,FileSort和lIndex，Index效率高.它指MySQL扫描索引本身完成排序。FileSort方式效率较低。</p>
<blockquote>
<p>2、 尽可能在索引列上完成排序操作，遵照索引建的最佳左前缀</p>
</blockquote>
<blockquote>
<p>3、 如果不在索引列上，FileSort有两种算法：MySQL就要启动双路排序和单路排序</p>
</blockquote>
<ul>
<li>双路排序：MySQL 4.1 之前使用的是双路排序，字面意思就是<strong>两次扫描磁盘</strong>，最终得到数据，读取行指针和order by列，对他们进行排序，然后扫描已经排序好的列表，按照列表中的值重新从列表中读取对应的数据输出</li>
</ul>
<p>取一批数据，要对磁盘进行了两次扫描，众所周知，TO是很耗时的，所以在mysq/4.1之后，出现了第二种改进的算法，就是单路排序。</p>
<ul>
<li>单路排序：从磁盘读取查询需要的所有列，按照order by列在buffer对它们进行排序，然后扫描排序后的列表进行输出，它的效率更快一些，避免了第二次读取数据。并且把随机I0变成了顺序I0,但是它会使用更多的空间，因为它把每一行都保存在内存中了。</li>
</ul>
<p>单路总体而言好于双路，但是使用单路会出现一个问题：</p>
<p>在sort_buffer中，方法B比方法A要多占用很多空间，因为方法B是把所有字段都取出,所以有可能取出的数据的总大小超出了sort_buffer的容量，导致每次只能取sort_buffer容量大小的数据，进行排序（创建tmp文件，多路合并），排完再取取sort_buffer容量大小,再排…..从而多次IO。</p>
<p>本来想省一次I/O操作,反而导致了大量的I/O操作，反而得不偿失。</p>
<blockquote>
<p>优化策略</p>
</blockquote>
<ol>
<li>增大sort_buffer_size参数的设置<ul>
<li>不管用哪种算法，提高这个参数都会提高效率，当然，要根据系统的能力去提高，因为这个参数是针对每个进程的</li>
</ul>
</li>
<li>增大max_length_for_sort_data参数的设置<ul>
<li>提高这个参数，会增加用改进算法的概率。但是如果设的太高，数据总容量超出sort_buffer_size的概率就增大，明显症状是高的磁盘I/O活动和低的处理器使用率.</li>
</ul>
</li>
<li>Order by时select*是一个大忌只Query需要的字段，这点非常重要。在这里的影响是:<ul>
<li>当Query的字段大小总和小于max_length_for_sort_data而且排序字段不是TEXTIBLOB类型时，会用改进后的算法一一单路排序，否则用老算法——多路排序。</li>
<li>两种算法的数据都有可能超出sort_buffer的容量，超出之后，会创建tmp文件进行合并排序，导致多次IO，但是用单路排序算法的风险会更大一些,所以要提高sort buffer size。</li>
</ul>
</li>
</ol>
<h3 id="3-1-3-Group-By优化"><a href="#3-1-3-Group-By优化" class="headerlink" title="3.1.3 Group By优化"></a>3.1.3 Group By优化</h3><p>趋同于Order By的优化</p>
<ul>
<li>group by实质是先排序后进行分组,遵照索引建的最佳左前缀</li>
<li>当无法使用索引列，增大max_length_for_sort_data参数的设置+增大sort_buffer_size参数的设置</li>
<li>where高于having，能写在where限定的条件就不要去having限定了。</li>
</ul>
<h2 id="3-2-慢查询日志"><a href="#3-2-慢查询日志" class="headerlink" title="3.2 慢查询日志"></a>3.2 慢查询日志</h2><blockquote>
<p>是什么</p>
</blockquote>
<ul>
<li>MySQL的慢查询日志是MySQL提供的一种日志记录，它用来记录在MySQL中响应时间超过阀值的语句，具体指运行时间超过long_query_time值的SQL，则会被记录到慢查询日志中。</li>
<li>具体指运行时间超过long_query_time值的SQL，则会被记录到慢查询日志中。long_query_time的默认值为10，意思是运行10秒以上的语句。</li>
</ul>
<p>由他来查看哪些SQL超出了我们的最大忍耐时间值，比如一条sql执行超过5秒钟，我们就算慢SQL，希望能收集超过5秒的sql，结合explain进行全面分析。</p>
<blockquote>
<p>使用方式</p>
</blockquote>
<p>默认情况下，MySQL数据库没有开启慢查询日志，需要我们手动来设置这个参数。如果不是调优需要的话，一般不建议启动该参数，因为开启慢查询日志会带来一定的性能影响。慢查询日志支持将日志记录写入文件。</p>
<pre><code class="sql"># 默认
SHOW VARIABLES LIKE &#39;%slow_query_log%&#39;;
# 开启,如果MySQL重启，则会自动关闭
SET GLOBAL slow_query_log = 1;
# 永久生效需要修改配置文件：my.cnf
# 查看阙值
SHOW VARIABLES LIKE &#39;long_query_time%&#39;;
# 设置慢的阙值时间：
SET GLOBAL long_query_time = s;
-- 修改后看不到值被修改
-- 需要重新连接或新开一个会话才能看到修改值。
-- SHOW VARIABLES LIKE &#39;long_query_time%&quot;;
-- show global variables like &#39;long_query_time&#39;;
</code></pre>
<p>关于慢查询的参数slow_query_log_file，它指定慢查询日志文件的存放路径，系统默认会给一个缺省的文件host_name-slow.log</p>
<p>假如运行时间正好等于long_query_time的情况，并不会被记录下来。在mysql源码里是判断大于long_query_time，而非大于等于。</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107151121735.png" alt="image-20220107151121735"></p>
<blockquote>
<p>日志分析工具 mysqldumpslow</p>
</blockquote>
<p>在生产环境中，如果要手工分析日志，查找、分析SQL，显然是个体力活，MySQL提供了日志分析工具mysqldumpslow。</p>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107151456717.png" alt="image-20220107151456717" style="zoom: 67%;" />

<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107151530203.png" alt="image-20220107151530203" style="zoom: 58%;" />



<h2 id="3-3-批量数据脚本案例"><a href="#3-3-批量数据脚本案例" class="headerlink" title="3.3 批量数据脚本案例"></a>3.3 批量数据脚本案例</h2><p>案例：查入1000w</p>
<blockquote>
<p>1、建库建表</p>
</blockquote>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107152514152.png" alt="image-20220107152514152" style="zoom: 50%;" />

<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107152807131.png" alt="image-20220107152807131" style="zoom:50%;" />

<blockquote>
<p>2、设置参数log_bin_trust_function_creators</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107153001546.png" alt="image-20220107153001546"></p>
<blockquote>
<p>3、创建函数，保证每条数据不同</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107153313111.png" alt="image-20220107153313111"></p>
<blockquote>
<p> 4、创建存储过程</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107154644751.png" alt="image-20220107154644751"></p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107154809445.png" alt="image-20220107154809445"></p>
<blockquote>
<p>5、 调用存储过程</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107155948779.png" alt="image-20220107155948779"></p>
<h2 id="3-4-Show-Profile"><a href="#3-4-Show-Profile" class="headerlink" title="3.4 Show Profile"></a>3.4 Show Profile</h2><p>是mysql提供可以用来分析当前会话中语句执行的资源消耗情况。可以用于sQL的调优的测量</p>
<p>默认情况下，参数处于关闭状态，并保存最近15次的运行结果</p>
<p>分析步骤：</p>
<ol>
<li><p>是否支持，查看当前MySQL版本是否支持</p>
<pre><code class="sql">SHOW VARIABLES LIKE &#39;profiling&#39;;
</code></pre>
</li>
<li><p>开启功能，默认是关闭的。</p>
<pre><code class="sql">SET profiling=on;
</code></pre>
</li>
<li><p>运行SQL</p>
</li>
<li><p>查看结果</p>
<pre><code class="sql">show profiles;
</code></pre>
</li>
<li><p>诊断SQL</p>
<pre><code class="sql">Show Profile cpu,block io for query (Show profiles中问题SQL数字号码，即Query_ID)
</code></pre>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107162418663.png" alt="image-20220107162418663"></p>
</li>
</ol>
<blockquote>
<p>应该要注意的点</p>
</blockquote>
<ul>
<li>converting HEAP to MyISAM查询结果太大，内存都不够用了往磁盘上搬了。</li>
<li>Creating tmp table创建临时表<ul>
<li>拷贝数据到临时表</li>
<li>用完再删除</li>
</ul>
</li>
<li>Copying to tmp table on disk把内存中临时表复制到磁盘，危险！！</li>
<li>locked</li>
</ul>
<h2 id="3-5-全局查询日志"><a href="#3-5-全局查询日志" class="headerlink" title="3.5 全局查询日志"></a>3.5 全局查询日志</h2><p>==只能用于测试环境，切不可用于线上环境==</p>
<p>启用方式：</p>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107163034508.png" alt="image-20220107163034508" style="zoom:67%;" />

<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107163049327.png" alt="image-20220107163049327"></p>
<h1 id="四、锁机制"><a href="#四、锁机制" class="headerlink" title="四、锁机制"></a>四、锁机制</h1><p>锁是计算机协调多个进程或线程并发访问某一资源的机制。</p>
<p>在数据库中，除传统的计算资源（如CPU、RAM、V/O等）的争用以外，数据也是一种供许多用户共享的资源。如何保证数据并发访问的一致性、有效性是所有数据库必须解决的一个问题，锁冲突也是影响数据库并发访问性能的一个重要因素。从这个角度来说，锁对数据库而言显得尤其重要，也更加复杂。</p>
<h2 id="4-0-SELECT-…-FOR-UPDATE"><a href="#4-0-SELECT-…-FOR-UPDATE" class="headerlink" title="4.0 SELECT … FOR UPDATE"></a>4.0 SELECT … FOR UPDATE</h2><p>FOR UPDATE 仅适用于InnoDB，且必须在事务区块(BEGIN/COMMIT)中才能生效。</p>
<p>使用select…for update会把数据给锁住，MySQL InnoDB默认Row-Level Lock，所以只有「明确」地指定主键，MySQL 才会执行Row lock (只锁住被选取的数据) ，否则MySQL 将会执行Table Lock (将整个数据表单给锁住)。</p>
<ul>
<li>例1: (明确指定主键，并且有此数据，row lock)</li>
</ul>
<p>SELECT * FROM products WHERE id=’3’ FOR UPDATE;</p>
<ul>
<li>例2: (明确指定主键，若查无此数据，无lock)</li>
</ul>
<p>SELECT * FROM products WHERE id=’-1’ FOR UPDATE;</p>
<ul>
<li>例2: (无主键，table lock)</li>
</ul>
<p>SELECT * FROM products WHERE name=’Hansious’ FOR UPDATE;</p>
<ul>
<li>例3: (主键不明确，table lock)</li>
</ul>
<p>SELECT * FROM products WHERE id&lt;&gt;’3’ FOR UPDATE;</p>
<ul>
<li>例4: (主键不明确，table lock)</li>
</ul>
<p>SELECT * FROM products WHERE id LIKE ‘3’ FOR UPDATE;</p>
<h2 id="4-1-锁的分类"><a href="#4-1-锁的分类" class="headerlink" title="4.1 锁的分类"></a>4.1 锁的分类</h2><p><em>更详细可参考[附录D](#附录D LBCC)</em></p>
<blockquote>
<p>从对数据操作的类型(读/写)分</p>
</blockquote>
<ul>
<li>读锁(共享锁)：针对同一份数据，多个读操作可以同时进行而不会相互影响</li>
<li>写锁(排他锁)：当前写操作没有完成前，他会阻断其他写锁和读锁</li>
</ul>
<blockquote>
<p>从对数据操作的粒度分</p>
</blockquote>
<ul>
<li>表锁</li>
<li>行锁</li>
</ul>
<h2 id="4-2-表锁-偏读"><a href="#4-2-表锁-偏读" class="headerlink" title="4.2 表锁(偏读)"></a>4.2 表锁(偏读)</h2><p>特点：</p>
<ul>
<li>偏向MyISAM存储引擎，开销小，加锁快;</li>
<li>无死锁;</li>
<li>锁定粒度大，发生锁冲突的概率最高,并发度最低</li>
</ul>
<blockquote>
<p>加锁</p>
</blockquote>
<pre><code class="sql"># 查看锁
Show open tables;
# 加读锁
lock table [表名] read;
# 加写锁
lock table [表名] write;
# 释放锁
unlock tables;
</code></pre>
<ul>
<li>施加读锁时<ul>
<li>自己可以读自己的锁定表，别人可以读自己的加锁表</li>
<li>自己和别人都 不可以修改加锁表，自己修改会报错，别人修改会堵塞</li>
<li>自己不可以读自己的非加锁表，别人可以读自己的非加锁表</li>
</ul>
</li>
<li>施加写锁时<ul>
<li>自己可以读自己的锁定表；别人<strong>不</strong>可以读自己的加锁表，会阻塞</li>
<li>自己可以修改加锁表；别人不可以修改加锁表</li>
<li>自己不可以读自己的非加锁表；别人可以读自己的非加锁表</li>
</ul>
</li>
</ul>
<ol>
<li>对MyISAM表的读操作〈加读锁)，不会阻塞其他进程对同一表的读请求，但会阻塞对同一表的写请求。只有当读锁释放后，才会执行其它进程的写操作。</li>
<li>对MyISAM表的写操作（加写锁)，会阻塞其他进程对同一表的读和写操作，只有当写锁释放后，才会执行其它进程的读写操作。</li>
</ol>
<blockquote>
<p>锁分析</p>
</blockquote>
<pre><code class="sql">SHOW Status like &#39;table%&#39;
</code></pre>
<p>这里有两个状态变量记录MySQL内部表级锁定的情况，两个变量说明如下:</p>
<ul>
<li>Table_locks_immediate:产生表级锁定的次数，表示可以立即获取锁的查询次数，每立即获取锁值加1 ;</li>
<li>Table_locks waited:出现表级锁定争用而发生等待的次数(不能立即获取锁的次数，每等待一次锁值加1)，此值高则说明存在着较严重的表级锁争用情况;</li>
</ul>
<p>此外，Myisam的读写锁调度是写优先，这也是myisam不适合做写为主表的引擎。因为写锁后，其他线程不能做任何操作，大量的更新会使查询很难得到锁，从而造成永远阻塞</p>
<h2 id="4-3-行锁-偏写"><a href="#4-3-行锁-偏写" class="headerlink" title="4.3 行锁(偏写)"></a>4.3 行锁(偏写)</h2><p>特点：</p>
<ul>
<li>偏向InnoDB存储引擎，开销大，加锁慢;</li>
<li>会出现死锁;</li>
<li>锁定粒度最小，发生锁冲突的概率最低,并发度也最高。</li>
</ul>
<p>InnoDB与MyISAM的最大不同有两点:一是支持事务（TRANSACTION)﹔二是采用了行级锁</p>
<blockquote>
<p>误操作导致无索引行锁升级为表锁</p>
</blockquote>
<p>索引失效，如varchar必须加单引号等</p>
<blockquote>
<p>间隙锁的危害</p>
</blockquote>
<p>当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁;对于键值在条件范围内但并不存在的记录，叫做“间隙”，</p>
<p>InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁(Next-Key锁)。</p>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107212921332.png" alt="image-20220107212921332" style="zoom:80%;" />

<p>没有a = 2，产生间隙</p>
<pre><code class="sql">INSERT INTO test_innodb_lock values(2,&#39;2000&#39;);
</code></pre>
<p>session1 commit之前，session2会被阻塞</p>
<ul>
<li>因为Query执行过程中通过过范围查找的话，他会锁定整个范围内所有的索引键值，<strong>即使这个键值并不存在。</strong></li>
<li>间隙锁有一个比较致命的弱点，就是当锁定一个范围键值之后，即使某些不存在的键值也会被无辜的锁定，而造成在锁定的时候无法插入锁定键值范围内的任何数据。在某些场景下这可能会对性能造成很大的危害</li>
</ul>
<blockquote>
<p>如何锁定一行</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107213257876.png" alt="image-20220107213257876"></p>
<blockquote>
<p>锁分析</p>
</blockquote>
<pre><code class="sql">Show status like &#39;innodb_row_lock%&#39;;
</code></pre>
<ul>
<li>lnnodb_row_lock_current_waits:当前正在等待锁定的数量;</li>
<li>Innodb_row_lock_time:从系统启动到现在锁定总时间长度;</li>
<li>Innodb_row_lock_time_avg:每次等待所花平均时间;</li>
<li>Innodb_row_lock_time_max:从系统启动到现在等待最常的一次所花的时间;</li>
<li>Innodb_row_lock_waits:系统启动后到现在总共等待的次数;</li>
</ul>
<p>对于这5个状态变量，比较重要的主要是:</p>
<ul>
<li>Innodb_row_lock_time_avg (等待平均时长)，</li>
<li>Innodb_row_lock_waits(等待总次数)</li>
<li>Innodb_row_lock_time(等待总时长)</li>
</ul>
<p>这三项。尤其是当等待次数很高，而且每次等待时长也不小的时候，我们就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手指定优化计划。</p>
<h2 id="4-4-页锁"><a href="#4-4-页锁" class="headerlink" title="4.4 页锁"></a>4.4 页锁</h2><p>特点：</p>
<ul>
<li>开销和加锁时间界于表锁和行锁之间;</li>
<li>会出现死锁;</li>
<li>锁定粒度界于表锁和行锁之间，并发度一般</li>
</ul>
<h2 id="4-5-锁优化建议"><a href="#4-5-锁优化建议" class="headerlink" title="4.5 锁优化建议"></a>4.5 锁优化建议</h2><ul>
<li>尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁。</li>
<li>合理设计索引，尽量缩小锁的范围</li>
<li>尽可能较少检索条件，避免间隙锁</li>
<li>尽量控制事务大小,减少锁定资源量和时间长度</li>
<li>尽可能低级别事务隔离</li>
</ul>
<h1 id="五、主从复制"><a href="#五、主从复制" class="headerlink" title="五、主从复制"></a>五、主从复制</h1><h2 id="5-1-原理"><a href="#5-1-原理" class="headerlink" title="5.1 原理"></a>5.1 原理</h2><p>slave会从master读取binlog来进行数据同步</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107215916362.png" alt="image-20220107215916362"></p>
<ol>
<li>master将改变记录到二进制日志(binary log)。这些记录过程叫做二进制日志事件，binary log events;</li>
<li>slave将master的binary log events拷贝到它的中继日志(relay log）；</li>
<li>slave重做中继日志中的事件，将改变应用到自己的数据库中。MySQL复制是异步的且串行化的</li>
</ol>
<blockquote>
<p>复制的基本原则</p>
</blockquote>
<ul>
<li>每个slave只有一个master</li>
<li>每个slave只能有一个唯一的服务器ID</li>
<li>每个master可以有多个salve</li>
</ul>
<blockquote>
<p>复制的最大问题</p>
</blockquote>
<p>延时</p>
<h2 id="5-2-一主一从配置案例"><a href="#5-2-一主一从配置案例" class="headerlink" title="5.2 一主一从配置案例"></a>5.2 一主一从配置案例</h2><ol>
<li><p>MySQL版本尽量一致，版本号前两段必须相同。同时互相必须能ping通</p>
</li>
<li><p>主机修改配置文件</p>
<ol>
<li><strong>必须:</strong> 主服务器唯一ID：server-id=1</li>
<li><strong>必须：</strong>启用二进制日志：log-bin = 本地路径/mysqlbin</li>
<li>启用错误日志：log-err = 本地路径/mysqlerr</li>
<li>根目录：basedir = “本地路径”</li>
<li>临时目录：tmpdir = “本地路径”</li>
<li>数据目录：datadir = “本地路径/Data”</li>
<li>read-only = 0 ,代表主机读写都可以</li>
<li>设置不要复制的数据库：binlog-ignore-db = 数据库名列表</li>
<li>设置需要复制的数据库：binlog-do-db = 数据库名列表</li>
</ol>
</li>
<li><p>从机修改配置文件</p>
<ol>
<li><strong>必须:</strong> 从机服务器唯一ID ：service-id = 2</li>
<li>[建议] 启用二进制日志</li>
</ol>
</li>
<li><p>重启主从机MySQL数据库</p>
</li>
<li><p>主从机关闭防火墙</p>
</li>
<li><p>在<strong>主机</strong>上建立账户并授权slave</p>
<ol>
<li><pre><code class="sql">GRANT REPLICATION SLAVE ON *.* TO &#39;账户名&#39;@&#39;从机数据库IP&#39; IDENTIFIED BY &#39;账户密码&#39;;
flush privileges; # 刷新
SHOW master status; # 查询Master的状态，并记录下File和Position的值！
</code></pre>
</li>
<li><p>操作完上述步骤后，不再操作主服务器MySQL，防止主服务器状态值变化</p>
</li>
</ol>
</li>
<li><p>在<strong>从机</strong>上配置需要复制的主机</p>
<ol>
<li><pre><code class="sql"># 登录主机账户
CHANGE MASTER TO MASTER_HOST=&#39;主机IP&#39;,
MASTER_USER=&#39;账户名&#39;,
MASTER_PASSWORD=&#39;账户密码&#39;,
MASTER_LOG_FILE=&#39;6.1步骤中记录下的File值&#39;,
MASTER_LOG_POS=&#39;6.1步骤中记录下的Position值&#39;;
# 启动从服务器复制功能
START SLAVE;
</code></pre>
</li>
<li><p>使用<code>Show slave status\G</code>命令，若<code>Slave_IO_Running:Yes</code>且<code>Slave_SQL_Running:Yes</code>则主从配置成功</p>
</li>
</ol>
</li>
<li><p>停止从服务复制功能：<code>stop slave;</code></p>
</li>
</ol>
<p>7.2 中可能出现某一项不为Yes，解决方法：</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220107223918622.png" alt="image-20220107223918622"></p>
<h1 id="附录A-MySQL文件结构"><a href="#附录A-MySQL文件结构" class="headerlink" title="附录A MySQL文件结构"></a>附录A MySQL文件结构</h1><p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220101131308574.png" alt="image-20220101131308574"></p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220101131534062.png" alt="image-20220101131534062"></p>
<ul>
<li>二进制日志log-bin :主从复制</li>
<li>错误日志log-error：默认是关闭的,记录严玉的警告和告误信息，每次启动和关闭的详细信息等。</li>
<li>查询日志log：默认关闭，记录查询的sql语句，如果开启会减低mysql的整体性能，因为记录日志也是需要消耗系统资源的</li>
<li>数据文件<ul>
<li>位置：<ul>
<li>windows data日录下可以祧选很多库</li>
<li>linux 默认路径:fvarflibfmysql</li>
</ul>
</li>
<li>frm文件 ：存放表结构</li>
<li>myd文件：存放表数据</li>
<li>myi文件：存放表索引</li>
</ul>
</li>
<li>配置文件<ul>
<li>windows：my.ini文件</li>
<li>Linux：/etc/my.cnf文件</li>
</ul>
</li>
</ul>
<h1 id="附录B-MySQL的隔离级别"><a href="#附录B-MySQL的隔离级别" class="headerlink" title="附录B MySQL的隔离级别"></a>附录B MySQL的隔离级别</h1><p>==在读懂本案例的前提是，你已经明白了事务是什么，下述的问题都出现在一个事务当中，而不是某次操作==</p>
<ol>
<li>读未提交（READ UNCOMMITTED）</li>
<li>读提交 （READ COMMITTED）</li>
<li>可重复读 （REPEATABLE READ）</li>
<li>串行化 （SERIALIZABLE）</li>
</ol>
<p>从上往下，隔离强度逐渐增强，性能逐渐变差。采用哪种隔离级别要根据系统需求权衡决定，其中，<strong>可重复读</strong>是 MySQL 的默认级别。</p>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220327102850878.png" alt="image-20220327102850878" style="zoom:67%;" />

<p>只有串行化的隔离级别解决了全部这 3 个问题，其他的 3 个隔离级别都有缺陷。</p>
<h2 id="1、读未提交"><a href="#1、读未提交" class="headerlink" title="1、读未提交"></a>1、读未提交</h2><p>MySQL 事务隔离其实是依靠锁来实现的，加锁自然会带来性能的损失。而<strong>读未提交隔离级别是不加锁的</strong>，所以它的性能是最好的，没有加锁、解锁带来的性能开销。但有利就有弊，这基本上就相当于裸奔啊，所以它连脏读的问题都没办法解决。</p>
<p>任何事务对数据的修改都会第一时间暴露给其他事务，即使事务还没有提交。</p>
<p>读未提交，其实就是可以读到其他事务未提交的数据，但没有办法保证你读到的数据最终一定是提交后的数据，<strong>如果中间发生回滚，那就会出现脏数据问题</strong>，读未提交没办法解决脏数据问题。</p>
<h2 id="2、读提交"><a href="#2、读提交" class="headerlink" title="2、读提交"></a>2、读提交</h2><p>既然读未提交没办法解决脏数据问题，那么就有了读提交。读提交就是一个事务只能读到其他事务已经提交过的数据，也就是其他事务调用 commit 命令之后的数据。</p>
<p>读提交事务隔离级别是大多数流行数据库的默认事务隔离界别，比如 Oracle，但是不是 MySQL 的默认隔离界别。</p>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220327103136736.png" alt="image-20220327103136736" style="zoom:50%;" />

<p>每个 select 语句都有自己的一份快照，而不是一个事务一份，所以在不同的时刻，查询出来的数据可能是不一致的。即本案例事务B中，前两个 SELECT 和第三个的查询结果是不一致的</p>
<p>读提交解决了脏读的问题，但是无法做到可重复读，也没办法解决幻读。</p>
<h2 id="3、可重复读"><a href="#3、可重复读" class="headerlink" title="3、可重复读"></a>3、可重复读</h2><p>可重复是对比不可重复而言的，不可重复读是指同一事物不同时刻读到的数据值可能不一致。而可重复读是指，<strong>事务不会读到其他事务对已有数据的修改，即使其他事务已提交</strong>，也就是说，事务开始时读到的已有数据是什么，在事务提交前的任意时刻，这些数据的值都是一样的。但是，对于其他事务新插入的数据是可以读到的，这也就引发了幻读问题</p>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220327103522717.png" alt="image-20220327103522717" style="zoom:50%;" />

<p>可重复读做到了，这只是针对已有行的更改操作有效，但是对于新插入的行记录，幻读就产生了</p>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220327103903244.png" alt="image-20220327103903244" style="zoom:50%;" />

<p>在事务A commit之前，第二个SELECT读到的数据比第一次SELECT多一条数据！</p>
<h2 id="4、串行化"><a href="#4、串行化" class="headerlink" title="4、串行化"></a>4、串行化</h2><p>串行化是4种事务隔离级别中隔离效果最好的，解决了脏读、可重复读、幻读的问题，但是效果最差，它将事务的执行变为顺序执行，与其他三个隔离级别相比，它就相当于单线程，后一个事务的执行必须等待前一个事务结束。<strong>效率极低</strong></p>
<h1 id="附录C-MVCC"><a href="#附录C-MVCC" class="headerlink" title="附录C MVCC"></a>附录C MVCC</h1><p>==为了解决不可重复读，或者为了实现可重复读，MySQL 采用了 MVCC (Multi-Version Concrrent Control多版本并发控制) 的方式。==</p>
<p>它的实现原理主要是<strong>版本链，undo日志 ，Read View</strong></p>
<p>我们在数据库表中看到的<strong>一行记录可能实际上有多个版本</strong>，每个版本的记录除了有数据本身外，还要有一个表示版本的字段，记为<code>row trx_id</code>，而这个字段就是使其产生的事务的 id，事务 ID 记为 <code>transaction id</code>，它在事务开始的时候向事务系统申请，按时间先后顺序递增。</p>
<ul>
<li><strong>6字节的事务ID(DB_TRX_ID)字段</strong>：用来标识最近一次对本行记录做修改(insert|update)的事务的标识符，即最后一次修改(insert|update)本行记录的事务id。至于delete操作，在innodb看来也不过是一次update操作，更新行中的一个特殊位将行表示为deleted，并非真正删除。</li>
<li><strong>7字节的回滚指针(DB_ROLL_PTR)字段</strong>：指写入回滚段(rollback segment)的 undo log record (撤销日志记录记录)。如果一行记录被更新, 则 undo log record 包含 ‘重建该行记录被更新之前内容’ 所必须的信息。</li>
<li><strong>6字节的DB_ROW_ID字段</strong>：包含一个随着新行插入而单调递增的行ID，当由innodb自动产生聚集索引时，聚集索引会包括这个行ID的值，否则这个行ID不会出现在任何索引中。</li>
</ul>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220327105002757.png" alt="image-20220327105002757" style="zoom:50%;" />

<p><strong>快照</strong>，学名叫做<strong>一致性视图</strong>，这也是可重复读和不可重复读的关键，可重复读是在事务开始的时候生成一个当前事务全局性的快照，而读提交则是每次执行语句的时候都重新生成一次快照。</p>
<p>对于一个快照来说，它能够读到那些版本数据，要遵循以下规则：</p>
<ol>
<li>当前事务内的更新，可以读到；</li>
<li>版本未提交，不能读到；</li>
<li>版本已提交，但是却在快照创建后提交的，不能读到；</li>
<li>版本已提交，且是在快照创建前提交的，可以读到；</li>
</ol>
<ul>
<li><p>快照读：读取的是快照版本，也就是历史版本。简单的select操作(不包括 select … lock in share mode, select … for update)</p>
</li>
<li><p>当前读：读取的是最新版本。UPDATE、DELETE、INSERT、SELECT …  LOCK IN SHARE MODE、SELECT … FOR UPDATE是当前读。</p>
</li>
</ul>
<h1 id="附录D-LBCC"><a href="#附录D-LBCC" class="headerlink" title="附录D LBCC"></a>附录D LBCC</h1><p>与附录C相对，LBCC (Lock-Based Concrrent Control)是基于锁的并发控制。如果仅仅是基于锁来实现事务隔离，一个事务读取的时候不允许其他时候修改，那 就意味着不支持并发的读写操作，而我们的大多数应用都是读多写少的，这样会极大地 影响操作数据的效率。</p>
<ul>
<li>锁定力度：表锁 &gt; 行锁</li>
<li>加锁效率：表锁 &gt; 行锁</li>
<li>冲突概率：表锁 &gt; 行锁</li>
<li>并发性能：表锁 &lt; 行锁</li>
</ul>
<p>innodb的行锁是通过给索引项加锁实现的,这就意味着只有通过<strong>索引</strong>条件检索数据时,innodb才使用行锁,否则使用表锁。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html">官方八锁</a></p>
</blockquote>
<ul>
<li>乐观锁、互斥锁(共享和独占/排他 锁)(Shard and Exclusive Locks, 行级锁)</li>
<li>意向锁(Intention Locks, 表级锁)</li>
<li>记录锁/行锁 (Record Locks, 行级锁)</li>
<li>间隙锁 (Gap Locks, 行级锁)</li>
<li>临键锁 (Next-key Locksl, 行级锁) (Record Locks + Gap Locks )</li>
<li>插入意向锁(Insert Intention Locks, 行级锁)</li>
<li>自增锁(AUTO-INC Locks, 表级锁)</li>
<li>空间索引的谓词锁 </li>
</ul>
<h2 id="D1-Shard-And-Exclusive-Locks"><a href="#D1-Shard-And-Exclusive-Locks" class="headerlink" title="D1 Shard And Exclusive Locks"></a>D1 Shard And Exclusive Locks</h2><p>行级锁定,其中有两种类型的锁：共享锁、独占锁</p>
<ul>
<li>共享(S)锁允许持有锁的事务读取一行。</li>
<li>排他(X)锁允许持有锁的事务更新或删除行</li>
</ul>
<p>如果事务<code>T1</code>在行<code>r</code>上持有共享(<code>S</code>)锁，则来自某些不同事务<code>T2</code>的对行<code>r</code>的锁请求将按以下方式处理：</p>
<ul>
<li><code>T2</code>对<code>S</code>锁定的请求可以立即获得批准。结果，<code>T1</code>和<code>T2</code>都在<code>r</code>上保持<code>S</code>锁定。</li>
<li><code>T2</code>对<code>X</code>锁定的请求无法立即获得批准。</li>
</ul>
<p>如果事务<code>T1</code>在行<code>r</code>上拥有排他(<code>X</code>)锁，则不能立即批准来自某个不同事务<code>T2</code>的对<code>r</code>上任一类型的锁的请求。相反，事务<code>T2</code>必须 await 事务<code>T1</code>释放对行<code>r</code>的锁定。</p>
<h2 id="D2-Intention-Locks"><a href="#D2-Intention-Locks" class="headerlink" title="D2 Intention Locks"></a>D2 Intention Locks</h2><p><strong>InnoDB 支持多重粒度，它允许行锁和表锁并存,意向锁是一种不与行级锁冲突表级锁</strong>。例如，<code>LOCK TABLES ... WRITE</code> 之类的语句在指定的table上具有排他锁。为了使在多个粒度级别上的锁定切实可行，<code>InnoDB</code>使用意向锁(Intention Locks)。==意向锁是 table 级锁==，指示事务稍后对 table 中的行需要哪种类型的锁(共享锁或排他锁)。</p>
<p>加意向锁的目的是为了表明某个事务正在锁定一行或者将要锁定一行。</p>
<p>当一个事务在需要获取资源的锁定时，如果该资源已经被排他锁占用，则数据库会自动给该事务申请一个该表的意向锁。如果自己需要一个共享锁定，就申请一个<strong>意向共享锁</strong>。如果需要的是某行（或者某些行）的排他锁定，则申请一个<strong>意向排他锁</strong>。</p>
<p>有两种类型的意图锁：</p>
<ul>
<li><p>意向共享锁(IS) 表示事务打算对table中的各个行设置共享锁</p>
<pre><code class="sql">-- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。
SELECT column FROM table ... LOCK IN SHARE MODE; 
</code></pre>
</li>
<li><p>意向排他锁(IX) 表示事务打算对table中的各个行设置排他锁</p>
<pre><code class="sql">-- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。
SELECT column FROM table ... FOR UPDATE; 
</code></pre>
</li>
</ul>
<p>意向锁是有数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享 / 排他锁之前，InooDB 会先获取该数据行所在在数据表的对应意向锁。</p>
<p>意向锁定协议：</p>
<ul>
<li>在事务可以获取 table 中某行的共享锁之前，它必须首先获取该 table 中的<code>IS</code>锁或更强的锁。</li>
<li>在事务可以获取 table 中某行的排它锁之前，它必须首先获取该 table 中的<code>IX</code>锁。</li>
</ul>
<blockquote>
<p>兼容性</p>
</blockquote>
<table>
<thead>
<tr>
<th></th>
<th><code>X</code></th>
<th><code>IX</code></th>
<th><code>S</code></th>
<th><code>IS</code></th>
</tr>
</thead>
<tbody><tr>
<td><code>X</code></td>
<td>冲突</td>
<td>冲突</td>
<td>冲突</td>
<td>冲突</td>
</tr>
<tr>
<td><code>IX</code></td>
<td>冲突</td>
<td>兼容</td>
<td>冲突</td>
<td>兼容</td>
</tr>
<tr>
<td><code>S</code></td>
<td>冲突</td>
<td>冲突</td>
<td>兼容</td>
<td>兼容</td>
</tr>
<tr>
<td><code>IS</code></td>
<td>冲突</td>
<td>兼容</td>
<td>兼容</td>
<td>兼容</td>
</tr>
</tbody></table>
<blockquote>
<p>举例</p>
</blockquote>
<p>事务A锁住表中的一行(写锁)</p>
<p>事务B锁住整个表(写锁)</p>
<ul>
<li>出现的问题：事务A既然锁住了某一行，其他事务就不可能修改这一行。这与”事务B锁住整个表就能修改表中的任意一行“形成了冲突。所以，没有意向锁的时候，行锁与表锁共存就会存在问题！！</li>
</ul>
<p>使用意向锁后，事务A在申请行锁（写锁）之前，数据库会自动先给事务A申请表的意向排他锁。当事务B去申请表的写锁时就会失败，因为表上有意向排他锁之后事务B申请表的写锁时会被阻塞。</p>
<p>事务 A 获取了某一行的排他锁，并未提交：</p>
<pre><code class="sql">SELECT * FROM users WHERE id = 6 FOR UPDATE;
</code></pre>
<p>此时 users 表存在两把锁：</p>
<ol>
<li>users 表上的<strong>意向排他锁</strong></li>
<li>id 为 6 的数据行上的<strong>排他锁</strong>。</li>
</ol>
<p>事务 B 想要获取 users 表的共享锁(表级)：</p>
<pre><code class="sql">LOCK TABLES users READ;
</code></pre>
<p>此时事务 B 检测事务 A 持有 users 表的<strong>意向排他锁</strong>，就可以得知事务 A 必然持有该表中某些数据行的<strong>排他锁</strong>，那么事务 B 对 users 表的加锁请求就会被排斥（阻塞），而无需去检测表中的每一行数据是否存在排他锁。</p>
<p>最后事务 C 也想获取 users 表中某一行的排他锁：</p>
<pre><code class="sql">SELECT * FROM users WHERE id = 5 FOR UPDATE;
</code></pre>
<ol>
<li>事务 C 申请 users 表的<strong>意向排他锁</strong>。</li>
<li>事务 C 检测到事务 A 持有 users 表的<strong>意向排他锁</strong>。</li>
<li>因为意向锁之间并不互斥，所以事务 C 获取到了 users 表的<strong>意向排他锁</strong>。</li>
<li>因为id 为 5 的数据行上不存在任何<strong>排他锁</strong>，最终事务 C 成功获取到了该数据行上的<strong>排他锁</strong>。</li>
</ol>
<h2 id="D3-Record-Locks"><a href="#D3-Record-Locks" class="headerlink" title="D3 Record Locks"></a>D3 Record Locks</h2><p>==InnoDB三种行锁算法之一==。单个行记录上的锁。</p>
<p>记录锁是对索引记录的锁定（<strong>行锁</strong>）。例如，<code>SELECT c1 FROM t WHERE c1 = 10 FOR UPDATE;</code>阻止任何其他事务插入，更新或删除<code>t.c1</code>的值为<code>10</code>的行。</p>
<p>记录锁始终锁定索引记录，即使没有定义索引的 table 也是如此。在这种情况下，<code>InnoDB</code>将创建一个隐藏的聚集索引，并将该索引用于记录锁定。</p>
<h2 id="D4-Gap-Locks"><a href="#D4-Gap-Locks" class="headerlink" title="D4 Gap Locks"></a>D4 Gap Locks</h2><p>==InnoDB三种行锁算法之一==。目的是为了防止同一事务的两次当前读，出现幻读的情况。</p>
<p>间隙锁是对索引记录之间的间隙的锁定，或者是对第一个或最后一个索引记录之前的间隙的锁定。例如，<code>SELECT c1 FROM t WHERE c1 BETWEEN 10 and 20 FOR UPDATE;</code>防止其他事务将<code>15</code>的值插入到<code>t.c1</code>列中，无论该列中是否已经有这样的值，因为该范围中所有现有值之间的间隙都被锁定。</p>
<p>间隙可能跨越单个索引值，多个索引值，甚至为空。间隙锁是性能和并发性之间权衡的一部分，并且在某些事务隔离级别而非其他级别中使用。</p>
<p><strong>值得注意的是</strong>：对于使用唯一索引来锁定唯一行来锁定行的语句，不需要间隙锁定。例如，如果<code>id</code>列具有唯一索引，则以下语句仅使用具有<code>id</code>值 100 的行的索引记录锁，其他会话是否在前面的间隙中插入行都没有关系：</p>
<pre><code class="sql">SELECT * FROM child WHERE id = 100;
</code></pre>
<p>如果<code>id</code>未构建索引或索引不唯一，则该语句会锁定前面的间隙。即锁定(- ∞ ，100]的行</p>
<p>如果将事务隔离级别更改为READ COMMITTED，将禁用间隙锁定进行搜索和索引扫描，并且仅将其用于外键约束检查和重复键检查。</p>
<h2 id="D5-Next-Key-Locks"><a href="#D5-Next-Key-Locks" class="headerlink" title="D5 Next-Key Locks"></a>D5 Next-Key Locks</h2><p>==InnoDB三种行锁算法之一==。对于行的查询，都是采用该方法，innodb默认的锁就是Next-Key locks。主要目的是解决幻读的问题。</p>
<p>临键锁 是索引记录上的记录锁(行锁)和索引记录之前的间隙上的间隙锁定的组和 </p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220328203808540.png" alt="image-20220328203808540"></p>
<h2 id="D6-Insert-Intention-Locks"><a href="#D6-Insert-Intention-Locks" class="headerlink" title="D6 Insert Intention Locks"></a>D6 Insert Intention Locks</h2><p>插入意图锁是一种在行插入之前通过 INSERT 操作设置的间隙锁定。此锁发出插入意图的 signal 是，如果多个事务未插入间隙中的相同位置，则无需 await 彼此插入的多个事务。假设有索引记录，其值分别为 4 和 7.单独的事务分别尝试插入值 5 和 6，在获得插入行的排他锁之前，每个事务都使用插入意图锁来锁定 4 和 7 之间的间隙，但不要互相阻塞，因为行是无冲突的。</p>
<p>插入意向锁本质上可以看成是一个<code>Gap Lock</code></p>
<ul>
<li>普通的Gap Lock 不允许 在 （上一条记录，本记录） 区间范围内插入数据。</li>
<li>插入意向锁Gap Lock 允许 在 （上一条记录，本记录） 区间范围内插入数据。</li>
</ul>
<p>插入意向锁的作用是为了<strong>提高并发插入的性能</strong>， 多个事务 同时写入 不同数据 至同一索引范围（区间）内，并不需要等待其他事务完成，不会发生锁等待。</p>
<blockquote>
<p>举例</p>
</blockquote>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody><tr>
<td align="center">Time</td>
<td align="center">会话A</td>
<td align="center">会话B</td>
</tr>
<tr>
<td align="center">1</td>
<td align="center">begin</td>
<td align="center">begin</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">select * from a where a&lt;=13 for update</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">3</td>
<td align="center"></td>
<td align="center">insert into a values (12)<br/>– waiting…… （被阻塞了，在这里等待）</td>
</tr>
<tr>
<td align="center">4</td>
<td align="center">commit</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">5</td>
<td align="center"></td>
<td align="center">输出：Query OK, 1 row affected<br/>前提条件：insert操作的锁没有超时</td>
</tr>
</tbody></table>
<p>此时事务B插入成功但是还未commit，再执行<code>show engine innodb status\G</code>语句，会有以下输出：</p>
<pre><code class="sql">---TRANSACTION 4425, ACTIVE 26 sec
2 lock struct(s), heap size 1136, 1 row lock(s), undo log entries 1
MySQL thread id 3, OS thread handle 140018685810432, query id 247 localhost root
TABLE LOCK table `test`.`a` trx id 4425 lock mode IX

RECORD LOCKS space id 37 page no 3 n bits 72 index PRIMARY of table `test`.`a` trx id 4425 lock_mode X locks gap before rec insert intention

Record lock, heap no 4 PHYSICAL RECORD: n_fields 3; compact format; info bits 0
 0: len 4; hex 8000000d; asc     ;;
 1: len 6; hex 000000001140; asc      @;;
 2: len 7; hex b400000128011c; asc     (  ;;
</code></pre>
<p>从上面的输出可以看到在记录13 上面加了一把插入意图锁（<code>lock_mode X locks gap before rec insert intention</code>）。</p>
<p>获得插入意图锁之后，我们就可以在11-13之间并发插入记录，而不需要一个事物等待另一事物，当所有相关的插入的事物都提交后， 13上的插入意向锁 便会释放。</p>
<p>假如没有插入意向锁，而是用普通的间隙锁。插入数据时会获取这条记录所在区间的间隙锁及这条记录的排它锁，其他事务是不可能在这个区间内插入数据的，因为当前事务已经获取了这个区间内的间隙锁，其他事务无法获取对应记录的排它锁，只能等待其他事务完成；</p>
<p>用插入意向锁后，数据库设计插入意向锁与排它锁不互斥。多个事务既可以获取对应区间的插入意向锁也可以获取对应记录的排它锁，各个事务互不影响，不需要等待其他事务完成后才能进行插入。</p>
<h2 id="D7-AUTO-INC-Locks"><a href="#D7-AUTO-INC-Locks" class="headerlink" title="D7 AUTO-INC Locks"></a>D7 AUTO-INC Locks</h2><p>在InnoDB中，每个含有自增列的表都有一个自增长计数器。当对含有自增长计数器的表进行插入时，首先会执行<code>select max(auto_inc_col) from t for update</code>来得到计数器的值，然后再将这个值加1赋予自增长列。我们将这种方式称之为<code>AUTO_INC Lock</code></p>
<p><code>AUTO-INC</code>锁是一种特殊的 table 级锁，由事务插入具有<code>AUTO_INCREMENT</code>列的 table 中获得。在最简单的情况下，如果一个事务正在向 table 中插入值，那么任何其他事务都必须 await 自己在该 table 中进行插入，以便第一个事务插入的行接收连续的主键值。</p>
<p>从MySQL 5.1.22开始，InnoDB中提供了一种轻量级互斥量的自增长实现机制，同时InnoDB存储引擎提供了一个参数<code>innodb_autoinc_lock_mode</code>来控制自增长的模式，进而提高自增长值插入的性能。<code>innodb_autoinc_lock_mode</code>和插入类型有关</p>
<p>innodb_autoinc_lock_mode值:</p>
<p><strong>innodb_autoinc_lock_mode = 0 传统模式</strong>，所有的插入语句在开始的时候都需要先获取自增锁，语句结束之后才释放自增自增锁，最安全但并发性最差。</p>
<p><strong>innodb_autoinc_lock_mode = 1 连续模式</strong>，InnoDB 中默认的方式，该模式对于可预测插入行数的插入进行了优化，一次可以批量生成连续的值。</p>
<p><strong>innodb_autoinc_lock_mode = 2 交错模式</strong>，在这种锁定模式下，没有使用表级的自增锁，因此它的速度是最快的。但是该模式下并不能保证生成的值是连续，因此在主从复制或数据恢复的时候，主键可能与之前产生的不一致。</p>
<p>插入类型：</p>
<ul>
<li><p>“INSERT-like” statements</p>
<p>泛指所有的插入语句, 它包括 “simple-inserts”, “bulk-inserts”, 和 “mixed-mode inserts”.</p>
</li>
<li><p>“Simple inserts”</p>
<p>插入的记录行数是确定的：比如：insert into values，replace<br>但是不包括： INSERT … ON DUPLICATE KEY UPDATE.</p>
</li>
<li><p>“Bulk inserts”</p>
<p>插入的记录行数不能马上确定的，比如： INSERT … SELECT, REPLACE … SELECT, and LOAD DATA</p>
</li>
<li><p>“Mixed-mode inserts”</p>
<p>这些都是simple-insert，但是部分auto increment值给定或者不给定. 例子如下(where <code>c1</code> is an <code>AUTO_INCREMENT</code> column of table <code>t1</code>):</p>
<pre><code class="sql">INSERT INTO t1 (c1,c2) VALUES (1,&#39;a&#39;), (NULL,&#39;b&#39;), (5,&#39;c&#39;), (NULL,&#39;d&#39;);
</code></pre>
<p>另外一种 “mixed-mode insert” 就是 <code>INSERT ... ON DUPLICATE KEY UPDATE</code></p>
</li>
</ul>
<h2 id="D8-Predicate-Locks-for-Spatial-Indexes"><a href="#D8-Predicate-Locks-for-Spatial-Indexes" class="headerlink" title="D8 Predicate Locks for Spatial Indexes"></a>D8 Predicate Locks for Spatial Indexes</h2><p>在多维空间数据中，没有绝对排序的概念，因此之前引入的间隙锁机制不能有效的处理空间数据的数据隔离。为此 InnoDB 中引入了空间索引谓词锁的机制，空间索引采用的是R-Tree 数据结构实现，空间索引包含了最小矩形边界的数据(MBR)，因此 InnoDB 可以通过在 MBR 上加谓词锁来保证一致性读。</p>
<blockquote>
<p>优化空间分析</p>
</blockquote>
<p>对于<code>MyISAM</code>和<code>InnoDB</code>table，可以使用<code>SPATIAL</code>索引优化包含空间数据的列中的搜索操作。最典型的操作是：</p>
<ul>
<li>点查询，搜索包含给定点的所有对象</li>
<li>区域查询搜索与给定区域重叠的所有对象</li>
</ul>
<p>MySQL 对空间列上的<code>SPATIAL</code>索引使用具有二次分裂的 R 树。使用几何的最小边界矩形(MBR)构建<code>SPATIAL</code>索引。对于大多数几何图形，MBR 是围绕几何图形的最小矩形。对于水平或垂直线串，MBR 是退化为线串的矩形。对于一个点，MBR 是退化为该点的矩形。</p>
<p>也可以在空间列上创建普通索引。在非<code>SPATIAL</code>索引中，必须为除<code>POINT</code>列之外的任何空间列声明前缀。</p>
<h1 id="附录E-B树、B-树和B-树"><a href="#附录E-B树、B-树和B-树" class="headerlink" title="附录E B树、B+树和B*树"></a>附录E B树、B+树和B*树</h1><p>传统用来搜索的平衡二叉树有很多，如 AVL 树，红黑树等。这些树在一般情况下查询性能非常好，但当数据非常大的时候它们就无能为力了。原因是当数据量非常大时，内存不够用，大部分数据只能存放在磁盘上，只有需要的数据才加载到内存中。一般而言内存访问的时间约为 50 ns，而磁盘在 10 ms 左右。速度相差了近 5 个数量级，磁盘读取时间远远超过了数据在内存中比较的时间。这说明程序大部分时间会阻塞在磁盘 IO 上。减少磁盘 IO 次数，像 AVL 树，红黑树这类平衡二叉树从设计上无法“迎合”磁盘。</p>
<p>B的全程是Blance，平衡的意思</p>
<ul>
<li>B/B- 树：多路搜索树，每个节点存储M/2到M个关键字，非叶子节点存储指向关键字范围的子节点；所有关键字在整棵树中出现，并且只出现一次，非叶子节点可以命中。每个节点只存储一个关键字，等于则命中，小于走左节点，大于走右节点</li>
<li>B+树：在B-树的基础上，为叶子节点增加链表指针，所有关键字都在叶子节点中出现，非叶子节点作为叶子节点的索引；B+树总时到叶子节点才命中。</li>
<li>B*树：在B+树的基础上，为非叶子节点也增加链表指针，将节点的最低利用率从1/2提高到2/3</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.cs.usfca.edu/~galles/visualization/BTree.html">B树模拟</a></p>
<h2 id="E1-B-B-树"><a href="#E1-B-B-树" class="headerlink" title="E1 B/B- 树"></a>E1 B/B- 树</h2><p>B类树是平衡树，每个结点到叶子结点的高度都是相同，这也保证了每个查询是稳定的，查询的时间复杂度是log2(n)；其次是构造一个多阶B类树，然后在尽量多的在结点上存储相关的信息，保证层数尽量的少，以便后面我们可以更快的找到信息；<br><strong>总结：利用平衡树的优势加快查询的稳定性和速度。</strong></p>
<p>一个 m 阶的B树满足以下条件：</p>
<ol>
<li>定义任意非叶子结点最多只有M个儿子；且M&gt;2；</li>
<li>根结点的儿子数为[2, M]；</li>
<li>除根结点以外的非叶子结点的儿子数为[M/2, M]；</li>
<li>每个结点存放至少M/2-1（取上整）和至多M-1个关键字；（至少2个关键字）</li>
<li>非叶子结点的关键字个数=指向儿子的指针个数-1；</li>
<li>非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] &lt; K[i+1]；</li>
<li>非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树；</li>
<li>所有叶子结点位于同一层；</li>
</ol>
<blockquote>
<p>插入流程</p>
</blockquote>
<ul>
<li>如果该结点的关键字个数没有到达m-1个，那么直接插入即可；</li>
<li>如果该结点的关键字个数已经到达了m-1个，那么根据B树的性质显然无法满足，需要将其进行分裂。<ul>
<li>分裂的规则是该结点分成两半，将中间的关键字进行提升，加入到父亲结点中，但是这又可能存在父亲结点也满员的情况，则不得不向上进行回溯，甚至是要对根结点进行分裂，那么整棵树都加了一层。</li>
</ul>
</li>
</ul>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220329173242591.png" alt="image-20220329173242591" style="zoom: 33%;" />



<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220329173326184.png" alt="image-20220329173326184" style="zoom:33%;" />

<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220329173341294.png" alt="image-20220329173341294" style="zoom:33%;" />



<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220329173352093.png" alt="image-20220329173352093" style="zoom:33%;" />

<blockquote>
<p>删除流程</p>
</blockquote>
<p>同样的，我们需要先通过搜索找到相应的值，存在则进行删除，需要考虑删除以后的情况，</p>
<ul>
<li>如果该结点拥有关键字数量仍然满足B树性质，则不做任何处理；</li>
<li>如果该结点在删除关键字以后不满足B树的性质（关键字没有到达ceil(m/2)-1的数量），则需要向兄弟结点借关键字，这有分为兄弟结点的关键字数量是否足够的情况。<ul>
<li>如果兄弟结点的关键字足够借给该结点，则过程为将父亲结点的关键字下移，兄弟结点的关键字上移；</li>
<li>如果兄弟结点的关键字在借出去以后也无法满足情况，即之前兄弟结点的关键字的数量为ceil(m/2)-1，借的一方的关键字数量为ceil(m/2)-2的情况，那么我们可以将该结点合并到兄弟结点中，合并之后的子结点数量少了一个，则需要将父亲结点的关键字下放，如果父亲结点不满足性质，则向上回溯；</li>
</ul>
</li>
<li>其余情况参照BST中的删除。</li>
</ul>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220329185544139.png" alt="image-20220329185544139" style="zoom: 50%;" />

<p><strong>索引的效率依赖与磁盘 IO 的次数，快速索引需要有效的减少磁盘 IO 次数</strong>，如何快速索引呢？索引的原理其实是不断的缩小查找范围，就如我们平时用字典查单词一样，先找首字母缩小范围，再第二个字母等等。平衡二叉树是每次将范围分割为两个区间。为了更快，<strong>B-树每次将范围分割为多个区间，区间越多，定位数据越快越精确。那么如果节点为区间范围，每个节点就较大了</strong>。</p>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220329190949543.png" alt="image-20220329190949543" style="zoom:67%;" />



<p>B-树的搜索，从根结点开始，对结点内的关键字（有序）序列进行二分查找，如果命中则结束，否则进入查询关键字所属范围的儿子结点；重复，直到所对应的儿子指针为空，或已经是叶子结点；</p>
<p>B-树的特性：</p>
<ol>
<li>关键字集合分布在整棵树中；</li>
<li>任何一个关键字出现且只出现在一个结点中；</li>
<li>搜索有可能在非叶子结点结束；</li>
<li>其搜索性能等价于在关键字全集内做一次二分查找；</li>
<li>自动层次控制；</li>
</ol>
<h2 id="E2-B-树"><a href="#E2-B-树" class="headerlink" title="E2 B+ 树"></a>E2 B+ 树</h2><p>B+树是B-树的变体，也是一种多路搜索树。</p>
<p>其定义基本与B-树同，除了：</p>
<ol>
<li>非叶子结点的子树指针与关键字个数相同；</li>
<li>非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树（B-树是开区间）；</li>
<li><strong>为所有叶子结点增加一个链指针；</strong></li>
<li><strong>所有关键字都在叶子结点出现；</strong></li>
</ol>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220329191140863.png" alt="image-20220329191140863" style="zoom:67%;" />

<p><strong>因为内节点并不存储 data，所以一般B+树的叶节点和内节点大小不同，而B-树的每个节点大小一般是相同的，为一页。</strong></p>
<blockquote>
<p>B+ 树和 B- 树的区别</p>
</blockquote>
<ul>
<li><p>B+树内节点不存储数据，所有 data 存储在叶节点导致查询时间复杂度固定为 log n。而B-树查询时间复杂度不固定，与 key 在树中的位置有关，最好为O(1)</p>
<p>如下：B-树/B+树查询节点 key 为 50 的 data</p>
<ul>
<li><p>B-树</p>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220329191428818.png" alt="image-20220329191428818" style="zoom:67%;" /></li>
<li><p>B+树</p>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220329191450289.png" alt="image-20220329191450289" style="zoom:67%;" /></li>
<li><p>key 为 50 的节点就在第一层，B-树只需要一次磁盘 IO 即可完成查找。<strong>由于B+树所有的 data 域都在根节点，所以查询 key 为 50的节点必须从根节点索引到叶节点，时间复杂度固定为 O(log n)。</strong></p>
</li>
</ul>
</li>
<li><p>B+树叶节点两两相连可大大增加区间访问性，可使用在范围查询等，而B-树每个节点 key 和 data 在一起，则无法区间查找。</p>
<ul>
<li><p>根据空间局部性原理：如果一个存储器的某个位置被访问，那么将它附近的位置也会被访问。</p>
</li>
<li><p>B+树可以很好的利用局部性原理，若我们访问节点 key为 50，则 key 为 55、60、62 的节点将来也可能被访问，<strong>我们可以利用磁盘预读原理提前将这些数据读入内存，减少了磁盘 IO 的次数。</strong></p>
</li>
</ul>
</li>
<li><p>B+树更适合外部存储。由于内节点无 data 域，每个节点能索引的范围更大更精确</p>
<p>由于B-树节点内部每个 key 都带着 data 域，而B+树节点只存储 key 的副本，真实的 key 和 data 域都在叶子节点存储。磁盘是分 block 的，一次磁盘 IO 会读取若干个 block，具体和操作系统有关，<strong>那么由于磁盘 IO 数据大小是固定的，在一次 IO 中，单个元素越小，量就越大</strong>。<strong>这就意味着B+树单次磁盘 IO 的信息量大于B-树</strong>，从这点来看B+树相对B-树磁盘 IO 次数少。</p>
</li>
</ul>
<h2 id="E3-B-树"><a href="#E3-B-树" class="headerlink" title="E3 B * 树"></a>E3 B * 树</h2><p><strong>是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针；</strong></p>
<p>B*树的分裂：当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针；</p>
<p>所以，B*树分配新结点的概率比B+树要低，空间使用率更高；</p>
<h2 id="E4-MySQL为什么使用B-Tree（B-Tree）"><a href="#E4-MySQL为什么使用B-Tree（B-Tree）" class="headerlink" title="E4 MySQL为什么使用B-Tree（B+Tree）"></a>E4 MySQL为什么使用B-Tree（B+Tree）</h2><p>上文说过，红黑树等数据结构也可以用来实现索引，但是文件系统及数据库系统普遍采用B-/+Tree作为索引结构。这需要结合计算机组成原理相关知识讨论B - /+Tree作为索引的理论基础。</p>
<p>一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，<strong>索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。</strong></p>
<blockquote>
<p>存储数据最小单元</p>
</blockquote>
<p>在计算机中磁盘存储数据最小单元是扇区，一个扇区的大小是512字节，而文件系统（例如XFS/EXT4）他的最小单元是块，一个块的大小是4k</p>
<p>InnoDB存储引擎也有自己的最小储存单元——页（Page），一个页的大小是16K(可以通过参数<code>innodb_page_size</code>设置)。</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220329194723833.png" alt="image-20220329194723833"></p>
<p>假设一行数据的大小是1k，那么一个页可以存放16行这样的数据。</p>
<blockquote>
<p>主存存取原理</p>
</blockquote>
<p>目前计算机使用的主存基本都是随机读写存储器（RAM），现代RAM的结构和存取原理比较复杂，这里抛却具体差别，抽象出一个十分简单的存取模型来说明RAM的工作原理。</p>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220329195045145.png" alt="image-20220329195045145" style="zoom: 25%;" />

<p>从抽象角度看，主存是一系列的存储单元组成的矩阵，每个存储单元存储固定大小的数据。每个存储单元有唯一的地址，现代主存的编址规则比较复杂，这里将其简化成一个二维地址：通过一个行地址和一个列地址可以唯一定位到一个存储单元。</p>
<p>主存的存取过程如下：</p>
<ol>
<li>当系统需要读取主存时，则将地址信号放到地址总线上传给主存，主存读到地址信号后，解析信号并定位到指定存储单元，然后将此存储单元数据放到数据总线上，供其它部件读取。</li>
<li>写主存的过程类似，系统将要写入单元地址和数据分别放在地址总线和数据总线上，主存读取两个总线的内容，做相应的写操作。</li>
<li>这里可以看出，主存存取的时间仅与存取次数呈线性关系，因为不存在机械操作，两次存取的数据的“距离”不会对时间有任何影响，例如，先取<code>A0</code>再取<code>A1</code>和先取<code>A0</code>再取<code>D3</code>的时间消耗是一样的。</li>
</ol>
<blockquote>
<p>磁盘存取原理</p>
</blockquote>
<p>索引一般以文件形式存储在磁盘上，索引检索需要磁盘I/O操作。与主存不同，磁盘I/O存在机械运动耗费，因此磁盘I/O的时间消耗是巨大的。</p>
<p>一个磁盘由大小相同且同轴的圆形盘片组成，磁盘可以转动（各个磁盘必须同步转动）。在磁盘的一侧有磁头支架，磁头支架固定了一组磁头，每个磁头负责存取一个磁盘的内容。磁头不能转动，但是可以沿磁盘半径方向运动（实际是斜切向运动），每个磁头同一时刻也必须是同轴的，即从正上方向下看，所有磁头任何时候都是重叠的（不过目前已经有多磁头独立技术，可不受此限制）。</p>
<p>盘片被划分成一系列同心环，圆心是盘片中心，每个同心环叫做一个磁道，所有半径相同的磁道组成一个柱面。磁道被沿半径线划分成一个个小的段，<strong>每个段叫做一个扇区，每个扇区是磁盘的最小存储单元</strong>。</p>
<p>当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点，磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，然后磁盘旋转将目标扇区旋转到磁头下，这个过程耗费的时间叫做旋转时间。</p>
<blockquote>
<p>局部性原理和磁盘预读</p>
</blockquote>
<p>由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是<strong>每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存</strong>。这样做的理论依据是计算机科学中著名的局部性原理：</p>
<ul>
<li><strong>当一个数据被用到时，其附近的数据也通常会马上被使用。程序运行期间所需要的数据通常比较集中。</strong></li>
</ul>
<p>由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。</p>
<p>预读的长度一般为页（page）的整倍数。<strong>页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k）</strong>，主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。</p>
<p><strong>所以IO一次就是读一页的大小</strong></p>
<h1 id="附录F-MySQL的在可重复读级别下幻读的解决方案"><a href="#附录F-MySQL的在可重复读级别下幻读的解决方案" class="headerlink" title="附录F MySQL的在可重复读级别下幻读的解决方案"></a>附录F MySQL的在可重复读级别下幻读的解决方案</h1><p>==解决办法：MySQL的间隙锁==</p>
<p>在数据库中会为索引维护一套B+树，用来快速定位行记录。B+索引树是有序的，所以会把这张表的索引分割成几个区间。</p>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220327104734292.png" alt="image-20220327104734292" style="zoom:33%;" />

<blockquote>
<p>案例</p>
</blockquote>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220327104616851.png" alt="image-20220327104616851" style="zoom:50%;" />

<p>本案例中，在事务A提交之前，事务B的插入操作只能等待，这就是间隙锁起得作用。</p>
<p>当事务A执行<code>update user set name=&#39;风筝2号’ where age = 10;</code> 的时候，由于条件 where age = 10 ，数据库不仅在 age =10 的行上添加了行锁，而且在这条记录的两边，也就是(负无穷,10]、(10,30]这两个区间加了间隙锁，从而导致事务B插入操作无法完成，只能等待事务A提交。</p>
<p>不仅插入 age = 10 的记录需要等待事务A提交，age&lt;10、10&lt;age&lt;30 的记录页无法完成，而大于等于30的记录则不受影响，这足以解决幻读问题了。</p>
<p><strong>值得注意的是</strong>：这是有索引的情况，如果 age 不是索引列，那么数据库会为整个表加上间隙锁。所以，如果是没有索引的话，不管 age 是否大于等于30，都要等待事务A提交才可以成功插入。</p>
<h1 id="附录G-MySQL中的日志"><a href="#附录G-MySQL中的日志" class="headerlink" title="附录G MySQL中的日志"></a>附录G MySQL中的日志</h1><ul>
<li><strong>undo log</strong>：是为回滚而用，具体内容就是copy事务前的数据库内容（行）到undo buffer，在适合的时间把undo buffer中的内容刷新到磁盘。<ul>
<li>undo buffer与redo buffer一样，也是环形缓冲，但当缓冲满的时候，undo buffer中的内容会也会被刷新到磁盘；</li>
<li>与redo log不同的是，磁盘上不存在单独的undo log文件，所有的undo log均存放在主ibd数据文件中（表空间），即使客户端设置了每表一个数据文件也是如此。</li>
</ul>
</li>
<li><strong>redo log</strong>：确保事务的持久性。redo日志记录事务执行后的状态，用来恢复未写入data file的已成功事务更新的数据。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。<ul>
<li>物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。</li>
</ul>
</li>
<li><strong>bin log</strong>：用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。用于数据库的基于时间点的还原。<ul>
<li>逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。而且还包括了执行的sql语句（增删改）反向的信息，也就意味着delete对应着delete本身和其反向的insert；update对应着update执行前后的版本的信息；insert对应着delete和insert本身的信息。</li>
</ul>
</li>
<li><strong>general query log</strong>：普通查询日志。记录了服务器接收到的每一个查询或是命令，无论这些查询或是命令是否正确甚至是否包含语法错误，general log 都会将其记录下来 ，记录的格式为 {Time ，Id ，Command，Argument }。Mysql默认是把General log关闭的。</li>
<li><strong>错误日志：</strong>记录着mysqld启动和停止,以及服务器在运行过程中发生的错误的相关信息。在默认情况下，系统记录错误日志的功能是关闭的，错误信息被输出到标准错误输出。</li>
<li><strong>慢查询日志：</strong>记录执行时间过长和没有使用索引的查询语句，报错select、update、delete以及insert语句，慢日志只会记录执行成功的语句。(在前面索引优化部分有讲解)</li>
</ul>
<h1 id="附录H-聚集索引和非聚集索引解析"><a href="#附录H-聚集索引和非聚集索引解析" class="headerlink" title="附录H 聚集索引和非聚集索引解析"></a>附录H 聚集索引和非聚集索引解析</h1><p><strong>聚集索引和非聚集索引的根本区别是表记录的排列顺序和与索引的排列顺序是否一致。</strong></p>
<h2 id="H1-聚集索引"><a href="#H1-聚集索引" class="headerlink" title="H1 聚集索引"></a>H1 聚集索引</h2><p>聚集索引表记录的排列顺序和索引的排列顺序一致(即索引的物理地址顺序和主键的逻辑顺序一致)，所以<strong>查询效率快</strong>，只要找到第一个索引值记录，其余就连续性的记录在物理也一样连续存放。聚集索引对应的缺点就是<strong>修改慢</strong>，因为为了保证表中记录的物理和索引顺序一致，在记录插入的时候，会对数据页重新排序。<strong>因为在物理内存中的顺序只能有一种，所以聚集索引在一个表中只能有一个</strong>。</p>
<h2 id="H2-非聚集索引"><a href="#H2-非聚集索引" class="headerlink" title="H2 非聚集索引"></a>H2 非聚集索引</h2><p>非聚集索引制定了表中记录的逻辑顺序，但是记录的物理和索引不一定一致（在逻辑上数据是按顺序排存放的，但是物理上在真实的存储器中是散列存放的），两种索引都采用B+树结构，<strong>非聚集索引的叶子层并不和实际数据页相重叠，而采用叶子层包含一个指向表中的记录在数据页中的指针方式。</strong>非聚集索引层次多，不会造成数据重排。所以如果表的读操作远远多于写操作，那么就可以使用非聚集索引。</p>
<h2 id="H3"><a href="#H3" class="headerlink" title="H3"></a>H3</h2>
            
        </div>
    </div>

    <div class="post-tags">
        
        <span class="icon">
            <a-icon type="tags" theme="filled" />
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/DBA" style=color:#ffa2c4>
                DBA
            </a>
        </span>
        
    </div>

    <a href="/2022/04/26/MySQL高级/ " class="go-post">
        阅读全文
    </a>
</div>

<div class="post">

    <a href="/2022/02/20/Java开发手册/">
        <h2>
            Java开发手册
        </h2>
    </a>

    <div class="category-and-date">

        

        <span class="date">
            <span class="icon">
                <a-icon type="calendar" theme="filled" />
            </span>
            2022/2/20
        </span>

    </div>

    <div class="excerpt">
        <div class="content" v-pre>
            
            
            <h1 id="零、前言"><a href="#零、前言" class="headerlink" title="零、前言"></a>零、前言</h1><p>@author：韩霄杰(hanxj_a)</p>
<p>@date: 2022.02.20</p>
<p>@update:2022.03.14 / 2022.03.15 / </p>
<ul>
<li>NPE即 NullPointerException</li>
<li>JSL即《The Java Language Specification》</li>
<li>OOM即OutOfMemoryError</li>
<li>CME即ConcurrentModificationException</li>
<li>JMM即Java Memory Model</li>
<li>JVM即Java Virtual Machine</li>
<li>J.U.C即java.util.concurrent.* 包</li>
</ul>
<center>目录</center>

<p>[toc]</p>
<h1 id="一、三目运算符导致NPE的问题"><a href="#一、三目运算符导致NPE的问题" class="headerlink" title="一、三目运算符导致NPE的问题"></a>一、三目运算符导致NPE的问题</h1><h2 id="1-1-NPE触发"><a href="#1-1-NPE触发" class="headerlink" title="1.1 NPE触发"></a>1.1 NPE触发</h2><pre><code class="java">Integer a = 1;
Integer b = 2;
Integer c = null;
Boolean flag = false;
// a*b的结果是int类型，那么c会强制拆箱成int型，而c是null，因此会抛出NPE
Integer res = (flag ? a*b : c);
</code></pre>
<h2 id="1-2-基础知识"><a href="#1-2-基础知识" class="headerlink" title="1.2 基础知识"></a>1.2 基础知识</h2><ul>
<li>三目运算符</li>
<li>自动拆箱、自动装箱</li>
</ul>
<h3 id="1-2-1-三目运算符运算规则"><a href="#1-2-1-三目运算符运算规则" class="headerlink" title="1.2.1  三目运算符运算规则"></a>1.2.1  三目运算符运算规则</h3><p>三目运算符形式：</p>
<p><code>&lt;表达式1&gt; ？ &lt;表达式2&gt; : &lt;表达式3&gt;</code></p>
<p>通过<code>?</code>、<code>:</code>组合的形式得到一个条件表达式。其中<code>?</code>运算符的含义是：先求表达式 1 的值，</p>
<ul>
<li>若为真，执行并返回 表达式 2  的结果；</li>
<li>若为假，则执行并返回 表达式 3 的结果。</li>
</ul>
<p><strong>值得注意的是</strong>：一个条件表达式从不会既计算 &lt; 表达式 2&gt;，又计算 &lt; 表达式</p>
<p>3&gt;。条件运算符是右结合的，也就是说，从右向左分组计算。例如，a?b:c?d:e 将按</p>
<p>a?b:（c?d:e）执行</p>
<h3 id="1-2-2-自动拆箱和自动装箱"><a href="#1-2-2-自动拆箱和自动装箱" class="headerlink" title="1.2.2 自动拆箱和自动装箱"></a>1.2.2 自动拆箱和自动装箱</h3><p>自动装箱和自动拆箱是在Java SE5中，为方便基本数据类型和包装类之间的转换引入的功能。</p>
<pre><code class="java">Integer a = 10; // 自动装箱
int b = a;         // 自动拆箱
</code></pre>
<p><code>自动装箱</code>都是通过包装类的 valueOf() 方法来实现的</p>
<p><code>自动拆箱</code>都是通过包装类对象的 xxxValue() 来实现的（如 booleanValue()、longValue() 等）。</p>
<h2 id="1-3-原理刨析"><a href="#1-3-原理刨析" class="headerlink" title="1.3 原理刨析"></a>1.3 原理刨析</h2><h3 id="1-3-1-问题复现"><a href="#1-3-1-问题复现" class="headerlink" title="1.3.1 问题复现"></a>1.3.1 问题复现</h3><pre><code class="java">boolean flag = true;         // 设置成 true，保证条件表达式的表达式二一定可以执行
boolean simpleBoolean = false; // 定义一个基本数据类型的 boolean 变量
Boolean nullBoolean = null    ;// 定义一个包装类对象类型的 Boolean 变量，值为 null
boolean x = flag ? nullBoolean : simpleBoolean; // 使用三目运算符并给 x 变量赋值
</code></pre>
<p>对上述代码反编译后，可以得到：</p>
<pre><code class="java">boolean flag = true;        
boolean simpleBoolean = false;
Boolean nullBoolean = null;
boolean x = flag ? nullBoolean.booleanValue() : simpleBoolean;    // 注意点
</code></pre>
<p>反编译后的代码，最后一行进行了一次<code>自动拆箱</code>，而nullBollean是null，null调用booleanValue()方法导致NPE。</p>
<p><strong>需要注意的是</strong>：根据三目运算符运算规则，NPE产生，和flag 以及 nullBoolean的位置有关，若flag = false;那当nullBoolean在<code>:</code>后时，才会导致NPE。</p>
<h3 id="1-3-2-原理分析"><a href="#1-3-2-原理分析" class="headerlink" title="1.3.2 原理分析"></a>1.3.2 原理分析</h3><p>根据《JLS》-15.25 相关介绍：</p>
<ul>
<li>当三目运算符&lt;表达式2&gt;和&lt;表达式3&gt;操作数的类型相同(如都是包装类)时，则三目运算符表达式的结果和这两位操作数的类型相同。</li>
<li>当三目运算符&lt;表达式2&gt;和&lt;表达式3&gt;操作数中存在一个基本数据类型，那么该表达式的结果的类型要求是基本类型。如果不符合预期，那么编译器就会自动拆箱。</li>
</ul>
<h2 id="1-4-开发场景拓展"><a href="#1-4-开发场景拓展" class="headerlink" title="1.4 开发场景拓展"></a>1.4 开发场景拓展</h2><p>假设下述场景：</p>
<pre><code class="java">Map&lt;String,Boolean&gt; map = new HashMap&lt;String, Boolean&gt;();
Boolean b = (map!=null ? map.get(“test”) : false);
</code></pre>
<p>结果：在小于 JDK 1.8 的版本中执行的结果是 NPE，在 JDK 1.8 及以后的版本中执行结果是 null。</p>
<blockquote>
<p>JDK 8 新规范</p>
</blockquote>
<p>依据JDK8 后的《JLS》：(JDK8前没有这些规定)</p>
<ul>
<li>如果表达式的第二个和第三个操作数都是布尔表达式，那么该条件表达式就是布尔表达式</li>
<li>如果表达式的第二个和第三个操作数都是数字型表达式，那么该条件表达式就是数字型表达式</li>
<li>除了以上两种以外的表达式就是引用表达式</li>
</ul>
<p>因为第二个操作数为<code>map.get(&quot;test&quot;)</code>，虽然Map在定义时规定了其值类型为Boolean，但是在编译过程泛型会被擦除，因此其结果就是Object，即引用表达式。</p>
<ul>
<li>如果引用条件表达式出现在赋值上下文或调用上下文中，那么条件表达式就是合成表达式</li>
</ul>
<p>因为<code>Boolean b = (map!=null ? map.get(&quot;test&quot;) : false)</code>就时一个赋值上下文，所以<code>map!=null ? map.get(&quot;test&quot;) : false</code>是合成表达式</p>
<ul>
<li>合成的引用条件表达式的类型与其目标类型相同</li>
</ul>
<p>因此该表达式的第二个操作数和第三个操作数的结果应该都是 Boolean 类型，所以JDK 8以后的编译过程中，把他们都转化成Boolean，即：</p>
<pre><code class="java">Boolean b = maps == null ? Boolean.valueOf(false) : (Boolean)maps.get(&quot;test&quot;);
</code></pre>
<blockquote>
<p>会出现空指针异常的原因</p>
</blockquote>
<p>对上述代码反编译后：</p>
<pre><code class="java">HashMap hashmap = new HashMap();
Boolean boolean1 = Boolean.valueOf(hashmap == null ? false : ( (Boolean)hashmap.get(&quot;test&quot;) ).booleanValue() );
</code></pre>
<p>问题出现在：<code>((Boolean)hashmap.get(&quot;test&quot;)).booleanValue()</code>的执行过程中：</p>
<pre><code class="java">hashmap.get(&quot;test&quot;) -&gt; null; 
(Boolean) null -&gt; null;
null.booleanValue() -&gt; 报错NPE
</code></pre>
<blockquote>
<p>解决办法</p>
</blockquote>
<pre><code class="java">Map&lt;String,Boolean&gt; map = new HashMap&lt;&gt;();
Boolean b = (map!=null ? map.get(&quot;test&quot;) : Boolean.FALSE );
</code></pre>
<p>统一为包装类，map.get(“test”)就不会因此调用booleanValue()进行拆箱了。</p>
<h1 id="二、初始化HashMap容量的建议"><a href="#二、初始化HashMap容量的建议" class="headerlink" title="二、初始化HashMap容量的建议"></a>二、初始化HashMap容量的建议</h1><h2 id="2-1-基础知识"><a href="#2-1-基础知识" class="headerlink" title="2.1 基础知识"></a>2.1 基础知识</h2><p><em>参考《集合》中HashMap的扩容原理。</em></p>
<p>HashMap 类中有以下主要成员变量：</p>
<ul>
<li>transient int size;<ul>
<li>记录了 Map 中 KV 对的个数</li>
</ul>
</li>
<li>loadFactor<ul>
<li>装载印子，用来衡量 HashMap 满的程度。loadFactor 的默认值为 0.75f（static final float DEFAULT_LOAD_FACTOR = 0.75f;）</li>
</ul>
</li>
<li>int threshold;<ul>
<li>临界值，当实际 KV 个数超过 threshold 时，HashMap 会将容量扩容，threshold ＝容量 * 加载因子</li>
</ul>
</li>
<li>除了以上这些重要成员变量外，HashMap 中还有一个概念：capacity<ul>
<li>容量，如果不指定，默认容量是 16(static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;)</li>
</ul>
</li>
</ul>
<h2 id="2-2-建议"><a href="#2-2-建议" class="headerlink" title="2.2 建议"></a>2.2 建议</h2><p>在已知 HashMap 中将要存放的 KV 个数的时候，设置一个合理的初始化容量可以有效的提高性能。</p>
<p>默认情况下，当我们设置 HashMap的初始化容量时，实际上 HashMap 会采用第一个大于该数值的 2 的幂作为初始化容量。如我们<code> new HashMap&lt;String, String&gt;(1)</code>实际容量为2。</p>
<p><em>在 Jdk 1.7 和 Jdk 1.8 中，HashMap 初始化这个容量的时机不同。jdk1.8中，在调用 HashMap 的构造函数定义 HashMap 的时候，就会进行容量的设定。而在 Jdk 1.7 中，要等到第一次 put 操作时才进行这一操作。但计算初始化容量的算法基本相同</em></p>
<blockquote>
<p>初始化大小建议</p>
</blockquote>
<p>依据JDK 8 中putAll方法中的算法实现：<code> (int) ((float) expectedSize / 0.75F + 1.0F)</code>。我们可以认为，当我们明确知道 HashMap 中元素的个数的时候，把默认容量设置成 expectedSize / 0.75F + 1.0F 是一个在性能上相对好的选择，但是，同时也会牺牲些内存</p>
<p><strong>值得注意的是</strong>：本操作是用内存换性能的做法，真正使用时需要考虑内存影响。</p>
<h1 id="三、禁止使用Executors创建线程池的原因"><a href="#三、禁止使用Executors创建线程池的原因" class="headerlink" title="三、禁止使用Executors创建线程池的原因"></a>三、禁止使用Executors创建线程池的原因</h1><h2 id="3-1-基础知识"><a href="#3-1-基础知识" class="headerlink" title="3.1 基础知识"></a>3.1 基础知识</h2><ul>
<li>线程池</li>
<li>阻塞队列</li>
</ul>
<h3 id="3-1-1-线程池"><a href="#3-1-1-线程池" class="headerlink" title="3.1.1 线程池"></a>3.1.1 线程池</h3><p>线程池技术：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/-89-CcDnSLBYy3THmcLEdQ">《深入源码分析Java线程池的实现原理》</a></p>
<h3 id="3-1-2-阻塞队列"><a href="#3-1-2-阻塞队列" class="headerlink" title="3.1.2 阻塞队列"></a>3.1.2 阻塞队列</h3><p>BlockingQueue主要有两种实现：</p>
<ul>
<li>ArrayBlockingQueue<ul>
<li>是一个用<strong>数组实现</strong>的有界阻塞队列，必须设置容量</li>
</ul>
</li>
<li>LinkedBlockingQueue<ul>
<li>是一个用链表实现的有界阻塞队列，容量可以选择进行设置，不设置的话将会是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE。</li>
</ul>
</li>
</ul>
<h2 id="3-2-Executors存在的问题"><a href="#3-2-Executors存在的问题" class="headerlink" title="3.2 Executors存在的问题"></a>3.2 Executors存在的问题</h2><ul>
<li>FixedThreadPool和SingleThreadPool：允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量请求，从而导致OOM</li>
<li>CachedThreadPool和ScheduledThreadPool：允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM</li>
</ul>
<pre><code class="java">public class ExecutorsDemo &#123;
    private static ExecutorService executor = Executors.newFixedThreadPool(15);
    public static void main(String[] args) &#123;
        for (int i = 0; i &lt; Integer.MAX_VALUE; i++) &#123;
            executor.execute(new SubThread());
        &#125;
    &#125;
&#125;
class SubThread implements Runnable &#123;
    @Override
    public void run() &#123;
        try &#123;
            Thread.sleep(10000);
        &#125; catch (InterruptedException e) &#123;
            //do nothing
        &#125;
    &#125;
&#125;
</code></pre>
<p>通过JVM参数：<code>-Xmx8m -Xms8m</code>运行，就会抛出OOM，抛错行数为5行<code>executor.execute(new SubThread())</code>处。</p>
<h2 id="3-3-Executors存在缺陷的原因"><a href="#3-3-Executors存在缺陷的原因" class="headerlink" title="3.3 Executors存在缺陷的原因"></a>3.3 Executors存在缺陷的原因</h2><p>通过报错信息，最直接导致OOM的是<code>LinkedBlockingQueue.offer()</code>方法。</p>
<p>底层实现：</p>
<pre><code class="java">public static ExecutorService newFixedThreadPool(int nThreads) &#123;
    return new ThreadPoolExecutor(nThreads, nThreads,
                                  0L, TimeUnit.MILLISECONDS,
                                  new LinkedBlockingQueue&lt;Runnable&gt;());
</code></pre>
<p>由LinkedBlockingQueue的实现可知，这里未设置阻塞队列容量，因此将会是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE。</p>
<h2 id="3-4-正确创建线程池"><a href="#3-4-正确创建线程池" class="headerlink" title="3.4 正确创建线程池"></a>3.4 正确创建线程池</h2><blockquote>
<p>方式一：</p>
</blockquote>
<p>避免使用Executors创建线程池，主要是避免使用其中的默认实现。那么可以自己直接调用ThreadPoolExecutor的构造函数自己创建线程池，只需要给BlockQueue指定容量就可以规避了。</p>
<pre><code class="java">private static ExecutorService executor = 
    new ThreadPoolExecutor(10, 10,
                           60L, TimeUnit.SECONDS,
                           new ArrayBlockingQueue(10));
</code></pre>
<p>此时只要提交的线程数超过当前可用线程数，就会抛出RejectedExecutionException异常。</p>
<blockquote>
<p>方式二：(更推荐)</p>
</blockquote>
<p>使用ThreadFactoryBuilder创建线程池</p>
<pre><code class="java">public class ExecutorsDemo &#123;
    private static ThreadFactory namedThreadFactory = new 
        ThreadFactoryBuilder().setNameFormat(&quot;demo-pool-%d&quot;).build();
    private static ExecutorService pool =
        new ThreadPoolExecutor(5, 200,
                               0L, TimeUnit.MILLISECONDS,
                               new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new 
                               ThreadPoolExecutor.
                               AbortPolicy());
    public static void main(String[] args) &#123;
        for (int i = 0; i &lt; Integer.MAX_VALUE; i++) &#123;
            pool.execute(new SubThread());
        &#125;
    &#125;
&#125;
</code></pre>
<p>这种方法不仅可以避免 OOM 的问题，还可以自定义线程名称，更加便于出错时溯源。</p>
<h1 id="四、谨慎使用ArrayList中的subList-方法"><a href="#四、谨慎使用ArrayList中的subList-方法" class="headerlink" title="四、谨慎使用ArrayList中的subList()方法"></a>四、谨慎使用ArrayList中的subList()方法</h1><h2 id="4-1-基础知识"><a href="#4-1-基础知识" class="headerlink" title="4.1 基础知识"></a>4.1 基础知识</h2><h3 id="4-1-1-subList-方法"><a href="#4-1-1-subList-方法" class="headerlink" title="4.1.1 subList()方法"></a>4.1.1 subList()方法</h3><p>subList() 是 List 接口中定义的一个方法，该方法主要用于返回一个集合中的一段，可以理解为截取一个集合中的部分元素，他的返回值也是一个 List。</p>
<p>如果将subList的返回值强转成ArrayList或其他List实现类，则会抛出ClassCastException异常。</p>
<h3 id="4-1-2-视图"><a href="#4-1-2-视图" class="headerlink" title="4.1.2 视图"></a>4.1.2 视图</h3><p>subList()方法返回的是一个视图，没有新建一个ArrayList，而是返回了一个ArrayList的内部类。这个内部类(SubList)即ArrayList的一个视图。</p>
<p>当通过set方法修改subList中某个元素的值的时候，源List中对应的元素的值也发生了改变；同理，对源List中的某个元素进行修改，那么subList中对应的值也会发生改变</p>
<h2 id="4-2-底层原理"><a href="#4-2-底层原理" class="headerlink" title="4.2 底层原理"></a>4.2 底层原理</h2><p>subList()的底层实现：</p>
<pre><code class="java">public List&lt;E&gt; subList(int fromIndex, int toIndex) &#123;
    subListRangeCheck(fromIndex, toIndex, size);
    return new SubList(this, 0, fromIndex, toIndex);
&#125;
</code></pre>
<p>这个方法返回了一个SubList，这个类是ArrayList中的一个内部类</p>
<p>SubList中单独定义了set、get、size、add、remove方法。调用subList()方法时会调用SubList的构造器创建一个SubList：</p>
<pre><code class="java">SubList(AbstractList&lt;E&gt; parent,
        int offset, int fromIndex, int toIndex) &#123;
    this.parent = parent;
    this.parentOffset = fromIndex;
    this.offset = offset + fromIndex;
    this.size = toIndex - fromIndex;
    this.modCount = ArrayList.this.modCount;
&#125;
</code></pre>
<p>构造函数中把原来的 List 以及该 List 中的部分属性直接赋值给自己的一些属性。</p>
<p>==SubList只是ArrayList的内部类，没有继承关系，无法直接进行强制类型转换。==</p>
<h1 id="五、String字符串的“-”操作原理"><a href="#五、String字符串的“-”操作原理" class="headerlink" title="五、String字符串的“+”操作原理"></a>五、String字符串的“+”操作原理</h1><h2 id="5-1-基础知识"><a href="#5-1-基础知识" class="headerlink" title="5.1 基础知识"></a>5.1 基础知识</h2><h3 id="5-1-1-String的不可变性"><a href="#5-1-1-String的不可变性" class="headerlink" title="5.1.1 String的不可变性"></a>5.1.1 String的不可变性</h3><p>不可变类的实例一旦创建，其成员变量的值就不能被修改。这样设计有很多好处，比如可以缓存 hashcode、使用更加便利以及更加安全等。</p>
<h3 id="5-1-2-StringBuffer"><a href="#5-1-2-StringBuffer" class="headerlink" title="5.1.2 StringBuffer"></a>5.1.2 StringBuffer</h3><p>Java 中除了定义了一个可以用来定义字符串常量的 String 类以外，还提供了可以用来定义字符串变量的 StringBuffer 类，它的对象是可以扩充和修改的。</p>
<pre><code class="java">StringBuffer wechat = new StringBuffer(&quot;hanxj_a&quot;);
String introduce = &quot; intro &quot;;
StringBuffer res = wechat.append(&quot;,&quot;).append(introduce);
</code></pre>
<h3 id="5-1-3-StringBuilder"><a href="#5-1-3-StringBuilder" class="headerlink" title="5.1.3 StringBuilder"></a>5.1.3 StringBuilder</h3><p>除了 StringBuffer 以外，还有一个类 StringBuilder 也可以使用，其用法和 StringBuffer 类似。如：</p>
<pre><code class="java">StringBuilder wechat = new StringBuilder(&quot;hanxj_a&quot;);
String introduce = &quot; intro &quot;;
StringBuilder res = wechat.append(&quot;,&quot;).append(introduce);
</code></pre>
<h3 id="5-1-4-StringUtils-join"><a href="#5-1-4-StringUtils-join" class="headerlink" title="5.1.4 StringUtils.join()"></a>5.1.4 StringUtils.join()</h3><p>apache.commons 中提供的 StringUtils 类，其中的 join 方法可以拼接字符串。</p>
<pre><code class="java">String wechat = &quot;hanxj_a&quot;;
String introduce = &quot; intro &quot;;
System.out.println(StringUtils.join(wechat, &quot;,&quot;, introduce));
</code></pre>
<h2 id="5-2-‘-’的拼接原理"><a href="#5-2-‘-’的拼接原理" class="headerlink" title="5.2 ‘+’的拼接原理"></a>5.2 ‘+’的拼接原理</h2><p>反编译结果：</p>
<pre><code class="java">String wechat = &quot;hanxj_a&quot;;
String introduce = &quot; intro &quot;;
String hollis = (new StringBuilder()).append(wechat).append(&quot;,&quot;).
    append(introduce).toString();
</code></pre>
<p>字符串常量在拼接过程中，是将 String 转成了 StringBuilder 后，使用其 append 方法进行处理的。</p>
<p>从性能来看：StringBuilder&lt;StringBuffer&lt;concat&lt;+&lt;StringUtils.join</p>
<h1 id="六、foreach中remove-add引起的CME问题"><a href="#六、foreach中remove-add引起的CME问题" class="headerlink" title="六、foreach中remove/add引起的CME问题"></a>六、foreach中remove/add引起的CME问题</h1><h2 id="6-1-基础知识"><a href="#6-1-基础知识" class="headerlink" title="6.1 基础知识"></a>6.1 基础知识</h2><h3 id="6-1-1-foreach循环"><a href="#6-1-1-foreach循环" class="headerlink" title="6.1.1 foreach循环"></a>6.1.1 foreach循环</h3><p>也叫增强for</p>
<pre><code class="java">for( 元素类型 t 元素变量 x : 遍历对象 obj)&#123; 
    
&#125;
</code></pre>
<p>原理：</p>
<pre><code class="java">Iterator iterator = variable.iterator();
do
&#123;
    if(!iterator.hasNext())
        break;
    String variable = (String)iterator.next();
    // 引用了 x 的 java 语句 ; 
&#125; while(true);
</code></pre>
<h3 id="6-1-2-fail-fast机制"><a href="#6-1-2-fail-fast机制" class="headerlink" title="6.1.2 fail-fast机制"></a>6.1.2 fail-fast机制</h3><p><a target="_blank" rel="noopener" href="http://www.hollischuang.com/archives/3542">《fail-fast机制》</a></p>
<p>Java的集合类运用fail-fast机制进行设计，默认指的是Java集合的一种错误检测机制。当多个线程对部分集合进行结构上的改变的操作时，有可能会产生fail-fast机制，这个时候就会抛出CME。</p>
<p><strong>值得注意的是：</strong>很多时候代码并没有在多线程环境中执行，但依然会抛出CME。</p>
<ul>
<li>在Java中， 如果在foreach 循环里对某些集合元素进行元素的 remove/add 操作的时候，就会触发fail-fast机制</li>
</ul>
<h2 id="6-2-原理刨析"><a href="#6-2-原理刨析" class="headerlink" title="6.2 原理刨析"></a>6.2 原理刨析</h2><ul>
<li>modCount 是 ArrayList 中的一个成员变量。它表示该集合实际被修改的次数。</li>
<li>expectedModCount 是 ArrayList 中的一个内部类——Itr 中的成员变量。expectedModCount表示这个迭代器期望该集合被修改的次数。其值是在ArrayList.iterator 方法被调用的时候初始化的。只有<strong>通过迭代器</strong>对集合进行操作，该值才会改变。</li>
<li>Itr 是一个 Iterator 的实现，使用 ArrayList.iterator 方法可以获取到的迭代器就是 Itr 类的实例</li>
</ul>
<h3 id="6-2-1-remove-add的工作机制"><a href="#6-2-1-remove-add的工作机制" class="headerlink" title="6.2.1 remove/add的工作机制"></a>6.2.1 remove/add的工作机制</h3><p>以remove为例</p>
<pre><code class="java">private void fastRemove(int index)&#123;
    modCount ++;
    int numMoved = size - index - 1;
    if(numMoved &gt; 0)
        System.arraycopy(elementData,index+1,elementData,index,numMoved);
    elementData[--size] = null; // clear to let GC do its work
&#125;
</code></pre>
<p>它只修改了 modCount，并没有对 expectedModCount 做任何操作</p>
<h3 id="6-2-2-原理分析"><a href="#6-2-2-原理分析" class="headerlink" title="6.2.2 原理分析"></a>6.2.2 原理分析</h3><p>通过异常堆栈可以发现，异常发生在<code>Iterator.next()</code>处，Iterator.next调用了<code>Iterator.checkForComodification()</code>方法。</p>
<pre><code class="java">final void checkForComodification() &#123;
    if (modCount != expectedModCount)
        throw new ConcurrentModificationException();
&#125;
</code></pre>
<p>当<code>modCount != expectedModCount</code>就会抛出CME。</p>
<p>由6.2.1可以知道，modCount在自增，而expectedModCount没有操作，导致该语句被触发</p>
<h1 id="七、日志框架的使用"><a href="#七、日志框架的使用" class="headerlink" title="七、日志框架的使用"></a>七、日志框架的使用</h1><p>探究不能直接使用Log4j、Logback中API的原因</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220216212400766.png" alt="image-20220216212400766"></p>
<p>结论：为了解耦</p>
<p>建议：使用例如 Log4j + SLF4J的组合进行日志输出</p>
<h2 id="7-1-常用日志框架"><a href="#7-1-常用日志框架" class="headerlink" title="7.1 常用日志框架"></a>7.1 常用日志框架</h2><h3 id="7-1-1-j-u-l"><a href="#7-1-1-j-u-l" class="headerlink" title="7.1.1 j.u.l"></a>7.1.1 j.u.l</h3><p>j.u.l 是 JDK 1.4 引入的 java.util.logging 包的简称。Java Logging API 提供了七个日志级别用来控制输出。这七个级别分别是：SEVERE、WARNING、INFO、CONFIG、FINE、FINER、FINEST。</p>
<h3 id="7-1-2-Log4j"><a href="#7-1-2-Log4j" class="headerlink" title="7.1.2 Log4j"></a>7.1.2 Log4j</h3><ul>
<li>可以控制日志信息输送的目的地是控制台、文件、GUI 组件，甚至是套接口服务器、NT 的事件记录器、UNIX Syslog 守护进程等；</li>
<li>控制日志的输出格式</li>
<li>通过定义每一条日志信息的级别，能够更加细致地控制日志的生成过程</li>
<li>可以通过一个配置文件来灵活地进行配置，而不需要修改应用的代码。</li>
</ul>
<p>Log4j的七种日志级别：OFF、FATAL、ERROR、WARN、INFO、DEBUG和 TRACE。</p>
<h3 id="7-1-3-LogBack"><a href="#7-1-3-LogBack" class="headerlink" title="7.1.3 LogBack"></a>7.1.3 LogBack</h3><p>logback 当前分成三个模块：logback-core,logback- classic 和 logback-access。logback-core 是其它两个模块的基础模块。logback-classic 是 Log4j 的一个改良版本。ogback-classic 完整实现 SLF4J API，可以很方便地更换成其它日记系统如 Log4j 或 j.u.l。logback-access 访问模块与Servlet 容器集成提供通过 Http 来访问日记的功能。</p>
<h3 id="7-1-4-Log4j2"><a href="#7-1-4-Log4j2" class="headerlink" title="7.1.4 Log4j2"></a>7.1.4 Log4j2</h3><p><em>与Log4j已经完全不同</em></p>
<h2 id="7-2-门面模式-外观模式"><a href="#7-2-门面模式-外观模式" class="headerlink" title="7.2 门面模式 (外观模式)"></a>7.2 门面模式 (外观模式)</h2><p>核心为：外部与一个子系统的通信必须通过一个统一的外观对象进行，使得子系统更易于使用。</p>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220216212512572.png" alt="image-20220216212512572" style="zoom:67%;" />





<h2 id="7-3-日志门面"><a href="#7-3-日志门面" class="headerlink" title="7.3 日志门面"></a>7.3 日志门面</h2><p>日志门面，是门面模式的一个典型的应用。是为了解决：“每一种日志框架都有自己单独的 API，要使用对应的框架就要使用其对应的 API，这就大大的增加应用程序代码对于日志框架的耦合性。” 这一问题，即<strong>解耦</strong></p>
<p>在日志框架和应用程序之间架设一个沟通的桥梁，对于应用程序来说，无论底层的日志框架如何变，都不需要有任何感知。只要门面服务做的足够好，随意换另外一个日志框架，应用程序不需要修改任意一行代码。</p>
<h2 id="7-4-常用日志门面"><a href="#7-4-常用日志门面" class="headerlink" title="7.4 常用日志门面"></a>7.4 常用日志门面</h2><h3 id="7-4-1-SLF4J"><a href="#7-4-1-SLF4J" class="headerlink" title="7.4.1 SLF4J"></a>7.4.1 SLF4J</h3><p>Java 简易日志门面（Simple Logging Facade for Java，缩写 SLF4J），是一套包装 Logging 框架的界面程式，以外观模式实现。可以在软件部署的时候决定要使用的 Logging 框架，目前主要支持的有 Java Logging API、Log4j 及 logback等。</p>
<blockquote>
<p>Log4j 和 SLF4J对比</p>
</blockquote>
<ul>
<li>Log4j 提供 TRACE, DEBUG, INFO, WARN, ERROR 及 FATAL 六种纪录等级。SLF4J认为ERROR与FATAL没有本质区别，因此只有五种：TRACE, DEBUG, INFO, WARN, ERROR</li>
<li> logger.error(exception)操作中，Log4j会去把 exception.tostring。真正的写法应该是logger(message.exception); SLF4J中不会使得程序员书写不合适的写法。</li>
<li>Log4j 间接的在鼓励程序员使用 string 相加的写法(参考<a href="#%E4%BA%94%E3%80%81String%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E2%80%9C+%E2%80%9D%E6%93%8D%E4%BD%9C%E5%8E%9F%E7%90%86">五、String字符串的“+”操作原理</a>,存在性能问题)，而 SLF4J 就不会有这个问题，可以使用 logger.error(“{} is+serviceid”,serviceid);</li>
<li> SLF4J 可以方便的使用其提供的各种集体的实现的 jar</li>
<li>提供字串内容替换的功能，会比较有效率</li>
<li>SLF4J 只支持 MDC，不支持 NDC</li>
</ul>
<h3 id="7-4-2-commons-logging"><a href="#7-4-2-commons-logging" class="headerlink" title="7.4.2 commons-logging"></a>7.4.2 commons-logging</h3><p>commons-logging 和 SLF4J 的功能是类似的。</p>
<p>是一个基于 Java 的日志记录实用程序，是用于日志记录和其他工具包的编程模型。它通过其他一些工具提供 API，日志实现和包装器实现。</p>
<h1 id="八、SimpleDateFormat不能被定义成static的原因"><a href="#八、SimpleDateFormat不能被定义成static的原因" class="headerlink" title="八、SimpleDateFormat不能被定义成static的原因"></a>八、SimpleDateFormat不能被定义成static的原因</h1><p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220216220634168.png" alt="image-20220216220634168"></p>
<h2 id="8-1-基础知识"><a href="#8-1-基础知识" class="headerlink" title="8.1 基础知识"></a>8.1 基础知识</h2><h3 id="8-1-1-SimpleDateFormat用法"><a href="#8-1-1-SimpleDateFormat用法" class="headerlink" title="8.1.1 SimpleDateFormat用法"></a>8.1.1 SimpleDateFormat用法</h3><p>用于 格式化（日期 -&gt; 文本）、解析（文本 -&gt; 日期）和规范化。使得可以选择任何用户定义的日期 - 时间格式的模式。</p>
<p>日期格式化时必须使用y表示年，而不能用Y，原因详见：<a href="#%E5%8D%81%E4%BA%8C%E3%80%81%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8F%E5%8C%96%E6%97%B6%E5%BF%85%E9%A1%BB%E4%BD%BF%E7%94%A8y%E8%A1%A8%E7%A4%BA%E5%B9%B4%EF%BC%8C%E4%B8%8D%E7%94%A8Y%E7%9A%84%E5%8E%9F%E5%9B%A0">十二、日期格式化时必须使用y表示年，不用Y的原因</a> 。</p>
<p>使用 SimpleDateFormat 的 format 方法，将一个 Date 类型转化成 String 类型，并且可以指定输出格式：</p>
<pre><code class="java">//Date 转 String
Date date = new Date();
SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);
String dateStr = sdf.format(date);
System.out.println(dateStr);
</code></pre>
<p>使用 SimpleDateFormat 的 parse 方法，将一个 String 类型转化成 Date 类型</p>
<pre><code class="java">//String 转 Date
System.out.println(sdf.parse(dateStr));
</code></pre>
<h3 id="8-1-2-日期和时间模式表达方法"><a href="#8-1-2-日期和时间模式表达方法" class="headerlink" title="8.1.2 日期和时间模式表达方法"></a>8.1.2 日期和时间模式表达方法</h3><p>使用 SimpleDateFormat 的时候，需要通过字母来描述时间元素，并组装成想要的日期和时间模式。常用的时间元素和字母的对应表如下：</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220216215937576.png" alt="image-20220216215937576"></p>
<p>==模式字母通常是重复的，其数量确定其精确表示==</p>
<h3 id="8-1-3-输出不同时区的时间"><a href="#8-1-3-输出不同时区的时间" class="headerlink" title="8.1.3 输出不同时区的时间"></a>8.1.3 输出不同时区的时间</h3><p>默认情况下，如果不指明，在创建日期的时候，会使用当前计算机所在的时区作为默认时区。</p>
<p>使用SimpleDateFormat实现输出指定时区的时间：</p>
<pre><code class="java">SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);
sdf.setTimeZone(TimeZone.getTimeZone(&quot;America/Los_Angeles&quot;));
System.out.println(sdf.format(Calendar.getInstance().getTime()));
</code></pre>
<h3 id="8-1-4-参考资料"><a href="#8-1-4-参考资料" class="headerlink" title="8.1.4 参考资料"></a>8.1.4 参考资料</h3><p><a target="_blank" rel="noopener" href="http://www.hollischuang.com/archives/2888">《线程池的创建》</a></p>
<p><a target="_blank" rel="noopener" href="http://www.hollischuang.com/archives/290">《CountDownLatch详解》</a></p>
<h2 id="8-2-问题触发"><a href="#8-2-问题触发" class="headerlink" title="8.2 问题触发"></a>8.2 问题触发</h2><p>以下代码使用线程池执行时间输出：</p>
<pre><code class="java">public class Main&#123;
    /* 定义一个全局SimpleDateFormat */
    private static SimpleDateFormat simpleDateformat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);
    /* 使用ThreadFactoryBuilder定义一个线程池 */
    private static ThreadFactory namedThreadFactory = new ThreadFactoryBuilder()
        .setNameFormat(&quot;demo-pool-%d&quot;)
        .build();
    private static ExecutorService pool = new ThreadPoolExecutor(5,200,0L,TimeUnit.MILLISECONDS,new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy() );
    
    /* 定义一个CountDownLatch，保证所有子线程执行完之后主线程再执行 */
    private static CountDownLatch countDownLatch = new CountDownLatch(100);
    
    public static void main(String[] args)&#123;
        // 定义一个线程安全的HashSet
        Set&lt;String&gt; dates = Collections.synchronizedSet(new HashSet&lt;String&gt;());
        for(int i = 0; i &lt; 100; i ++)&#123;
            // 获取当前时间
            Calendar calendar = Calendar.getInstance();
            int finalI = i;
            pool.execute(()-&gt;&#123;
                // 时间增加
                calendar.add(Calendar.DATE, finalI);
                // 通过simpleDateFormat把时间转化成字符串
                String dateString = simpleDateFormat.format(calendar.getTime());
                // 把字符串放入Set中
                dates.add(dateString);
                // countDown
                countDownLatch.countDown();
                &#125;);
        &#125;
        // 阻塞,直到countDown数量为0
        countDownLatch.await();
        // 输出 去重后 的时间个数
        System.out.println(dates.size());
    &#125;
&#125;
//================================
// result &lt; 100
</code></pre>
<p>代码概述：循环一百次，每次循环的时候都在当前时间基础上增加一个天数（这个天数随着循环次数而变化），然后把所有日期放入一个线程安全的、带有去重功能的 Set 中，然后输出 Set 中元素个数。</p>
<p> SimpleDateFormat 作为一个非线程安全的类，被当做了共享变量在多个线程中进行使用，出现了线程安全问题。</p>
<h2 id="8-3-原理刨析"><a href="#8-3-原理刨析" class="headerlink" title="8.3 原理刨析"></a>8.3 原理刨析</h2><h3 id="8-3-1-线程不安全的原因"><a href="#8-3-1-线程不安全的原因" class="headerlink" title="8.3.1 线程不安全的原因"></a>8.3.1 线程不安全的原因</h3><p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220216222924300.png" alt="image-20220216222924300"></p>
<p>SimpleDateFormat 中的 format 方法在执行过程中，会使用一个成员变量calendar 来保存时间。这就是问题的关键。</p>
<p>由于我们在声明 SimpleDateFormat 的时候，使用的是 static 定义的。那么这 个 SimpleDateFormat 就 是 一 个 共 享 变 量， 随 之，SimpleDateFormat 中 的calendar 也就可以被多个线程访问到。</p>
<p><em>假设线程 1 刚刚执行完 calendar.setTime 把时间设置成 2018-11-11，还没等执行完，线程 2 又执行了 calendar.setTime 把时间改成了 2018-12-12。这时候线程 1 继续往下执行，拿到的 calendar.getTime 得到的时间就是线程 2 改过之后的</em></p>
<p><strong>需要注意的是：</strong>除了 format 方法以外，SimpleDateFormat 的 parse 方法也有同样的问题</p>
<h3 id="8-3-2-解决方案"><a href="#8-3-2-解决方案" class="headerlink" title="8.3.2 解决方案"></a>8.3.2 解决方案</h3><ol>
<li><p>使用局部变量</p>
<pre><code class="java">for(int i = 0; i &lt; 100; i ++)&#123;
    // 获取当前时间
    Calendar calendar = Calendar.getInstance();
    int finalI = i;
    pool.execute(()-&gt;&#123;
       // SimpleDateFormat 声明为 局部变量
        SimpleDateFormat simpleDateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);
        // 时间增加
        calendar.add(Calendar.DATE, finalI);
        // 通过simpleDateFormat把时间转换成字符串
        String dateString = simpleDateFormat.format(calendar.getTime());
        // 把字符串放入Set中
        dates.add(dateString);
        // countDown
        countDownLatch.countDown();
    &#125;);
&#125;
</code></pre>
</li>
<li><p>加同步锁</p>
<pre><code class="java">for (int i = 0; i &lt; 100; i++) &#123;
    // 获取当前时间
    Calendar calendar = Calendar.getInstance();
    int finalI = i;
    pool.execute(() -&gt; &#123;
        // 加锁
        synchronized (simpleDateFormat) &#123;
            // 时间增加
            calendar.add(Calendar.DATE, finalI);
            // 通过 simpleDateFormat 把时间转换成字符串
            String dateString = simpleDateFormat.format(calendar.getTime());
            // 把字符串放入 Set 中
            dates.add(dateString);
            //countDown
            countDownLatch.countDown();
        &#125;
    &#125;);
&#125;
</code></pre>
<p>优化：可以把锁的粒度再设置的小一点，可以只对 simpleDateFormat.format 这一行加锁</p>
</li>
<li><p>使用ThreadLocal</p>
<pre><code class="java">/* 使用Thread Local定义一个全局的simpleDateFormat */
private static ThreadLocal&lt;SimpleDateFormat&gt; simpleDateFormatThreadLocal = new ThreadLocal&lt;SimpleDateFormat&gt;()&#123;
    @Override
    protected SimpleDateFormat initialValue()&#123;
        return new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);
    &#125;
&#125;;

// 使用
String dateString = simpleDateFormatThreadLocal
    .get()    // 得到全局的simpleDateFormat
    .format(calendar.getTime()); // 调用全局simpleDateFormat的format方法
</code></pre>
</li>
<li><p>使用DateTimeFormatter 代替SimpleDateFormat (JDK 8 +)</p>
<pre><code class="java">// 解析日期
String dateStr= &quot;2016 年 10 月 25 日 &quot;;
DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy 年 MM 月 dd 日 &quot;);
LocalDate date= LocalDate.parse(dateStr, formatter);
// 日期转换为字符串
LocalDateTime now = LocalDateTime.now();
DateTimeFormatter format = DateTimeFormatter.ofPattern(&quot;yyyy 年 MM 月 dd 日 hh:mm a&quot;);
String nowStr = now .format(format);

System.out.println(nowStr);
</code></pre>
</li>
</ol>
<h1 id="九、禁止使用isXxx作为变量名的原因"><a href="#九、禁止使用isXxx作为变量名的原因" class="headerlink" title="九、禁止使用isXxx作为变量名的原因"></a>九、禁止使用isXxx作为变量名的原因</h1><p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220217150122710.png" alt="image-20220217150122710"></p>
<h2 id="9-1-使用场景"><a href="#9-1-使用场景" class="headerlink" title="9.1 使用场景"></a>9.1 使用场景</h2><p>关于这个”本次请求是否成功”的字段的定义，一般情况下，可以有以下四种方式来定义一个布尔类型的成员变量：</p>
<pre><code class="java">boolean success;
boolean isSuccess;
Boolean success;
Boolean isSuccess;
</code></pre>
<p>以上三种命名方式，在IDEA的POJO中自动构建的getter/setter 分别如下：</p>
<pre><code class="java">// 方式一：boolean success
class Model1 &#123;
    private boolean success;
    public boolean isSuccess()&#123;        // 相当于getter
        return success;
    &#125;
    public void setSuccess(boolean success)&#123;
        this.success = success;
    &#125;
&#125;
// 方式二：boolean isSuccess
class Model2 &#123;
    private boolean isSuccess;
    public boolean isSuccess() &#123;    // 相当于getter
        return isSuccess;
    &#125;
    public void setSuccess(boolean success)&#123;
        isSuccess = success;
    &#125;
&#125;
// 方式三：Boolean success
class Model3 &#123;
    private Boolean success;
    public Boolean getSuccess()&#123;
        return success;
    &#125;
    public void setSuccess(Boolean success)&#123;
        this.success = success;
    &#125;
&#125;
//方式四：Boolean isSuccess
class Model4 &#123;
    private Boolean isSuccess;
    public Boolean getSuccess()&#123;
        return isSuccess;
    &#125;
    public void setSuccess(Boolean success)&#123;
        isSuccess = success;
    &#125;
&#125;
</code></pre>
<p>简单来说：</p>
<ul>
<li>基本类型自动生成的 getter 和 setter 方法，名称都是 isXXX() 和 setXXX()形式的。</li>
<li>包 装 类 型 自 动 生 成 的 getter 和 setter 方 法， 名 称 都 是 getXXX() 和setXXX() 形式的。</li>
</ul>
<h2 id="9-2-原理剖析"><a href="#9-2-原理剖析" class="headerlink" title="9.2 原理剖析"></a>9.2 原理剖析</h2><h3 id="9-2-1-Java-Bean中关于setter-getter的规范"><a href="#9-2-1-Java-Bean中关于setter-getter的规范" class="headerlink" title="9.2.1 Java Bean中关于setter/getter的规范"></a>9.2.1 Java Bean中关于setter/getter的规范</h3><p>Java Bean 规范文档：<a target="_blank" rel="noopener" href="https://download.oracle.com/otndocs/jcp/7224-javabeans-1.01-fr-spec-oth-JSpec/">JavaBeans(TM) Specification</a> 规定，如果是普通的参数 propertyName，要以以下方式定义其 setter/getter：</p>
<pre><code class="java">public &lt;PropertyType&gt; get&lt;PropertyName&gt;();
public void set&lt;PropertyName&gt;(&lt;PropertyType&gt; a);
</code></pre>
<p><strong>但是，布尔类型的变量 propertyName 则是单独定义的</strong>：</p>
<pre><code class="java">public boolean is&lt;PropertyName&gt;();
public void set&lt;PropertyName&gt;(boolean m);
</code></pre>
<p>因此根据Java Bean规范，Model2(boolean isSuccess)中变量名为isSuccess，如果严格按照规范定义，那么getter应命名为<code>isIsSuccess()</code>。但是多数IDE会默认生成<code>isSuccess</code></p>
<h3 id="9-2-2-序列化带来的影响"><a href="#9-2-2-序列化带来的影响" class="headerlink" title="9.2.2 序列化带来的影响"></a>9.2.2 序列化带来的影响</h3><p>这里以JSON序列化为例：</p>
<pre><code class="java">public class BooleanMainTest &#123;
    
    public static void main(String[] args) throws IOException &#123;
        // 创建Model2实体
        Model2 model2 = new Model2();
        model2.setSuccess(true);
        
        // 使用fastJson(1.2.16)序列化model2成字符串
        JSON.toJSONString(model2);
        
        // 使用Gson(2.8.5)序列化model2 成字符串
        gson.toJson(model2);
        
        //使用jackson(2.9.7)序列化model2成字符串
        ObjectMapper om = new ObjectMapper();
        om.writeValueAsString(model2);
    &#125;
&#125;

class Model2 implements Serializable &#123;
    private static final long serialVersionUID = 1836697963736227954L;
    private boolean isSuccess;
    public boolean isSuccess() &#123;
        return isSuccess;
    &#125;
    public void setSuccess(boolean success) &#123;
        isSuccess = success;
    &#125;
    public String getTest()&#123;
        return &quot;booleanTest&quot;;
    &#125;
&#125;
</code></pre>
<p>如果输出上述的三种序列化后的字符串：</p>
<pre><code class="java">Serializable Result With fastjson :&#123;&quot;test&quot;:&quot;booleanTest&quot;,&quot;success&quot;:true&#125;
Serializable Result With Gson :&#123;&quot;isSuccess&quot;:true&#125;
Serializable Result With jackson :&#123;&quot;success&quot;:true,&quot;test&quot;:&quot;booleanTest&quot;&#125;
</code></pre>
<p><strong>可以得出结论：</strong>fastjson 和 jackson 在把对象序列化成 json 字符串的时候，是通过反射遍历出该类中的<strong>所有 getter 方法</strong>，得到getTest和isSuccess，然后根据JavaBeans规则，认为这是两个属性test和success的值。直接序列化成json:{“test”:”booleanTest”,”success”:true}。 Gson通过反射遍历该类中的<strong>所有属性</strong>，并把其值序列化成 json:{“isSuccess”:true}。</p>
<p>若不考虑getTest，那么结果应该是：</p>
<pre><code class="java">Serializable Result With fastjson :&#123;&quot;success&quot;:true&#125;
Serializable Result With Gson :&#123;&quot;isSuccess&quot;:true&#125;
Serializable Result With jackson :&#123;&quot;success&quot;:true&#125;
</code></pre>
<p>不同的序列化框架得到的 json 内容并不相同，如果使用 fastjson 进行序列化，再使用 Gson 反序列化：</p>
<pre><code class="java">public class BooleanMainTest &#123;
    public static void main(String[] args) throws IOException &#123;
        Model2 model2 = new Model2();
        Model2.setSuccess(true);
        Gson gson = new Gson();
        System.out.println( gson.fromJson( JSON.toJSONString(model2), Model2.class ) );
    &#125;
&#125;
class Model2 implements Serializable &#123;
    private static final long serialVersionUID = 1836697963736227954L;
    private boolean isSuccess;
    public boolean isSuccess() &#123;
        return isSuccess;
    &#125;
    public void setSuccess(boolean success) &#123;
        isSuccess = success;
    &#125;
    @Override
    public String toString() &#123;
        return new StringJoiner(&quot;, &quot;, Model2.class.getSimpleName() + &quot;[&quot;,&quot;]&quot;)
            .add(&quot;isSuccess=&quot; + isSuccess)
            .toString();
    &#125;
&#125;
// ================================
// Model2[isSuccess=false]
</code></pre>
<p>我们setSuccces为true，而最终得到的结果是false，这是因为：</p>
<p>JSON 框架通过扫描所有的 getter后发现有一个 isSuccess 方法，然后根据 JavaBeans 的规范，解析出变量名为success，把 model 对象序列化城字符串后内容为<code> &#123;&quot;success&quot;:true&#125;</code></p>
<p>根据 {“success”:true} 这个 json 串，Gson 框架在通过解析后，通过反射寻找 Model 类中的 success 属性，但是 Model 类中只有 isSuccess 属性，所以，最终反序列化后的 Model 类的对象中，isSuccess 则会使用默认值 false。</p>
<h3 id="9-2-3-在POJO中Boolean和boolean的使用"><a href="#9-2-3-在POJO中Boolean和boolean的使用" class="headerlink" title="9.2.3 在POJO中Boolean和boolean的使用"></a>9.2.3 在POJO中Boolean和boolean的使用</h3><p>经过 &lt;&lt;9.2.2 序列化带来的影响&gt;&gt; 的解释，排除错误项后，还剩：</p>
<pre><code class="java">boolean success;
Boolean success;
</code></pre>
<p>结论：定义一个成员变量时，使用包装类型更好。</p>
<pre><code class="java">public class BooleanMainTest &#123;
    public static void main(String[] args) &#123;
        Model model = new Model();
        System.out.println(&quot;default model: &quot; + model);
    &#125;
&#125;
class Model &#123;
    private Boolean success;
    private boolean failure;
    @Override
    public String toString()&#123;
        return new StringJoiner(&quot;, &quot; , Model.class.getSimpleName() + &quot;[&quot;, &quot;]&quot;)
            .add(&quot;success=&quot; + success)
            .add(&quot;failure=&quot; + failure)
            .toString();
    &#125;
&#125;
// =============================================
// default model : Model[success=null, failure=false]
</code></pre>
<p>当我们没有设置 Model 对象的字段的值的时候，Boolean 类型的变量会设置默认值为 null，而 boolean 类型的变量会设置默认值为 false。（即对象的默认值是 null，boolean 基本数据类型的默认值是 false）</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220217160819331.png" alt="image-20220217160819331"></p>
<blockquote>
<p>举例</p>
</blockquote>
<p>扣费系统：扣费时需要从外部的定价系统中读取一个费率的值，我们预期该接口的返回值中会包含一个浮点型的费率字段。当我们取到这个值得时候就使用公式：金额 * 费率 = 费用 进行计算，计算结果进行划扣。</p>
<p>如果由于计费系统异常，他可能会返回个默认值，如果这个字段是 Double 类型的话，该默认值为 null，如果该字段是 double 类型的话，该默认值为 0.0。</p>
<p>如果扣费系统对于该费率返回值没做特殊处理的话，拿到 null 值进行计算会直接报错，阻断程序。拿到 0.0 可能就直接进行计算，得出接口为 0 后进行扣费了。</p>
<p>如果是基本类型，这种异常情况就无法被感知！！</p>
<h2 id="9-3-拓展：由JavaBean规范引起的异常"><a href="#9-3-拓展：由JavaBean规范引起的异常" class="headerlink" title="9.3 拓展：由JavaBean规范引起的异常"></a>9.3 拓展：由JavaBean规范引起的异常</h2><p>JavaBean的规范中明确提到：如果第一个字母是小写，第二个字母大写的情况(如：eId, eName…)，在生成setter/getter的时候直接在前面加上set/get，比如eId的setter/getter是seteId()/geteId()，所以 eId在注入的时候会寻找seteId()方法，而不是setEId()。</p>
<p>但是Lombok等插件自动生成的get/set是setEId()和getEId()，因此注入时会找不到seteId()方法</p>
<p><strong>解决方案</strong>：</p>
<ol>
<li>在属性上面加注解@JsonProperty(value = “eId”)</li>
<li>不使用lombok, 手动写setter -&gt; seteId()</li>
</ol>
<h1 id="十、禁止修改serialVersionUID值的原因"><a href="#十、禁止修改serialVersionUID值的原因" class="headerlink" title="十、禁止修改serialVersionUID值的原因"></a>十、禁止修改serialVersionUID值的原因</h1><p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220217161611775.png" alt="image-20220217161611775"></p>
<h2 id="10-1-基础知识"><a href="#10-1-基础知识" class="headerlink" title="10.1 基础知识"></a>10.1 基础知识</h2><p>参考资料：</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://www.hollischuang.com/archives/1150">《序列化与反序列化》</a></li>
<li><a target="_blank" rel="noopener" href="http://www.hollischuang.com/archives/1140">《深入分析Java序列化与反序列化》</a></li>
<li><a target="_blank" rel="noopener" href="http://www.hollischuang.com/archives/1144">《单例与序列化》</a></li>
</ul>
<h3 id="10-1-1-Serializable"><a href="#10-1-1-Serializable" class="headerlink" title="10.1.1 Serializable"></a>10.1.1 Serializable</h3><p>类通过实现 java.io.Serializable 接口以启用其序列化功能。<strong>未实现此接口的类将无法进行序列化或反序列化。</strong></p>
<p> <strong>Serializable 接口没有方法或字段，仅用于标识可序列化的语义。</strong>但是，如果一个类没有实现这个接口，想要被序列化的话，就会抛出 java.io.NotSerializableException 异常：</p>
<pre><code class="java">// 在执行序列化时会执行：
if (obj instanceof String) &#123;
    writeString((String) obj, unshared);
&#125; else if (c1.isArray())&#123;
    writeArray(obj, desc, unshared);
&#125; else if (obj instanceof Enum)&#123;
    writeEnum((Enum&lt;?&gt;) obj, desc, unshared);
&#125; else if (obj instanceof Serializable)&#123;
    writeOrdinaryObject(obj, desc, unshared);
&#125; else &#123;
    if (extendedDebugInfo) &#123;
        throw new NotSerializableException(c1.getName() + &quot;\n&quot; + debugInfoStack.toString());
    &#125;else &#123;
        throw new NotSerializableException(c1.getName());
    &#125;
&#125;
</code></pre>
<p>在进行序列化操作时，会判断要被序列化的类是否是 Enum、Array 和 Serializable 类型，如果都不是则直接抛出 NotSerializableException。</p>
<h3 id="10-1-2-Externalizable"><a href="#10-1-2-Externalizable" class="headerlink" title="10.1.2 Externalizable"></a>10.1.2 Externalizable</h3><p>Externalizable 继承自 Serializable，该接口中定义了两个抽象方法：<code>writeExternal()</code> 与<code> readExternal()</code></p>
<p>当使用 Externalizable 接口来进行序列化与反序列化的时候需要开发人员重写 writeExternal() 与 readExternal() 方法。否则所有变量的值都会变成默认值。</p>
<h3 id="10-1-3-transient"><a href="#10-1-3-transient" class="headerlink" title="10.1.3 transient"></a>10.1.3 transient</h3><p>transient 关键字的作用是控制变量的序列化，在变量声明前加上该关键字，可以<strong>阻止该变量被序列化到文件中</strong>，在被反序列化后，transient 变量的值被设为初始值，如 int 型的是 0，对象型的是 null。</p>
<h3 id="10-1-4-自定义序列化策略"><a href="#10-1-4-自定义序列化策略" class="headerlink" title="10.1.4 自定义序列化策略"></a>10.1.4 自定义序列化策略</h3><p>​    在序列化过程中，如果被序列化的类中定义了<code>writeObject </code>和<code>readObject</code>方法，虚拟机会试图调用对象类里的 writeObject 和 readObject 方法，进行用户自定义的序列化和反序列化。</p>
<p>​    如果没有这样的方法，则默认调用是 <code>ObjectOutputStream 的 defaultWriteObject </code>方法以及 <code>ObjectInputStream 的 defaultReadObject </code>方法。</p>
<p>​    用户自定义的 writeObject 和 readObject 方法可以允许用户控制序列化的过程，比如可以在序列化的过程中动态改变序列化的数值。所以，对于一些特殊字段需要定义序列化的策略的时候，可以考虑使用 transient 修饰，并自己重写 writeObject 和 readObject 方法。(ArrayList中就有这样的实现)</p>
<h3 id="10-1-5-serialVersionUID"><a href="#10-1-5-serialVersionUID" class="headerlink" title="10.1.5 serialVersionUID"></a>10.1.5 serialVersionUID</h3><p>==序列化是将对象的状态信息转换为可存储或传输的形式的过程。== 可以在JVM 停机的情况下也能把对象保存下来。</p>
<p>虚拟机是否允许反序列化，不仅取决于类路径和功能代码是否一致，一个非常重要的一点是两个类的序列化 ID 是否一致，这个所谓的序列化 ID，就是我们在代码中定义的 <code>serialVersionUID</code>。</p>
<blockquote>
<p>举例：serialVersionUID变化后会发生什么</p>
</blockquote>
<pre><code class="java">public class SerializableDemo &#123;
    public static void main(String[] args) &#123;
        // 初始化Object
        User1 user = new User1();
        user.setName(&quot;Han Xiaojie&quot;);
        // 序列化到文件
        ObjectOutputStream oos = null;
        try &#123;
            oos = new ObjectOutputStream(new FileOutputStream(&quot;tempFile&quot;));
            oos.writeObject(user);
        &#125; catch (IOException e) &#123;
            e.printStackTrace();
        &#125; finally &#123;
            IOUtils.closeQuietly(oos);
        &#125;
    &#125;
&#125;
class User1 implements Serializable &#123;
    private static final long serialVersionUID = 1L;
    private String name;
    
    public String getName() &#123;return name;&#125;
    public void setName(String name) &#123;this.name = name;&#125;
&#125;
</code></pre>
<p>存入文件后，修改User1类，将serialVersionUID修改为2L</p>
<pre><code class="java">class User1 implements Serializable &#123;
    private static final long serialVersionUID = 2L;
    private String name;
    
    public String getName() &#123;return name;&#125;
    public void setName(String name) &#123; this.name = name;&#125;
&#125;
</code></pre>
<p>反序列化</p>
<pre><code class="java">public class SerializableDemo2 &#123;
    public static void main(String[] args) &#123;
        // 从File中读数据
        File file = new File(&quot;tempFile&quot;);
        ObjectInputStream ois = null;
        try &#123;
            ois = new ObjectInputStream(new FileInputStream(file));
            User1 newUser = (User1) ios.readObject();
            System.out.println(newUser);
        &#125; catch (IOException e) &#123;
            e.printStackTrace();
        &#125; finally &#123;
            IOUtils.closeQuietly(ois);
            try &#123;
                FileUtils.forceDelete(file);
            &#125; catch (IOException e) &#123;
                e.printStackTrace();
            &#125;
        &#125;
    &#125;
&#125;
</code></pre>
<p>执行结果：</p>
<pre><code class="java">java.io.InvalidClassException: com.hollis.User1; local class incompatible: stream classdesc 
serialVersionUID = 1, local class serialVersionUID = 2
</code></pre>
<blockquote>
<p>举例：不设置serialVersionUID</p>
</blockquote>
<p>根据上各例子的demo代码，修改User1：</p>
<pre><code class="java">class User1 implements Serializable &#123;
    private String name;
    
    public String getName() &#123;return name;&#125;
    public void setName(String name) &#123;this.name = name;&#125;
&#125;
</code></pre>
<p>然后修改User1类，向其中增加一个属性：</p>
<pre><code class="java">class User1 implements Serializable &#123;
    private String name;
    private int age;
    
    public String getName() &#123;return name;&#125;
    public void setName(String name) &#123;this.name = name;&#125;
    public int getAge() &#123;return age;&#125;
    public void setAge(int age) &#123;this.age = age;&#125;
&#125;
</code></pre>
<p>反序列化结果：</p>
<pre><code class="java">java.io.InvalidClassException: com.hollis.User1; 
local class incompatible: stream classdesc serialVersionUID = -2986778152837257883, local class serialVersionUID = 7961728318907695402
</code></pre>
<p>从本例中可以看出，系统自己添加了一个serialVersionUID。</p>
<p>serialVersionUID的两种显式生成方式：</p>
<ul>
<li>默认的 1L，比如：private static final long serialVersionUID = 1L;</li>
<li>根据类名、接口名、成员方法及属性等来生成一个 64 位的哈希字段，如：private static final long serialVersionUID = xxxxL; ([本方法可以借助IDE实现](#10.3 IDEA提示设置))</li>
</ul>
<p>==总结来说，serialVersionUID 其实是验证版本一致性的==</p>
<h2 id="10-2-原理剖析"><a href="#10-2-原理剖析" class="headerlink" title="10.2 原理剖析"></a>10.2 原理剖析</h2><p>反序列化的调用链：</p>
<p><code>ObjectInputStream.readObject -&gt; readObject0 -&gt; readOrdinaryObject -&gt; readClassDesc -&gt; readNonProxyDesc -&gt; ObjectStreamClass.initNonProxy</code></p>
<p>在<code>initNonProxy</code>中，关键代码：</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220217164748622.png" alt="image-20220217164748622"></p>
<p>在反序列化过程中，对 serialVersionUID 做了比较，如果发现不相等，则直接抛出异常</p>
<p>深入至 getSerialVersionUID() 方法：</p>
<pre><code class="java">public long getSerialVersionUID() &#123;
    // REMIND: synchronize instead of relying on volatile?
    if (suid == null) &#123;
        suid = AccessController.doPrivileged(
            new PrivilegeAction&lt;Long&gt;() &#123;
                public Long run() &#123;
                    return computeDefaultSUID(c1);
                &#125;
            &#125;
        );
    &#125;
    return suid.longValue();
&#125;
</code></pre>
<p>在没有定义 serialVersionUID 的时候，会调用 computeDefaultSUID 方法，生成一个默认的 serialVersionUID。</p>
<p>这里也解释了  [&lt;&lt;10.1.5 serialVersionUID&gt;&gt;](#10.1.5 serialVersionUID) 中两个例子的现象</p>
<h2 id="10-3-IDEA的提示设置"><a href="#10-3-IDEA的提示设置" class="headerlink" title="10.3 IDEA的提示设置"></a>10.3 IDEA的提示设置</h2><p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220217165356925.png" alt="image-20220217165356925"></p>
<ol>
<li>File -&gt; setting 中搜索serialVersionUID</li>
<li>勾选<code>Serializable class without serialVersionUID</code>项。</li>
</ol>
<h1 id="十一、禁止使用Apache-Beanutils进行属性copy的原因"><a href="#十一、禁止使用Apache-Beanutils进行属性copy的原因" class="headerlink" title="十一、禁止使用Apache Beanutils进行属性copy的原因"></a>十一、禁止使用Apache Beanutils进行属性copy的原因</h1><p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220217172413260.png" alt="image-20220217172413260"></p>
<h2 id="11-1-常用工具类"><a href="#11-1-常用工具类" class="headerlink" title="11.1 常用工具类"></a>11.1 常用工具类</h2><ul>
<li>Spring BeanUtils</li>
<li>Cglib BeanCopier</li>
<li>Apache BeanUtils</li>
<li>Apache PropertyUtils</li>
<li>Dozer</li>
</ul>
<h2 id="11-2-性能对比"><a href="#11-2-性能对比" class="headerlink" title="11.2 性能对比"></a>11.2 性能对比</h2><p>POJO：</p>
<pre><code class="java">public class PersonDO &#123;
    private Integer id;
    private String name;
    private Integer age;
    private Date birthday;
    // 省略 setter/getter
&#125;
// ===================================
public class PersonDTO &#123;
    private String name;
    private Integer age;
    private Date birthday;
&#125;
</code></pre>
<blockquote>
<p>使用Spring BeanUtils进行属性拷贝</p>
</blockquote>
<pre><code class="java">private void mappingBySpringBeanUtils(PersonDO personDO, int times) &#123;
    // stopwatch 用于记录代码执行时间
    StopWatch stopwatch = new StopWatch();
    stopwatch.start();
    
    for(int i = 0; i &lt; times; i++) &#123;
        PersonDTO personDTO = new PersonDTO();
        org.springframework.beans.BeanUtils.copyProperties(personDO, personDTO);
    &#125;
    stopwatch.stop();
    System.out.println(&quot;mappingBySpringBeanUtils cost :&quot; + stopwatch.getTotalTimeMillis());
&#125;
</code></pre>
<blockquote>
<p>使用Cglib BeanCopier进行属性拷贝</p>
</blockquote>
<pre><code class="java">private void mappingByCglibBeanCopier (PersonDO personDO, int time) &#123;
    StopWatch stopwatch = new StopWatch();
    stopwatch.start();
    
    for(int i = 0; i &lt; times; i++)&#123;
        PersonDTO personDTO = new PersonDTO();
        BeanCopier copier = BeanCopier.create(PersonDO.class, PersonDTO.class, false);
        copier.copy(personDO, personDTO, null);
    &#125;
    stopwatch.stop();
    System.out.println(&quot;mappingByCglibBeanCopier cost :&quot; + stopwatch.getTotalTimeMillis());
&#125;
</code></pre>
<blockquote>
<p>使用Apache BeanUtils进行属性拷贝</p>
</blockquote>
<pre><code class="java">private void mappingByApachePropertyUtils(PersonDO personDO, int times) throws InvocationTargetException, IllegalAccessException,NoSuchMethodException &#123;
    StopWatch stopwatch = new StopWatch();
    stopwatch.start();
    for(int i = 0; i &lt; times; i++)&#123;
        PersonDTO personDTO = new PersonDTO();
        BeanUtils.copyProperties(personDTO, personDO);
    &#125;
    stopwatch.stop();
    System.out.println(&quot;mappingByApacheBeanUtils cost :&quot; + stopwatch.getTotalTimeMillis());
&#125;
</code></pre>
<blockquote>
<p>使用Apache PropertyUtils进行属性拷贝</p>
</blockquote>
<pre><code class="java">private void mappingByApachePropertyUtils(PersonDO personDO, int times) throws nvocationTargetException, IllegalAccessException,NoSuchMethodException &#123;
    StopWatch stopwatch = new StopWatch();
    stopwatch.start();
    for(int i = 0; i &lt; times; i++)&#123;
        PersonDTO personDTO = new PersonDTO();
        PropertyUtils.copyProperties(personDTO, personDO);
    &#125;
    stopwatch.stop();
    System.out.println(&quot;mappingByApachePropertyUtils cost :&quot; + stopwatch.getTotalTimeMillis());
&#125;
</code></pre>
<p>性能测试代码：</p>
<pre><code class="java">public static void main(String[] args)
    throws InvocationTargetException, IllegalAccessException, 
NoSuchMethodException &#123;
    PersonDO personDO = new PersonDO();
    personDO.setName(&quot;Hollis&quot;);
    personDO.setAge(26);
    personDO.setBirthday(new Date());
    personDO.setId(1);
    MapperTest mapperTest = new MapperTest();
    mapperTest.mappingBySpringBeanUtils(personDO, 100);
    mapperTest.mappingBySpringBeanUtils(personDO, 1000);
    mapperTest.mappingBySpringBeanUtils(personDO, 10000);
    mapperTest.mappingBySpringBeanUtils(personDO, 100000);
    mapperTest.mappingBySpringBeanUtils(personDO, 1000000);
    mapperTest.mappingByCglibBeanCopier(personDO, 100);
    mapperTest.mappingByCglibBeanCopier(personDO, 1000);
    mapperTest.mappingByCglibBeanCopier(personDO, 10000);
    mapperTest.mappingByCglibBeanCopier(personDO, 100000);
    mapperTest.mappingByCglibBeanCopier(personDO, 1000000);
    mapperTest.mappingByApachePropertyUtils(personDO, 100);
    mapperTest.mappingByApachePropertyUtils(personDO, 1000);
    mapperTest.mappingByApachePropertyUtils(personDO, 10000);
    mapperTest.mappingByApachePropertyUtils(personDO, 100000);
    mapperTest.mappingByApachePropertyUtils(personDO, 1000000);
    mapperTest.mappingByApacheBeanUtils(personDO, 100);
    mapperTest.mappingByApacheBeanUtils(personDO, 1000);
    mapperTest.mappingByApacheBeanUtils(personDO, 10000);
    mapperTest.mappingByApacheBeanUtils(personDO, 100000);
    mapperTest.mappingByApacheBeanUtils(personDO, 1000000);
&#125;
</code></pre>
<p>运行结果：</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220217222754740.png" alt="image-20220217222754740"></p>
<p>折线图：</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220217222810438.png" alt="image-20220217222810438"></p>
<p>在性能方面，Spring BeanUtils 和 Cglib BeanCopier 表现比较不错，</p>
<p>Apache PropertyUtils、Apache BeanUtils 以及 Dozer则表现的很不好</p>
<p>​        所以考虑性能的话，不要选择 Apache PropertyUtils、Apache BeanUtils 以及 Dozer 等工具类。Apache BeanUtils 力求做得完美 , 在代码中增加了非常多的校验、兼容、日志打印等代码，过度的包装导致性能下降严重。</p>
<h1 id="十二、日期格式化时必须使用y表示年，不用Y的原因"><a href="#十二、日期格式化时必须使用y表示年，不用Y的原因" class="headerlink" title="十二、日期格式化时必须使用y表示年，不用Y的原因"></a>十二、日期格式化时必须使用y表示年，不用Y的原因</h1><p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220217224239863.png" alt="image-20220217224239863"></p>
<p>SimpleDateFormat的用法可见：[8.1.1 SimpleDateFormat用法](#8.1.1 SimpleDateFormat用法)</p>
<h2 id="12-1-ISO-8601"><a href="#12-1-ISO-8601" class="headerlink" title="12.1 ISO 8601"></a>12.1 ISO 8601</h2><p>因为不同人对于日期和时间的表示方法有不同的理解，于是制定了一个国际规范：ISO 8601。</p>
<p>​        国际标准化组织的国际标准 ISO 8601 是<strong>日期和时间的表示方法</strong>，全称为《数据存储和交换形式·信息交换·日期和时间的表示方法》</p>
<p>在 ISO 8601 中。对于一年的第一个日历星期有以下四种等效说法：</p>
<ol>
<li>本年度第一个星期四所在的星期</li>
<li>1 月 4 日所在的星期</li>
<li>本年度第一个至少有 4 天在同一星期内的星期</li>
<li>星期一在去年 12 月 29 日至今年 1 月 4 日以内的星期</li>
</ol>
<p>根据这个标准，我们可以推算出：</p>
<p>2020 年第一周：2019.12.29-2020.1.4</p>
<p>所以， 根 据 ISO 8601 标 准，2019 年 12 月 29 日、2019 年 12 月 30 日、2019 年 12 月 31 日这两天，其实不属于 2019 年的最后一周，而是属于 2020 年的第一周</p>
<h2 id="12-2-JDK-针对ISO-8601提供的支持"><a href="#12-2-JDK-针对ISO-8601提供的支持" class="headerlink" title="12.2 JDK 针对ISO 8601提供的支持"></a>12.2 JDK 针对ISO 8601提供的支持</h2><p>​        我们希望输入一个日期，然后程序告诉我们，根据 ISO 8601 中关于日历日期的定义，这个日期到底属于哪一年。比如输入 2019-12-20，他显示 2019；而输入 2019-12-30 的时候，他显示 2020。</p>
<p>​        为了提供这样的数据，Java 7 引入了「YYYY」作为一个新的日期模式来作为标识。使用「YYYY」作为标识，再通过 SimpleDateFormat 就可以得到一个日期所属的周属于哪一年了。</p>
<pre><code class="java">public class WeekYearTest &#123;
    public static void main(String[] args) &#123;
        SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;);
        SimpleDateFormat sdf1 = new SimpleDateFormat(&quot;YYYY&quot;);
        System.out.println(sdf1.format(sdf.parse(&quot;2019-12-01&quot;)));
        System.out.println(sdf1.format(sdf.parse(&quot;2019-12-30&quot;)));
        System.out.println(sdf1.format(sdf.parse(&quot;2020-01-01&quot;)));
    &#125;
&#125;
// =============================
// 2019
// 2020
// 2020
</code></pre>
<p>因为有这样的情况，所以在日常开发的时候，如果把 y 写成了 Y，那就可能导致日期输出的结果不符合我们的预期。</p>
<p>当我们要表示日期的时候，==一定要使用 yyyy-MM-dd 而不是 YYYY-MM-dd==，这两者的返回结果大多数情况下都一样，但是极端情况就会有问题了。</p>
<h1 id="十三、MySQL中count-列名-、count-常量-和count-的区别"><a href="#十三、MySQL中count-列名-、count-常量-和count-的区别" class="headerlink" title="十三、MySQL中count(列名)、count(常量)和count(*)的区别"></a>十三、MySQL中count(列名)、count(常量)和count(*)的区别</h1><p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220217170145676.png" alt="image-20220217170145676"></p>
<h2 id="13-1-COUNT"><a href="#13-1-COUNT" class="headerlink" title="13.1 COUNT"></a>13.1 COUNT</h2><ol>
<li>COUNT(expr) ，返回 SELECT 语句检索的行中 expr 的值不为 NULL 的数量。结果是一个 BIGINT 值。</li>
<li>如果查询结果没有命中任何记录，则返回 0。</li>
<li><strong>值得注意的是</strong>，COUNT(*) 的统计结果中，会包含值为 NULL 的行数。</li>
</ol>
<h2 id="13-2-count-列名-、count-常量-和count-之间的区别"><a href="#13-2-count-列名-、count-常量-和count-之间的区别" class="headerlink" title="13.2 count(列名)、count(常量)和count(*)之间的区别"></a>13.2 count(列名)、count(常量)和count(*)之间的区别</h2><p>列名、常量 和 * 这三个条件中，</p>
<p><code>常量</code> 是一个固定值，肯定不为 NULL，</p>
<p><code>*</code> 可以理解为查询整行，所以肯定也不为 NULL，</p>
<p><code>列名</code> 可能为NULL</p>
<p>所以， <strong>COUNT( 常量 ) 和 COUNT(*) 表示的是直接查询符合条件的数据库表的行数</strong>。而 <strong>COUNT( 列名 ) 表示的是查询符合条件的列的值不为 NULL 的行数</strong>。</p>
<h2 id="13-3-COUNT-优化"><a href="#13-3-COUNT-优化" class="headerlink" title="13.3 COUNT(*) 优化"></a>13.3 COUNT(*) 优化</h2><p>​    优化与SQL引擎有关，MySQL中常用InnoDB和MyISAM。COUNT(*)的优化主要和“MyISAM 不支持事务，MyISAM 中的锁是表级锁；而InnoDB 支持事务，并且支持行级锁。”有关</p>
<p>​    因为 MyISAM 的锁是表级锁，所以同一张表上面的操作需要串行进行，所以，MyISAM 做了一个简单的优化，那就是它可以把表的总行数单独记录下来，如果从一张表中使用 COUNT(*) 进行查询的时候，可以直接返回这个记录下来的数值就可以了，但前提是不能有 where 条件。</p>
<p><em>MyISAM 数据库是表级锁，不会有并发的数据库行数修改，查询得到的行数是准确的。</em></p>
<p>​    在 InnoDB 中，使用COUNT(*)要不可避免的扫表，在扫表的过程中做了一些优化：MySQL 会优先选择<strong>最小的非聚簇索引</strong>来扫表。所以，当我们建表的时候，除了主键索引以外，<strong>创建一个非主键索引还是有必要的</strong>。</p>
<p><em>InnoDB中的优化前提是查询语句中不包含WHERE或GROUP BY等条件</em></p>
<h2 id="13-4-COUNT-和COUNT-1"><a href="#13-4-COUNT-和COUNT-1" class="headerlink" title="13.4 COUNT(*) 和COUNT(1)"></a>13.4 COUNT(*) 和COUNT(1)</h2><p>==对于 COUNT(1)和 COUNT(*)，MySQL 的优化是完全一样的!!==</p>
<p>但是更建议使用COUNT(*)</p>
<p>COUNT(*)是 SQL92 定义的标准统计行数的语法</p>
<h2 id="13-5-COUNT-字段"><a href="#13-5-COUNT-字段" class="headerlink" title="13.5 COUNT( 字段 )"></a>13.5 COUNT( 字段 )</h2><p>工作原理：全表扫描，然后判断指定字段的值是不是为 NULL，不为 NULL 则累加。</p>
<p>相比 COUNT( * )，COUNT( 字段 ) 多了一个步骤就是判断所查询的字段是否为NULL，所以他的性能要比 COUNT( * ) 慢。</p>
<h2 id="13-6-总结"><a href="#13-6-总结" class="headerlink" title="13.6 总结"></a>13.6 总结</h2><p><strong>结论：建议使用COUNT(*)</strong></p>
<p>​    因为 COUNT(*) 是 SQL92 定义的标准统计行数的语法，所以 MySQL 对他进行了很多优化</p>
<p>​    在 InnoDB 中 COUNT(*) 和 COUNT(1) 实现上没有区别，而且效率一样，但是COUNT( 字段 ) 需要进行字段的非 NULL 判断，所以效率会低一些。</p>
<h1 id="十四、Java值传递的误区和探索"><a href="#十四、Java值传递的误区和探索" class="headerlink" title="十四、Java值传递的误区和探索"></a>十四、Java值传递的误区和探索</h1><p>==首先讲结论：Java只有值传递，没有引用传递==</p>
<p><em>声明：三个误区均为错误结论。本章就是要解释三个误区为什么错，错在哪里</em></p>
<ul>
<li>误区一：值传递和和引用传递，区分的条件是传递的内容，如果是个值，就是值传递；如果是个引用就是引用传递。</li>
<li>误区二：Java存在引用传递。</li>
<li>误区三：传递的参数如果是普通类型，那就是值传递；如果是对象，那就是引用传递。</li>
</ul>
<h2 id="14-1-值传递和引用传递"><a href="#14-1-值传递和引用传递" class="headerlink" title="14.1 值传递和引用传递"></a>14.1 值传递和引用传递</h2><p>当我们调用一个有参函数的时候，会把实际参数(实参)传递给形式参数(形参)。但是，在程序语言中，这个传递过程中传递的两种情况，即值传递和引用传递。定义如下：</p>
<ul>
<li>值传递(pass by value)：指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。</li>
<li>引用传递(pass by reference)：指在调用函数时将实际参数的<strong>地址</strong>直接传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。</li>
</ul>
<p>值传递和引用传递的根本区别是：<strong>值传递会创建副本，引用传递不创建副本</strong></p>
<pre><code class="java">public class Test &#123;
    public static void main(String[] args) &#123;
        int i = 10;
        pass(i);
        System.out.println(&quot;In Main,i is &quot; + i);
    &#125;
    static void pass(int j) &#123;
        j = 20;
        System.out.println(&quot;In Pass,j is &quot; + j);
    &#125;
&#125;
// ========================OUTPUT=============================
// In Pass,j is 20
// In Main,i is 10
</code></pre>
<p>由上述实例，我们可以看出，当形参为基本类型时，Java的方法是值传递。</p>
<p>(本实例仅展示值传递和引用传递的区别，不能因当前实例妄下结论：Java的方法均是值传递。但在下文会去证实这个结论)</p>
<h2 id="14-2-问题复现"><a href="#14-2-问题复现" class="headerlink" title="14.2 问题复现"></a>14.2 问题复现</h2><p>实例：</p>
<pre><code class="java">public class Test &#123;
    public static void main(String[] args) &#123;
        User han = new User();
        han.setName(&quot;Han Xiaojie&quot;);
        han.setAge(22);
        pass(han);
        System.out.println(&quot;In Main,user is &quot; + user);
    &#125;

    static void pass(User user) &#123;
        user.setName(&quot;SkyFroop&quot;);
        System.out.println(&quot;In Pass,user is &quot; + user);
    &#125;
&#125;

class User &#123;
    private String name;
    private Integer age;
    /* 省略Setter/Getter和toString() */
&#125;
// ========================OUTPUT=============================
// In Pass,user is User&#123;name=&#39;SkyFroop&#39;, age=22&#125;
// In Main,user is User&#123;name=&#39;SkyFroop&#39;, age=22&#125;
</code></pre>
<p>为什么这里的实参发生变化了？</p>
<p>那是不是可以得出 “传递的参数如果是普通类型，那就是值传递；如果是对象，那就是引用传递”的结论呢？</p>
<p>再看下面的例子：</p>
<pre><code class="java">public class Test &#123;
    public static void main(String[] args) &#123;
        String name = &quot;Han Xiaojie&quot;
        pass(user);
        System.out.println(&quot;In Main,name is &quot; + user);
    &#125;

    static void pass(User name) &#123;
        name = &quot;SkyFroop&quot;
        System.out.println(&quot;In Pass,name is &quot; + user);
    &#125;
&#125;
// ========================OUTPUT=============================
// In Pass,name is SkyFroop
// In Main,name is Han Xiaojie
</code></pre>
<p>同样传递了一个对象，但是原始参数的值并没有被修改。</p>
<h2 id="14-3-Java的值传递"><a href="#14-3-Java的值传递" class="headerlink" title="14.3 Java的值传递"></a>14.3 Java的值传递</h2><p>上面，我们举了三个例子，表现的结果却不一样，上面的概念没有错，只是代码展示了三种值传递的情况。</p>
<p>回到14.2的第一个例子，从JMM层面来看：</p>
<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220315202311356.png" alt="image-20220315202311356" style="zoom:80%;" />

<p>在参数传递过程中，实际参数的地址0x123456 <strong>拷贝</strong>给了形参user，只是，在这个方法中，并没有对形参本身进行修改，而是修改的形参持有的地址中存储的内容。也就是修改的并不是0x123456这个值，而是修改的这个引用下的成员变量的引用。因此这里仍然是值传递，只不过这个值，是一个地址。但由于这个地址是<strong>拷贝</strong>给了形参，因此仍然是值传递。</p>
<p>如何看出来这里是 <strong>拷贝</strong> 给了形参呢？再看下面这个例子：</p>
<pre><code class="java">public class Test &#123;
    public static void main(String[] args) &#123;
        User han = new User();
        han.setName(&quot;Han Xiaojie&quot;);
        han.setAge(22);
        pass(han);
        System.out.println(&quot;In Main,user is &quot; + user);
    &#125;

    static void pass(User user) &#123;
        user = new User();
        user.setName(&quot;SkyFroop&quot;);
        System.out.println(&quot;In Pass,user is &quot; + user);
    &#125;
&#125;

class User &#123;
    private String name;
    private Integer age;
    /* 省略Setter/Getter和toString() */
&#125;
// ========================OUTPUT=============================
// In Pass,user is User&#123;name=&#39;SkyFroop&#39;, age=22&#125;
// In Main,user is User&#123;name=&#39;Han Xiaojie&#39;, age=22&#125;
</code></pre>
<p>这里的流程如下：</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220315203254549.png" alt="image-20220315203254549"></p>
<p>new User()并没有对0x123456进行修改，而是又复制了一个 <strong>副本</strong>，开辟了一个新的空间。</p>
<p>因此可以完全得出结论：<strong>值传递和引用传递的区别并不是传递的内容。而是实参到底有没有被复制一份给形参。</strong>在判断实参内容有没有受影响的时候，要看传的的是什么，如果你传递的是个地址，那么就看这个地址的变化会不会有影响，而不是看地址指向的对象的变化。</p>
<h2 id="14-4-拓展"><a href="#14-4-拓展" class="headerlink" title="14.4  拓展"></a>14.4  拓展</h2><p>关于String，String是一个不可变类，从String的方法可以看到，所有对String的操作，都是在CopyOf一个新的String对象，如果尝试在pass中修改name，其实间接的创建了一个新的String对象，因此不会改变实参的值。</p>

            
        </div>
    </div>

    <div class="post-tags">
        
        <span class="icon">
            <a-icon type="tags" theme="filled" />
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/Java" style=color:#879cff>
                Java
            </a>
        </span>
        
    </div>

    <a href="/2022/02/20/Java开发手册/ " class="go-post">
        阅读全文
    </a>
</div>

<div class="post">

    <a href="/2021/05/01/Nginx简单应用/">
        <h2>
            Nginx简单应用及配置模板
        </h2>
    </a>

    <div class="category-and-date">

        

        <span class="date">
            <span class="icon">
                <a-icon type="calendar" theme="filled" />
            </span>
            2021/5/1
        </span>

    </div>

    <div class="excerpt">
        <div class="content" v-pre>
            
            
            <h1 id="Nginx概述"><a href="#Nginx概述" class="headerlink" title="Nginx概述"></a>Nginx概述</h1><p>Nginx (engine x)是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务</p>
<h1 id="Nginx常用命令"><a href="#Nginx常用命令" class="headerlink" title="Nginx常用命令"></a>Nginx常用命令</h1><pre><code class="bash">cd /usr/local/nginx/sbin/
./nginx #启动
./nginx -s stop   # 停止
./nginx -s quit   # 安全退出
./nginx -s reload # 重新加载配置文件
ps auxlgrep nginx # 查看nginx进程
</code></pre>
<h1 id="Nginx语法匹配规则"><a href="#Nginx语法匹配规则" class="headerlink" title="Nginx语法匹配规则"></a>Nginx语法匹配规则</h1><p>语法规则： location [=|<del>|</del>*|^~] /uri/ { … }</p>
<ul>
<li>= 开头表示精确匹配</li>
<li>^~ 开头表示uri以某个常规字符串开头，理解为匹配 url路径即可。nginx不对url做编码，因此请求为/static/20%/aa，可以被规则^~ /static/ /aa匹配到（注意是空格）。</li>
<li>~ 开头表示区分大小写的正则匹配</li>
<li>~* 开头表示不区分大小写的正则匹配</li>
<li>!~ 和 !~*分别为区分大小写不匹配及不区分大小写不匹配 的正则</li>
<li>/ 通用匹配，任何请求都会匹配到。</li>
</ul>
<p>多个location配置的情况下匹配顺序为（参考资料而来，还未实际验证，试试就知道了，不必拘泥，仅供参考）：首先匹配 =，其次匹配^~, 其次是按文件中顺序的正则匹配，最后是交给 / 通用匹配。当有匹配成功时候，停止匹配，按当前匹配规则处理请求。</p>
<p>例子，有如下匹配规则：</p>
<pre><code class="shell">location = / &#123;    # 精确匹配，必须是127.0.0.1/

#规则A

&#125;

location = /login &#123;    # 精确匹配，必须是127.0.0.1/login

#规则B

&#125;

location ^~ /static/ &#123;    # 非精确匹配，并且不区分大小写，比如127.0.0.1/static/js.

#规则C

&#125;

location ~ \.(gif|jpg|png|js|css)$ &#123;    # 区分大小写，以gif,jpg,js结尾

#规则D

&#125;

location ~* \.png$ &#123;     # 不区分大小写，匹配.png结尾的

#规则E

&#125;

location !~ \.xhtml$ &#123;   # 区分大小写，匹配不已.xhtml结尾的

#规则F

&#125;

location !~* \.xhtml$ &#123;

#规则G

&#125;

location / &#123;  # 什么都可以

#规则H

&#125;
</code></pre>
<p>那么产生的效果如下：</p>
<ul>
<li>访问根目录/， 比如<a target="_blank" rel="noopener" href="http://localhost/">http://localhost/</a> 将匹配规则A</li>
<li>访问 <a target="_blank" rel="noopener" href="http://localhost/login">http://localhost/login</a> 将匹配规则B，<a target="_blank" rel="noopener" href="http://localhost/register">http://localhost/register</a> 则匹配规则H</li>
<li>访问 <a target="_blank" rel="noopener" href="http://localhost/static/a.html">http://localhost/static/a.html</a> 将匹配规则C</li>
<li>访问 <a target="_blank" rel="noopener" href="http://localhost/a.gif">http://localhost/a.gif</a>, <a target="_blank" rel="noopener" href="http://localhost/b.jpg">http://localhost/b.jpg</a> 将匹配规则D和规则E，但是规则D顺序优先，规则E不起作用， 而 <a target="_blank" rel="noopener" href="http://localhost/static/c.png">http://localhost/static/c.png</a> 则优先匹配到 规则C</li>
<li>访问 <a target="_blank" rel="noopener" href="http://localhost/a.PNG">http://localhost/a.PNG</a> 则匹配规则E， 而不会匹配规则D，因为规则E不区分大小写。</li>
<li>访问 <a target="_blank" rel="noopener" href="http://localhost/a.xhtml">http://localhost/a.xhtml</a> 不会匹配规则F和规则G，<a target="_blank" rel="noopener" href="http://localhost/a.XHTML%E4%B8%8D%E4%BC%9A%E5%8C%B9%E9%85%8D%E8%A7%84%E5%88%99G%EF%BC%8C%E5%9B%A0%E4%B8%BA%E4%B8%8D%E5%8C%BA%E5%88%86%E5%A4%A7%E5%B0%8F%E5%86%99%E3%80%82%E8%A7%84%E5%88%99F%EF%BC%8C%E8%A7%84%E5%88%99G%E5%B1%9E%E4%BA%8E%E6%8E%92%E9%99%A4%E6%B3%95%EF%BC%8C%E7%AC%A6%E5%90%88%E5%8C%B9%E9%85%8D%E8%A7%84%E5%88%99%E4%BD%86%E6%98%AF%E4%B8%8D%E4%BC%9A%E5%8C%B9%E9%85%8D%E5%88%B0%EF%BC%8C%E6%89%80%E4%BB%A5%E6%83%B3%E6%83%B3%E7%9C%8B%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E4%B8%AD%E5%93%AA%E9%87%8C%E4%BC%9A%E7%94%A8%E5%88%B0%E3%80%82">http://localhost/a.XHTML不会匹配规则G，因为不区分大小写。规则F，规则G属于排除法，符合匹配规则但是不会匹配到，所以想想看实际应用中哪里会用到。</a></li>
<li>访问 <a target="_blank" rel="noopener" href="http://localhost/category/id/1111">http://localhost/category/id/1111</a> 则最终匹配到规则H，因为以上规则都不匹配，这个时候应该是nginx转发请求给后端应用服务器，比如FastCGI（php），tomcat（jsp），nginx作为方向代理服务器存在。</li>
</ul>
<p>==注意:如果uri包含正则表达式，则必须要有~ 或者 ~*标识。==</p>
<blockquote>
<p>实际中常用</p>
</blockquote>
<pre><code class="shell">#这里是直接转发给后端应用服务器了，也可以是一个静态首页

# 第一个必选规则

location = / &#123;

proxy_pass http://tomcat:8080/index

&#125;

# 第二个必选规则是处理静态文件请求，这是nginx作为http服务器的强项

# 有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用

location ^~ /static/ &#123;

root /webroot/static/;

&#125;

location ~* \.(gif|jpg|jpeg|png|css|js|ico)$ &#123;

root /webroot/res/;

&#125;

#第三个规则就是通用规则，用来转发动态请求到后端应用服务器

#非静态文件请求就默认是动态请求，自己根据实际把握

#毕竟目前的一些框架的流行，带.php,.jsp后缀的情况很少了

location / &#123;

proxy_pass http://tomcat:8080/

&#125;

#直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。

#这里是直接转发给后端应用服务器了，也可以是一个静态首页

# 第一个必选规则

location = / &#123;

proxy_pass http://tomcat:8080/index

&#125;

# 第二个必选规则是处理静态文件请求，这是nginx作为http服务器的强项

# 有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用

location ^~ /static/ &#123;

root /webroot/static/;

&#125;

location ~* \.(gif|jpg|jpeg|png|css|js|ico)$ &#123;

root /webroot/res/;

&#125;

#第三个规则就是通用规则，用来转发动态请求到后端应用服务器

#非静态文件请求就默认是动态请求，自己根据实际把握

#毕竟目前的一些框架的流行，带.php,.jsp后缀的情况很少了

location / &#123;

proxy_pass http://tomcat:8080/

&#125;
</code></pre>
<h1 id="反向代理配置"><a href="#反向代理配置" class="headerlink" title="反向代理配置"></a>反向代理配置</h1><p>配置文件结构：</p>
<pre><code class="bash">http&#123;
    (http 配置)
    
    server&#123;
        listen  80;
        server_name localhost;
        # 代理
        location / &#123;
            # xxxx
            root 
            index
            proxy_pass #代理服务
        &#125;
        
        location / &#123;
            # xxxx
        &#125;
    &#125;
    
    server&#123;
        listen  443;
        server_name localhost;
        # 代理
    &#125;
    (......)
&#125;
</code></pre>
<h1 id="负载均衡配置"><a href="#负载均衡配置" class="headerlink" title="负载均衡配置"></a>负载均衡配置</h1><pre><code class="shell">http&#123;
    (http 配置)
    
    upstream name&#123;
        # 负载均衡策略
        [轮询(default) | weight | ip_hash | fair]
        # 负载均衡服务器列表
        server IP:Port weight = x;
        ...
    &#125;
    
    server&#123;
        listen  80;
        server_name localhost;
        # 代理
        location / &#123;
            # xxxx
            root 
            index
            # 代理服务
            proxy_pass http://[upstream起的name];
        &#125;
        
    &#125;
    
&#125;
</code></pre>
<p>分配策略：</p>
<ul>
<li>轮询(默认)：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除</li>
<li>weight：weight代表权重，默认值为1，权重越高，被分配的客户端越多</li>
<li>ip_hash：每个请求按访问ip的hash结果分配，这样每个访客固定访问同一台后端服务器</li>
<li>fair(第三方)：按后端服务器的响应时间来分配请求，响应时间短的优先分配。</li>
</ul>
<h1 id="动静分离配置"><a href="#动静分离配置" class="headerlink" title="动静分离配置"></a>动静分离配置</h1><p>Nginx动静分离简单来说就是把动态跟静态请求分开,不能理解成只是单纯的把动态页面和静态页面物理分离。严格意义上说应该是动态请求跟静态请求分开，可以理解成使用Nginw.处理静态页面，Tomcat处理动态页面。动静分离从目前实现角度来讲大致分为两种：</p>
<ol>
<li>一种是纯粹把静态文件独立成单独的域名,放在独立的服务器上,也是目前主流推崇的方案;</li>
<li>另外一种方法就是动态跟静态文件混合在一起发布，通过nginx来分开。</li>
</ol>
<p>通过location指定不同的后缀名实现不同的请求转发。通过expires参数设置，可以使浏览器缓存过期时间，减少与服务器之前的请求和流量。具体Expires定义:是给一个资源设定一个过期时间,也就是说无需去服务端验证,直接通过浏览器自身确认是否过期即可，所以不会产生额外的流量。此种方法非常适合不经常变动的资源。(如果经常更新的文件，不建议使用Expires来缓存)，我这里设置3d，表示在这3天之内访问这个URL，发送一个请求，比对服务器该文件最后更新时间没有变化，则不会从服务器抓取，返回状态码304，如果有修改，则直接从服务器重新下载，返回状态码200。</p>
<pre><code class="shell">http&#123;
    (http 配置)
    
    server&#123;
        listen  80;
        server_name localhost;
        # 代理
        location /规则1 &#123;
            # xxxx
            root 
            index
            # 代理服务
            proxy_pass http://[upstream起的name];
        &#125;
        
        location /规则2 &#123;
            # xxxx
            root 
            index
            # 代理服务
            proxy_pass http://[upstream起的name];
        &#125;
        
    &#125;
    
&#125;
</code></pre>
<h1 id="高可用集群"><a href="#高可用集群" class="headerlink" title="高可用集群"></a>高可用集群</h1><p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220109203922527.png" alt="image-20220109203922527"></p>
<ul>
<li><p>需要两台Nginx服务器</p>
</li>
<li><p>需要Keepalived</p>
<ul>
<li><pre><code class="bash">yum install keepalived -y
</code></pre>
</li>
<li><p>在etc里面生成目录keepalived，有文件keepalived.conf</p>
<pre><code class="shell"># 全局配置
glocal_defs &#123;
    notification_email&#123;
        acassen@firewall.loc
        failover@firewall.loc
        sysadmin@firewall.loc
    &#125;
    notification_email_from Alexandre.Cassen@firewall.loc
    smtp_server 主机IP
    smtp_counnect_timeout 30 
    router_id 主机名 # 访问到主机 /etc/hosts中编辑
&#125;

# 检测脚本配置
vrrp_script chk_http_port &#123;
    script &quot;/usr/local/src/nginx_check.sh&quot;
    interval 2 # 检测脚本执行的间隔
    weight 2 # 权重，设置当前服务器的一个权重
&#125;

# 虚拟IP的配置
vrrp_instance VI_1&#123;
    state MASTER # 备份服务器上讲MASTER换成BACKUP
    interface ens33 # 网卡
    virtual_router_id 51 # 主备机的virtual_router id 必须相同
    priority 100 # 主备机取不同的优先级，主机值较大，备份机较小
    advert_int 1 # 时间间隔
    authtication &#123;
        auth_type PASS
        auth_pass 1111
    &#125;
    viretual_ipaddress &#123;
        # VRRP H虚拟地址
    &#125;
&#125;
</code></pre>
</li>
<li><p>检测脚本nginx_check.sh</p>
<pre><code class="shell"># !/bin/bash
A = `ps -C nginx -no-header |wc -l`
if [$A -eq 0]; then
    /usr/local/nginx/sbin/nginx
    sleep 2
    if [`ps -C nginx --no-header |wc -l` -eq 0]; then
        killall keepalived
    fi
fi
</code></pre>
</li>
</ul>
</li>
<li><p>需要虚拟ip</p>
</li>
</ul>
<h1 id="Nginx原理"><a href="#Nginx原理" class="headerlink" title="Nginx原理"></a>Nginx原理</h1><p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220109213113322.png" alt="image-20220109213113322"></p>
<p>两个进程：worker&amp;master</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20220109213215084.png" alt="image-20220109213215084"></p>
<p>多个worker使用的是争抢机制</p>
<blockquote>
<p>一个 master 和多个 woker 有好处</p>
</blockquote>
<ol>
<li>可以使用 nginx –s reload 热部署，利用 nginx 进行热部署操作</li>
<li>每个 woker 是独立的进程，如果有其中的一个 woker 出现问题，其他 woker 独立的，继续进行争抢，实现请求过程，不会造成服务中断</li>
</ol>
<blockquote>
<p>设置多少个 woker 合适</p>
</blockquote>
<p>Nginx和Redis类似都采用了IO多路复用机制，每个worker都是一个独立的进程，但每个进程里面只有一个主线程，通过异步非阻塞的方式来处理请求。每个worker的线程可以把一个CPU的i性能发挥到极致。所以worker数和服务器的CPU数相等是最合适的。设少了会浪费CPU，多了会导致CPU频繁的上下文切换</p>
<blockquote>
<p>连接数 worker_connection</p>
</blockquote>
<p>这个值表示每个worker进程所能建立连接的最大值，所以，一个Nginx能建立的最大连接数，应该是worker_connections * worker_processes。这里所说的是最大连接数。</p>
<ul>
<li>对于HTTP请求本地资源来说，能够支持的最大并发数量是 worker_connections * worker_processses，</li>
<li>如果是支持http1.1 的浏览器每次访问要占两个连接，所以普通的静态访问最大并发数是: worker_connections * worker_processes / 2</li>
<li>如果是HTTP作为反向代理来说，最大并发数量应该是worker_connection * worker_processes / 4</li>
</ul>
<p>因此作为反向代理服务器，每个并发会与客户端的连接和与后端服务的连接，会占用两个连接</p>
<h1 id="解决办法"><a href="#解决办法" class="headerlink" title="[解决办法]"></a>[解决办法]</h1><h2 id="阿里云服务器80端口被占用解决方案"><a href="#阿里云服务器80端口被占用解决方案" class="headerlink" title="阿里云服务器80端口被占用解决方案"></a>阿里云服务器80端口被占用解决方案</h2><p>fuser -k 80/tcp命令停止阿里云的占用进程</p>

            
        </div>
    </div>

    <div class="post-tags">
        
        <span class="icon">
            <a-icon type="tags" theme="filled" />
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/运维" style=color:#00bcd4>
                运维
            </a>
        </span>
        
    </div>

    <a href="/2021/05/01/Nginx简单应用/ " class="go-post">
        阅读全文
    </a>
</div>

<div class="post">

    <a href="/2021/01/01/Linux/">
        <h2>
            Linux快速上手
        </h2>
    </a>

    <div class="category-and-date">

        

        <span class="date">
            <span class="icon">
                <a-icon type="calendar" theme="filled" />
            </span>
            2021/1/1
        </span>

    </div>

    <div class="excerpt">
        <div class="content" v-pre>
            
            
            <h1 id="Linux基础"><a href="#Linux基础" class="headerlink" title="Linux基础"></a>Linux基础</h1><hr>

<p>Kali Linux ： 安全渗透测试使用</p>
<h2 id="开机登录"><a href="#开机登录" class="headerlink" title="开机登录"></a>开机登录</h2><p>开机会启动许多程序。它们在Windows叫做”服务” ( service )，在Linux就叫做”守护进程” ( daemon ) 。<br>开机成功后，它会显示一个文本登录界面，这个界面就是我们经常看到的登录界面，在这个登录界面中会提示用户输入用户名，而用户输入的用户将作为参数传给login程序来验证用户的身份，密码是不显示的，输完回车即可！<br>一般来说，用户的登录方式有三种:</p>
<ul>
<li>命令行登录</li>
<li>ssh登录</li>
<li>图形界面登录</li>
</ul>
<p>最高权限账户为root，可以操作一切!</p>
<h2 id="关机"><a href="#关机" class="headerlink" title="关机"></a>关机</h2><pre><code class="bash">sync # 将数据由内存同步到硬盘
shutdown # 关机
shutdown -h 10 # 10分钟后关机
shutdown -h 20:25 # 系统会在今天的20:25关机
shutdown -h +10 #
shutdown -r now # 立马重启
reboot # 同上
halt # 关闭系统
</code></pre>
<h2 id="系统的目录结构"><a href="#系统的目录结构" class="headerlink" title="系统的目录结构"></a>系统的目录结构</h2><p>==一切皆文件==</p>
<p>根目录: <code>/</code>所有的文件都在这个目录下</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210902221238313.png" alt="image-20210902221238313"></p>
<ul>
<li>/bin : Binary的缩写，这个目录存放的是最常用的命令</li>
<li>/boot : 这里存放的是启动Linux时使用的一些核心文件，包括一些连接文件及镜像文件(不要动)</li>
<li>/dev : dev时Device(设备)的缩写，存放的时Linux的外部设备，再Linux中访问设备的方式和访问文件的方式是相同的</li>
<li><strong>/etc : 用来存放所有的系统管理所需要的配置文件和子目录</strong></li>
<li><strong>/home : 用户的主目录，在Linux中，每个用户都有一个自己的目录，一般该目录是以用户的帐号命名的</strong></li>
<li>/lib : 存放着系统最近本的动态连接共享库，起作用类似于Windows里的DLL文件(不要动)</li>
<li>/lost+found : 一般情况下是孔的，当系统非法关机后，这里会存放一些文件(不要动)</li>
<li>/media : Linux系统会自动识别一些设备，例如U盘、光驱等等，当识别后，Linux会把识别的设备挂载到这个目录下</li>
<li>/mnt : 系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载到/mnt/上，然后进入该目录就可以查看光驱里的内容了</li>
<li><strong>/opt : 给主机额外安装软件所摆放的目录，默认是空的</strong></li>
<li>/proc : 虚拟目录，是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息</li>
<li><strong>/root : 系统管理员，也称作超级权限这的用户主目录</strong></li>
<li>/sbin  : s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序</li>
<li>/srv : 该目录存放一些服务启动之后需要提取的数据</li>
<li>/sys : 是Linux2.6内核的很大的变化，目录下安装了2.5内核新出现的一个文件系统sysfs</li>
<li><strong>/tmp : 用来存放一些临时文件</strong>(用完即丢的文件可以放在这个目录下)</li>
<li><strong>/usr</strong> : ==非常重要的目录==，用户的很多应用程序和文件都放在这个目录下，类似于Windos下的program Files目录</li>
<li>/usr/bin : 系统用户使用的应用程序</li>
<li>/usr/sbin : 超级用户使用的比较高级的管理程序和系统守护程序</li>
<li>/usr/src : 内核源代码默认的放置目录</li>
<li><strong>/var : 存放着不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下，包括各种日志文件</strong></li>
<li>/run : 是一个临时文件系统，存储系统启动以来的信息，当系统重启时，这个目录下的文件应该被删掉或清除。</li>
<li><strong>/www : 存放服务器网站相关的资源，比如环境、网站的项目</strong></li>
</ul>
<blockquote>
<p>基本属性</p>
</blockquote>
<p>Linux系统是一种典型的多用户系统，不同的用户处于不同的地位，拥有不同的权限。为了保护系统的安全性，Linux系统对不同的用户访问同一文件（包括目录文件)的权限做了不同的规定。</p>
<p>在Linux中我们可以使用<code>ll</code>或者<code>ls -l</code>命令来显示一个文件的属性以及文件所属的用户和组，如︰</p>
<p>实例中，boot文件的第一个属性用”d”表示。”d””在Linux中代表该文件是一个目录文件。在Linux中第一个字符代表这个文件是目录、文件或链接文件等等:</p>
<ul>
<li>当为[ d]则是目录</li>
<li>当为[-]则是文件;</li>
<li>若是[Ⅰ]则表示为链接文档(link file ) ;</li>
<li>若是[ b ]则表示为装置文件里面的可供储存的接口设备（可随机存取装置);</li>
<li>若是[ c]则表示为装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置)。</li>
</ul>
<p>接下来的字符中，以三个为一组，且均为『rwx』的三个参数的组合。其中，[ r ]代表可读(read)、[ w ]代表可写(write)、[ x]代表可执行(execute)。要注意的是，这三个权限的位置不会改变，如果没有权限，就会出现减号[ - ]而已。每个文件的属性由左边第一部分的10个字符来确定（如下图）∶</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210903093718642.png" alt="image-20210903093718642"></p>
<blockquote>
<p>修改文件属性</p>
</blockquote>
<ul>
<li>更改文件属组</li>
</ul>
<pre><code class="bash">chgrp [-R] 数组名 文件名
</code></pre>
<ul>
<li>更改文件属主，也可以同时更改文件属组</li>
</ul>
<pre><code class="bash">chown [-R] 属主名 文件名
chown [-R] 属主名: 属组名 文件名
</code></pre>
<ul>
<li><strong>更改文件的九个属性</strong></li>
</ul>
<pre><code class="bash">chmod [-R] xyz 文件或目录
</code></pre>
<p>Linux文件属性有两种设置方法，一种是数字，一种是符号。<br>Linux文件的基本权限就有九个，分别是owner/group/others三种身份各有自己的read/write/execute权限。<br>先复习一下刚刚上面提到的数据∶文件的权限字符为︰『-wxrwXrwx』，这九个权限是三个三个一组的!其中，我们可以使用数字来代表各个权限，各权限的分数对照表如下:</p>
<pre><code>r:4     w:2   x:1
可读可写不可执行   rw-   6
可读可写可执行     rwx   7
chomd 777 就代表所有用户都赋予可读可写可执行
</code></pre>
<h2 id="文件内容查看"><a href="#文件内容查看" class="headerlink" title="文件内容查看"></a>文件内容查看</h2><ul>
<li><p>cat 由第一行开始显示文件内容</p>
</li>
<li><p>tac 从最后一行开始显示，(冷知识 : tac是cat的倒着写)</p>
</li>
<li><p>nl 显示的时候，顺便输出行号</p>
</li>
<li><p>more 一页一页的显示文件内容(空格表示翻页，enter表示向下看一行，:f可以查看行号)</p>
</li>
<li><p>less 与 more类似，但是比more更好的是可以往前翻页(上下键代表上下翻动页面，退出使用q命令，<code>/</code> 可以向下查询，<code>?</code>向上查询 n继续查询下一个,N查询上一个)</p>
</li>
<li><p>head 只看头几行 <code>head -n 行数</code></p>
</li>
<li><p>tail只看尾部几行 <code>tail -n 行数</code></p>
</li>
</ul>
<p>ifconfig 查看网络配置</p>
<h2 id="Vim编辑器"><a href="#Vim编辑器" class="headerlink" title="Vim编辑器"></a>Vim编辑器</h2><p>所有的Unix Like系统都会内建vi文书编辑器，其他的文书编辑器则不一定会存在。<br>连vim的官方网站(<a target="_blank" rel="noopener" href="http://www.vim.org)自己也说vim是一个程序开发工具而不是文字处理软件./">http://www.vim.org)自己也说vim是一个程序开发工具而不是文字处理软件。</a></p>
<p>vim键盘图:</p>
<p> <img src="https://img0.baidu.com/it/u=510349211,2341950463&fm=26&fmt=auto&gp=0.jpg" alt="img"></p>
<blockquote>
<p>三种使用模式</p>
</blockquote>
<p>基本上vivim 共分为三种模式，分别是命令模式(Command mode )，输入模式( lnsert mode)和底线命令模式( Lastline mode )。这三种模式的作用分别是:<br><strong>命令模式</strong><br>用户刚刚启动vi/vim，便进入了命令模式。<br>此状态下敲击键盘动作会被Vim识别为命令，而非输入字符。比如我们此时按下i，并不会输入一个字符，i被当作了一个命令。以下是常用的几个命令∶</p>
<ul>
<li><code>i</code> : 切换到输入模式，以输入字符。</li>
<li><code>x</code> : 删除当前光标所在处的字符。</li>
<li><code>:</code>  :切换到底线命令模式，以在最底一行输入命令。如果是编辑模式需要先退出编辑模式。<br>若想要编辑文本∶启动Vim，进入了命令模式，按下i，切换到输入模式。命令模式只有一些最基本的命令，因此仍要依靠底线命令模式输入更多命令。</li>
</ul>
<p><strong>输入模式</strong></p>
<p>在命令模式下按下i就进入了输入模式</p>
<p>在输入模式中：</p>
<ul>
<li>字符按键以及shift组合，输入字符</li>
<li>Enter，回车键，换行</li>
<li>Backspace删除光标的前一个字符</li>
<li>Del : 删除键，删除光标后的一个字符</li>
<li>方向键，移动光标</li>
<li>Home/End : 以动光标到行首/行尾处</li>
<li>Page Up / Page Down : 上/下翻页</li>
<li>Insert : 切换光标为输入/替换模式，光标变成竖线/下划线</li>
<li>ESC : 退出输入模式，切换到命令模式</li>
</ul>
<p><strong>底线命令模式</strong></p>
<p>在命令模式下按下:（英文冒号)就进入了底线命令模式。<br>底线命令模式可以输入单个或多个字符的命令，可用的命令非常多。在底线命令模式中，基本的命令有（已经省略了冒号)︰</p>
<ul>
<li>q 退出程序</li>
<li>w 保存文件</li>
<li>ESC 退出底线命令模式</li>
</ul>
<blockquote>
<p> Vim按键说明</p>
</blockquote>
<p><strong>命令模式</strong></p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210903165526545.png" alt="image-20210903165526545"></p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210903165601194.png" alt="image-20210903165601194"></p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210903165748059.png" alt="image-20210903165748059"></p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210903165807546.png" alt="image-20210903165807546"></p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210903165827848.png" alt="image-20210903165827848"></p>
<p><strong>输入模式</strong></p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210903165906653.png" alt="image-20210903165906653"></p>
<p><strong>底线命令模式</strong></p>
<p><em>只需要记前几个</em></p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210903165928896.png" alt="image-20210903165928896"></p>
<p>==set nu== : 设置行号,代码中十分常用</p>
<h2 id="帐号管理"><a href="#帐号管理" class="headerlink" title="帐号管理"></a>帐号管理</h2><blockquote>
<p> <code>useradd</code> 添加用户</p>
</blockquote>
<p>useradd -选项 用户名</p>
<p>-m ： 自动创建这个用户的主目录 /home/用户名</p>
<p>-g : 用户组，指定用户所属的用户组</p>
<p>-G : 用户组，用户组 指定用户所属的附加组</p>
<p>理解一下本质:Linux中一切皆文件，这里的添加用户说白了就是往某一个文件中写入用户的信息了! 位置：/etc/passwd</p>
<blockquote>
<p><code>userdel</code> 删除用户</p>
</blockquote>
<p>userdel -r 用户名 ： 一般会将用户目录一并删除</p>
<blockquote>
<p><code>usermod</code> 修改用户</p>
</blockquote>
<p>usermod 对应修改的内容  修改那个用户</p>
<p>修改完毕后以配置文件内容为准</p>
<blockquote>
<p>切换用户</p>
</blockquote>
<ol>
<li><p>切换用户的命令为: su username 【username是 用户名 】</p>
</li>
<li><p>从普通用户切换到root用户，还可以使用命令 : sudo su</p>
</li>
<li><p>在终端输入exit或logout或使用快捷方式ctrl+d，可以退回到原来用户，其实ctrl+d也是执行的exit命令</p>
</li>
<li><p>在切换用户时，如果想在切换用户之后使用新用户的工作环境，可以在su和username之间加 - ，例如:【su - root】</p>
<ul>
<li><p>$表示普通用户</p>
</li>
<li><p>#表示超级用户，也就是root用户</p>
</li>
</ul>
</li>
</ol>
<blockquote>
<p>密码设置问题</p>
</blockquote>
<p>通过root创建用户的时候要配置密码</p>
<p><em>Linux上输入密码不会显示</em></p>
<p><code>passwd</code> 用户名 : 修改密码</p>
<blockquote>
<p>锁定账户</p>
</blockquote>
<p>passwd -l 用户名 : 锁定之后这个用户就不能登录了</p>
<h2 id="用户组管理"><a href="#用户组管理" class="headerlink" title="用户组管理"></a>用户组管理</h2><p>属组</p>
<p>每个用户都有一个用户组，系统可以对一个用户组中的所有用户进行集中管理(开发、测试、运维)。不同Linux系统对用户组的规定有所不同，如Linux下的用户属于与它同名的用户组，这个用户组在创建用户时同时创建。<br>用户组的管理涉及用户组的添加、删除和修改。组的增加、删除和修改实际上就是对/etc/group文件的更新。</p>
<blockquote>
<p>groupadd 添加用户组</p>
</blockquote>
<p>创建完用户组后，可以得到一个组的id，这个id是可以指定的，若不指定就是自增1</p>
<blockquote>
<p>groupdel 删除用户组</p>
</blockquote>
<p>删除对应的文件</p>
<blockquote>
<p>groupmod 修改用户组</p>
</blockquote>
<p><code>groupmod -g id -n 新名字 原名字</code> </p>
<blockquote>
<p>切换用户组</p>
</blockquote>
<p>newgrp 用户组</p>
<h2 id="磁盘管理"><a href="#磁盘管理" class="headerlink" title="磁盘管理"></a>磁盘管理</h2><ul>
<li>df : 列出文件系统整体的磁盘使用量</li>
<li>du : 检查磁盘空间使用量<ul>
<li>-a 可以看到隐藏文件以及子目录</li>
</ul>
</li>
</ul>
<blockquote>
<p>挂载外部设备</p>
</blockquote>
<p>mount  外部设备  /mnt/</p>
<p>挂载到mnt目录下，来实现访问</p>
<blockquote>
<p>卸载外部设备</p>
</blockquote>
<p>umount </p>
<p>-f : 强制卸载</p>
<h2 id="进程管理"><a href="#进程管理" class="headerlink" title="进程管理"></a>进程管理</h2><ul>
<li><strong>ps</strong>: 查看当前系统中正在执行的各种进程的信息<ul>
<li>-a 显示当前终端运行的所有的进程信息</li>
<li>-u 以用户的信息显示进程</li>
<li>-x 显示后台运行进程的参数</li>
<li>-aux 可以查看所有的进程</li>
<li>-ef 可以查看到父进程的信息<ul>
<li>看父进程我们一般可以通过目录树的结构来查看：pstree -p 显示父id  -u 显示用户组</li>
</ul>
</li>
</ul>
</li>
<li><strong>kill</strong> : 结束进程<ul>
<li>-(id) 结束进程id为(id)的进程</li>
</ul>
</li>
</ul>
<h2 id="其他常用命令"><a href="#其他常用命令" class="headerlink" title="其他常用命令"></a>其他常用命令</h2><pre><code class="bash"># | 在Linux中，叫做管道符 
# grep 查找文件中符合条件的字符串
</code></pre>
<h2 id="Linux链接-了解"><a href="#Linux链接-了解" class="headerlink" title="Linux链接 (了解)"></a>Linux链接 (了解)</h2><p>分为两种：硬链接、软链接</p>
<p>硬链接 : A——B 假设B是A的硬链接，那么他们两个指向了同一个文件，允许一个文件拥有多个路径，用户可以通过这种机制建立硬链接到一些重要文件上，防止误删</p>
<p>软链接 : 类似Windows下的快捷方式，删除了源文件，快捷方式也访问不了</p>
<p>创建链接: <code>ln</code> 命令</p>
<p><code>touch</code>可以创建文件</p>
<p><code>echo</code> 输入字符串</p>
<h1 id="环境安装"><a href="#环境安装" class="headerlink" title="环境安装"></a>环境安装</h1><p>安装软件一般有三种方式：rpm、解压缩安装、yum在线安装</p>
<h2 id="JDK安装"><a href="#JDK安装" class="headerlink" title="JDK安装"></a>JDK安装</h2><p>开发Java程序必要的环境</p>
<ol>
<li><p>下载JDK rpm包</p>
</li>
<li><p>安装java环境</p>
<pre><code class="bash"># 检查当前是否存在Java环境。
##卸载方式: rpm -qa|grep jdk  查出版本号
##########  rpm -e --nodeps 上述版本号

 rpm -ivh jdk-8u301-linux-x64.rpm # rpm安装
</code></pre>
</li>
<li><p>配置环境变量</p>
<pre><code class="bash"># 在/etc/profile文件中修改
JAVA_HOME=/usr/java/jdk1.8.0_301-amd64
CLASSPATH=%JAVA_HOME%/lib;=%JAVA_HOME%/jre/lib
PATH=$JAVA_HOME/bin;$JAVA_HOME/jre/bin
export PATH CLASSPATH JAVA_HOME # 导出
</code></pre>
</li>
<li><p>让配置生效</p>
<pre><code class="bash">source /etc/profile
</code></pre>
</li>
</ol>
<blockquote>
<p>发布项目</p>
</blockquote>
<ol>
<li>打包发布</li>
<li>开放防火墙端口</li>
<li>重启防火墙</li>
</ol>
<pre><code class="bash">#开启防火墙端口
firewa1l-cmd --zone=public --add-port=9000/tcp --permanen
#重启防火墙
systemctl restart firewa11d.service
#查番所有开启的端口，如果是阿里云，需要配置安全组规则!
firewa1l -cmd --list-ports
</code></pre>
<h2 id="Tomcat安装"><a href="#Tomcat安装" class="headerlink" title="Tomcat安装"></a>Tomcat安装</h2><ol>
<li><p>下载Tomcat-Linux压缩包</p>
</li>
<li><p>解压</p>
<pre><code class="bash">tar -Zxvf apache-tomcat-9.0.22.tar.gz
</code></pre>
</li>
<li><p>运行！</p>
</li>
</ol>
<pre><code class="bash"># 执行 ./startuo.sh
# 停止 ./shotdown.sh
</code></pre>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210903200459651.png" alt="image-20210903200459651"></p>
<p>如果对应防火墙端口已经开放，并且Aliyun服务器端口也已开放</p>
<h2 id="防火墙的配置命令"><a href="#防火墙的配置命令" class="headerlink" title="防火墙的配置命令"></a>防火墙的配置命令</h2><pre><code class="bash">#查看firewa11服务状态
systemctl status firewalld
#开启、重启、关闭、firewalld.service服务
#开启
service firewalld start
#重启
service firewalld restart
#关闭
service firewalld stop
#查看防火墙规则
firewall-cmd --list-all  #查看全部信息
firewall-cmd --1ist-ports  #只看端口信息
#开启端口
开端口命令: firewall-cmd --zone=public --add-port=8080/tcp --permanent
重启防火墙: systemctl restart firewalld.service
命令含义:
--zone # 作用域
--add-port=80/tcp # 添加端口，格式为:端口I/通讯协议
--permlanent # 永久生效，没有此参数重启后失效

</code></pre>
<p>域名解析后,如果端口是80 - http或者443-https可以直接访问,如果是9000 8080 ,就需要通过Apcahe或者Nginx做一下反向代理即可,配置文件即可</p>
<h2 id="Docker安装"><a href="#Docker安装" class="headerlink" title="Docker安装"></a>Docker安装</h2><p>官方文档：<a target="_blank" rel="noopener" href="https://docs.docker.com/engine/install/centos/">https://docs.docker.com/engine/install/centos/</a></p>
<blockquote>
<p>安装</p>
</blockquote>
<ol>
<li>检测CentOS版本 <code>cat /etc/redhat-release</code></li>
<li>安装准备环境<code>yum -y install gcc</code></li>
<li>卸载旧版本</li>
<li>安装新版本(依据官方文档步骤)</li>
</ol>
<h1 id="拓展：VMware本地网络配置"><a href="#拓展：VMware本地网络配置" class="headerlink" title="拓展：VMware本地网络配置"></a>拓展：VMware本地网络配置</h1><p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210903204726785.png" alt="image-20210903204726785"></p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210903204926304.png" alt="image-20210903204926304"></p>
<p>桥接模式：虚拟机可以直接访问到主机</p>
<p>==注意：桥接模式一定要桥接到正确的网卡==</p>
<p><strong>以下是静态网络配置</strong></p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210903205424394.png" alt="image-20210903205424394"></p>
<p>图形化界面配置网络：</p>
<pre><code class="bash">nm-connection-editor
</code></pre>

            
        </div>
    </div>

    <div class="post-tags">
        
        <span class="icon">
            <a-icon type="tags" theme="filled" />
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/运维" style=color:#ffa2c4>
                运维
            </a>
        </span>
        
    </div>

    <a href="/2021/01/01/Linux/ " class="go-post">
        阅读全文
    </a>
</div>

<div class="post">

    <a href="/2020/12/01/OpenStack/">
        <h2>
            OpenStack 部署
        </h2>
    </a>

    <div class="category-and-date">

        

        <span class="date">
            <span class="icon">
                <a-icon type="calendar" theme="filled" />
            </span>
            2020/12/1
        </span>

    </div>

    <div class="excerpt">
        <div class="content" v-pre>
            
            
            <h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><p>Nova调用KVM(libvirt)服务提供虚拟化</p>
<p>Nuetron提供网络服务</p>
<p>Glance 提供镜像模板</p>
<p>cinder 提供存储服务</p>
<p>Cellometer 监控-&gt; Cinder、Nova、Glance</p>
<p>Swift 对象存储</p>
<p>Heat 编排服务：启动服务器集群</p>
<p>存储类型：块存储、文件存储、对象存储</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210913130944845.png" alt="image-20210913130944845"></p>
<pre><code class="bash">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 0.0.0.0:9696            0.0.0.0:*               LISTEN      13960/server.log    
tcp        0      0 0.0.0.0:6080            0.0.0.0:*               LISTEN      1167/python2        
tcp        0      0 0.0.0.0:8774            0.0.0.0:*               LISTEN      20411/python2       
tcp        0      0 0.0.0.0:9191            0.0.0.0:*               LISTEN      20343/python2       
tcp        0      0 0.0.0.0:8775            0.0.0.0:*               LISTEN      1162/python2        
tcp        0      0 0.0.0.0:25672           0.0.0.0:*               LISTEN      1172/beam.smp       
tcp        0      0 192.168.10.43:3306      0.0.0.0:*               LISTEN      1705/mysqld         
tcp        0      0 192.168.10.43:11211     0.0.0.0:*               LISTEN      5458/memcached      
tcp        0      0 127.0.0.1:11211         0.0.0.0:*               LISTEN      5458/memcached      
tcp        0      0 192.168.10.43:2379      0.0.0.0:*               LISTEN      1212/etcd           
tcp        0      0 0.0.0.0:9292            0.0.0.0:*               LISTEN      1170/python2        
tcp        0      0 192.168.10.43:2380      0.0.0.0:*               LISTEN      1212/etcd           
tcp        0      0 0.0.0.0:111             0.0.0.0:*               LISTEN      657/rpcbind         
tcp        0      0 0.0.0.0:4369            0.0.0.0:*               LISTEN      1/systemd           
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1174/sshd           
tcp        0      0 127.0.0.1:631           0.0.0.0:*               LISTEN      1154/cupsd          
tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN      1590/master         
tcp        0      0 127.0.0.1:6010          0.0.0.0:*               LISTEN      45180/sshd: root@pt 
tcp6       0      0 :::5000                 :::*                    LISTEN      5540/httpd          
tcp6       0      0 :::5672                 :::*                    LISTEN      1172/beam.smp       
tcp6       0      0 :::8778                 :::*                    LISTEN      5540/httpd          
tcp6       0      0 ::1:11211               :::*                    LISTEN      5458/memcached      
tcp6       0      0 :::111                  :::*                    LISTEN      657/rpcbind         
tcp6       0      0 :::80                   :::*                    LISTEN      5540/httpd          
tcp6       0      0 :::22                   :::*                    LISTEN      1174/sshd           
tcp6       0      0 ::1:631                 :::*                    LISTEN      1154/cupsd          
tcp6       0      0 ::1:25                  :::*                    LISTEN      1590/master         
tcp6       0      0 ::1:6010                :::*                    LISTEN      45180/sshd: root@pt
</code></pre>
<h1 id="状态检查"><a href="#状态检查" class="headerlink" title="状态检查"></a>状态检查</h1><p>openstack token issue 检查KeyStone是否正常</p>
<p>openstack image list 检查glance是否正常</p>
<p>openstack compute service list 检查nova是否正常</p>
<p>域、项目、用户</p>

            
        </div>
    </div>

    <div class="post-tags">
        
        <span class="icon">
            <a-icon type="tags" theme="filled" />
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/云计算" style=color:#ff7d73>
                云计算
            </a>
        </span>
        
    </div>

    <a href="/2020/12/01/OpenStack/ " class="go-post">
        阅读全文
    </a>
</div>

<div class="post">

    <a href="/2020/06/01/Redis/">
        <h2>
            Redis 基础
        </h2>
    </a>

    <div class="category-and-date">

        

        <span class="date">
            <span class="icon">
                <a-icon type="calendar" theme="filled" />
            </span>
            2020/6/1
        </span>

    </div>

    <div class="excerpt">
        <div class="content" v-pre>
            
            
            <h1 id="零、NoSQL概述"><a href="#零、NoSQL概述" class="headerlink" title="零、NoSQL概述"></a>零、NoSQL概述</h1><p>Not Only SQL 不仅仅是SQL，泛指非关系型数据库，随着Web2.0互联网的诞生，传统的关系型数据库很难对付。尤其是超大规模的高并发的社区。</p>
<p>关系型数据库：表格，行和列 （POI可以操作Excel）</p>
<p>非关系型数据库：很多的数据类型如个人信息、社交网络、地理位置。这些数据类型的储存不需要一个固定的格式！不需要多余的操作就可以横向扩展。Map&lt;String,Object&gt;可存万事万物，使用键值对来控制</p>
<h2 id="0-1-NoSQL特点"><a href="#0-1-NoSQL特点" class="headerlink" title="0.1 NoSQL特点"></a>0.1 NoSQL特点</h2><p>解耦！</p>
<ol>
<li>方便扩展（数据之间没有关系，很好扩展）</li>
<li>大数据量高性能(Redis 一秒写8万次，读取11万次 ，NoSQL的缓存记录级，是一种细粒度的缓存，性能会比较高)</li>
<li>数据类型是多样型的。不需要事先设计数据库，随去随用</li>
</ol>
<blockquote>
<p>传统RDBMS和NoSQL的关系</p>
</blockquote>
<p>传统的RDBMS：</p>
<ul>
<li>结构化组织</li>
<li>SQL</li>
<li>数据和关系都存在单独的表 row col</li>
<li>操作，数据定义语言</li>
<li>严格的一致性 ACID</li>
<li>基础的事务操作</li>
<li>…</li>
</ul>
<p>NoSQL：</p>
<ul>
<li>不仅仅是数据</li>
<li>没有固定的查询语言</li>
<li>键值对存储，列存储，文档存储，图形数据库(社交关系)</li>
<li>最终一致性，CAP定理和BASE理论(异地多活)  —&gt; 初级架构师</li>
<li>高性能，高可用，高可扩展性</li>
</ul>
<blockquote>
<p>了解</p>
</blockquote>
<p>3V + 3高</p>
<p>大数据时代的3V：</p>
<ul>
<li>主要是描述问题的</li>
<li>海量Volume</li>
<li>多样Variety</li>
<li>实时Velocity</li>
</ul>
<p>大数据时代的3高：</p>
<ul>
<li>高并发</li>
<li>高可拓 </li>
<li>高性能</li>
</ul>
<h2 id="0-2-阿里巴巴演进分析"><a href="#0-2-阿里巴巴演进分析" class="headerlink" title="0.2 阿里巴巴演进分析"></a>0.2 阿里巴巴演进分析</h2><p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829125500862.png" alt="image-20210829125500862"></p>
<p>敏捷开发、极限编程</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829131251178.png" alt="image-20210829131251178"></p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829131613382.png" alt="image-20210829131613382"></p>
<p>大型互联网应用问题：</p>
<ul>
<li>数据类型太多了</li>
<li>数据源繁多，经常重构。</li>
<li>数据要改造，需要大面积改造</li>
</ul>
<p>解决问题：</p>
<ul>
<li>统一数据服务层</li>
</ul>
<h2 id="0-3-NoSQL的四大分类"><a href="#0-3-NoSQL的四大分类" class="headerlink" title="0.3 NoSQL的四大分类"></a>0.3 NoSQL的四大分类</h2><blockquote>
<p>KV键值对</p>
</blockquote>
<ul>
<li>新浪： <strong>Redis</strong></li>
<li>美团：Redis+Tair</li>
<li>阿里、百度：Redis + memecache</li>
</ul>
<blockquote>
<p>文档型数据库(BSON格式)</p>
</blockquote>
<ul>
<li>MongoDB<ul>
<li>MongoDB是一个基于分布式文件存储的数据库，C++编写，主要用来处理大量的文档</li>
<li>MongoDB是一个介于关系型数据库和非关系型数据库中间的产品，是非关系型数据库中功能最丰富，最像关系型数据库的</li>
</ul>
</li>
<li>ConchDB</li>
</ul>
<blockquote>
<p>列存储数据库</p>
</blockquote>
<ul>
<li><strong>HBase</strong></li>
<li>分布式文件系统</li>
</ul>
<blockquote>
<p>图关系数据库</p>
</blockquote>
<ul>
<li>不是存图形的，放到是关系，比如：朋友圈社交网络，广告推荐。</li>
<li><strong>Neo4j</strong> ， InfoGrid;</li>
</ul>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829133547319.png" alt="image-20210829133547319"></p>
<h2 id="0-4-文档内容："><a href="#0-4-文档内容：" class="headerlink" title="0.4 文档内容："></a>0.4 文档内容：</h2><ul>
<li>NoSQL讲解</li>
<li>阿里巴巴架构演进</li>
<li>NoSQL数据模型</li>
<li>NoSQL四大分类</li>
<li>CAP</li>
<li>BASE</li>
<li>五大基本数据类型<ul>
<li>String</li>
<li>List</li>
<li>Set</li>
<li>Hash</li>
<li>Zset</li>
</ul>
</li>
<li>三种特殊数据类型<ul>
<li>geo</li>
<li>hyperloglog</li>
<li>bitmap</li>
</ul>
</li>
<li>Redis配置</li>
<li>Redis持久化<ul>
<li>RDB</li>
<li>AOF</li>
</ul>
</li>
<li>Redis事务操作 -包含CAP和BASE</li>
<li>Redis实现订阅发布</li>
<li>Redis主从复制</li>
<li>Redis哨兵模式：现在公司中所有的集群都在用哨兵模式</li>
<li>缓存穿透及解决方案</li>
<li>缓存击穿及解决方案</li>
<li>缓存雪崩及解决方案</li>
<li>基础API之Jedis详解 ( Redis 底层)</li>
<li>SpringBoot集成Redis操作</li>
<li>Redis分析</li>
</ul>
<h1 id="一、Redis-入门"><a href="#一、Redis-入门" class="headerlink" title="一、Redis 入门"></a>一、Redis 入门</h1><h2 id="1-1-Redis概述"><a href="#1-1-Redis概述" class="headerlink" title="1.1 Redis概述"></a>1.1 Redis概述</h2><blockquote>
<p>Redis是什么?</p>
</blockquote>
<p>Redis ( <strong>Re</strong>mote <strong>Di</strong>ctionary <strong>S</strong>erver )，远程字典服务</p>
<p>是一个开源的使用ANSIC语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的APl。</p>
<blockquote>
<p>Redis能干什么</p>
</blockquote>
<ol>
<li>内存存储、持久化，内存中是断电即失，所以持久化很重要(RDB、AOF)</li>
<li>效率高，可以用于高速缓存</li>
<li>发布订阅系统</li>
<li>地图信息分析</li>
<li>计时器、计数器（浏览量！）</li>
<li>….</li>
</ol>
<blockquote>
<p>特性</p>
</blockquote>
<ol>
<li>多样的数据类型</li>
<li>持久化</li>
<li>集群</li>
<li>事务</li>
<li>…</li>
</ol>
<blockquote>
<p>学习中需要用到的东西</p>
</blockquote>
<ol>
<li>Redis官网：redis.io </li>
<li>Redis中文网：redis.cn</li>
</ol>
<p>注意！Windows在Github上下载，但是已经停更很久了。</p>
<p>Redis建议在Linux上学习和使用</p>
<h2 id="1-2-Windwos安装"><a href="#1-2-Windwos安装" class="headerlink" title="1.2 Windwos安装"></a>1.2 Windwos安装</h2><ol>
<li>下载：<a target="_blank" rel="noopener" href="https://github.com/dmajkic/redis">https://github.com/dmajkic/redis</a></li>
<li>解压到电脑上的环境目录下即可</li>
<li>开启Redis，开启服务即可<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829152823131.png" alt="image-20210829152823131"></li>
<li>默认端口为6379<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829152843479.png" alt="image-20210829152843479"></li>
<li>使用Redis客户端连接Redis<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829152929245.png" alt="image-20210829152929245"></li>
<li>连接成功检验<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829153105031.png" alt="image-20210829153105031"></li>
<li></li>
</ol>
<p>虽然Windows 版本的Redis操作十分简单，但Redis官方推荐我们使用Linux！ </p>
<h2 id="1-3-Linux安装"><a href="#1-3-Linux安装" class="headerlink" title="1.3 Linux安装"></a>1.3 Linux安装</h2><ol>
<li><p>官网下载安装包</p>
</li>
<li><p>解压安装包，程序一般放在 /otp目录下<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829163352523.png" alt="image-20210829163352523"></p>
</li>
<li><p>进入解压后的文件夹，可以看到redis的配置文件：redis.conf</p>
</li>
<li><p>安装基本的环境安装</p>
<pre><code class="bash">yum install gcc-c++
</code></pre>
<pre><code class="bash">make
</code></pre>
<p>检查make是否讲所需环境已经装配完成</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829163939626.png" alt="image-20210829163939626"></p>
</li>
</ol>
<p>5.redis的默认安装路径： /usr/local/bin/ </p>
<p>6.将redis配置备份一份，复制到bin目录下的一个自命名的文件夹内</p>
<pre><code class="bash">mkdir SkyFroopConfig
</code></pre>
<pre><code class="bash">cp /opt/redis-6.2.5/redis.conf SkyFroopConfig/
</code></pre>
<p>7.启动：</p>
<ul>
<li>默认不是后台启动，修改配置文件：<img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829170034641.png" alt="image-20210829170034641">改为yes</li>
<li>通过指定的配置文件启动服务：运行redis-server SkyFroopConfig/redis.conf</li>
<li>运行redis-cli -p 端口号 运行</li>
<li>测试连接</li>
</ul>
<p>8.查看Redis的服务是否开启</p>
<pre><code class="bash">ps -ef|grep redis
</code></pre>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829170710229.png" alt="image-20210829170710229"></p>
<p>9.关闭Redis服务</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829170748046.png" alt="image-20210829170748046"></p>
<p>10.后面会使用单机多Redis启动集群测试！</p>
<h2 id="1-4-测试性能"><a href="#1-4-测试性能" class="headerlink" title="1.4 测试性能"></a>1.4 测试性能</h2><p><strong>redis-benchmark</strong>是一个压力测试工具</p>
<p>redis-benchmark 命令</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829171112405.png" alt="image-20210829171112405"></p>
<pre><code class="bash"># 测试 100个并发连接 10万个请求
redis-benchmark -h localhost -p 6379 -c 100 -n 100000
</code></pre>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829183347452.png" alt="image-20210829183347452"></p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829183537841.png" alt="image-20210829183537841"></p>
<blockquote>
<p>如何查看分析</p>
</blockquote>
<ol>
<li>10w并发在2.20 秒完成</li>
<li>100个并发客户端</li>
<li>每次只写三个字节</li>
<li>只有一台服务器在处理请求(单机性能)</li>
<li>每秒处理45351个请求</li>
</ol>
<h2 id="1-5-基础知识"><a href="#1-5-基础知识" class="headerlink" title="1.5 基础知识"></a>1.5 基础知识</h2><p>Redis默认有16个数据库</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829183752843.png" alt="image-20210829183752843"></p>
<p>默认使用的是第0个，可以使用Select进行切换 Select [0,15]</p>
<h3 id="部分数据库操作语法"><a href="#部分数据库操作语法" class="headerlink" title="部分数据库操作语法"></a>部分数据库操作语法</h3><pre><code class="bash">SELECT [index] #选择第几个数据库
DBSIZE # 数据库内容大小
keys * # 查看数据库所有的key
flushdb # 清空当前库
flushall # 清空所有库
</code></pre>
<blockquote>
<p>Redis是单线程的</p>
</blockquote>
<p>Redis是很快的，官方表示，Redis是基于内存操作，CPU不是Redis的性能瓶颈，Redis的瓶颈是根据机器的内存和网络带宽，可以使用单线程实现，就是用单线程了。</p>
<p>Redis是 ANSI C语言写的，官方数据为100000+的APS，完全这个不比同样使用Key-Vale的Memecache差</p>
<p><strong>那么Redis是单线程为什么还这么快？</strong></p>
<p>误区：</p>
<ol>
<li>误区1：高性能的服务器一定是多线程的？</li>
<li>误区2：多线程(CPU)一定比单线程效率高？ 多线程CPU上下文会切换会耗时。速度：CPU &gt; 内存 &gt; 硬盘</li>
</ol>
<p>核心：</p>
<p>Redis是将所有的数据全部放在内存中的，所以说使用单线程去操作效率就是最高的。对于内存系统来说，如果没有上下文切换，效率就是最高的。多次读写都是在一个CPU上的，在内存情况下，这就是最佳方案。</p>
<h1 id="二、Redis的数据类型"><a href="#二、Redis的数据类型" class="headerlink" title="二、Redis的数据类型"></a>二、Redis的数据类型</h1><h2 id="2-1-五大基本数据类型"><a href="#2-1-五大基本数据类型" class="headerlink" title="2.1 五大基本数据类型"></a>2.1 五大基本数据类型</h2><blockquote>
<p>官网文档</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210829185444157.png" alt="image-20210829185444157"></p>
<p>即Redis是一个开源（BSD许可)的，内存中的数据结构存储系统，它可以用作<strong>数据库</strong>、<strong>缓存</strong>和<strong>消息中间件</strong>。它支持多种类型的数据结构，如字符串( strings )，散列( hashes )，列表( lists )，集合( sets )，有序集合( sorted sets ）与范围查询，bitmaps ，hyperloglogs和地理空间 ( geospatial）索引半径查询。Redis 内置了 复制( replication )，LUA脚本( Lua scripting )，LRU驱动事件( LRU eviction )，事务( transactions）和不同级别的磁盘持久化( persistence)，并通过Redis哨兵( Sentinel)和自动分区( Cluster )提供高可用性( high availability )。</p>
<h3 id="Redis-Key"><a href="#Redis-Key" class="headerlink" title="Redis-Key"></a>Redis-Key</h3><pre><code class="bash">EXISTS [value] # 是否存在某个值
MOVE [key-value] # 移除某个值
EXPIRE [key] [seconds] # 设置有效时间
TTL [key] # 查看key的剩余有效时间
TYPE [key] # 查看当前key的类型
</code></pre>
<h3 id="String-字符串"><a href="#String-字符串" class="headerlink" title="String(字符串)"></a>String(字符串)</h3><pre><code class="bash">SET [key-value] # 设置值
GET [key] # 获得值
APPEND [key] [&quot;String&quot;] # 在key字段后追加字符串,如果这个字符串不存在则会新建,相当于SET

STRLEN [key] # key字符串的长度
INCR [key] # 自增1
DECR [key] # 自减1
INCRBY [key] [value] # 令key自增步长为value

GETRANGE [key] [start] [end] # 取key的start到end区间的值(闭区间)，end为-1时，就是全部值
SETRANGE [key] [offset] [value] # 从offset后改成value，替换指定位置开始的字符串

SETEX [key] [seconds] [value]# 设置过期时间，过期时间为seconds
SETNX [key-value] # 如果不存在再设置 , 在分布式锁中常常会使用，如果key不存在才会创建，否则失败
MSET [key-value ...] # 一次性设置多个值
MGET [key ...] # 一次获取多个值
MSETNX [key-value ...] # 是一个原子性的操作，要么一起成功，要么一起失败 

####对象如何储存
SET user:1 &#123;name:zhangsan,age:3&#125; # 设置一个user:1对象，值为JSON字符串来保存一个对象

#### 这里的key是一个巧妙的设计 : user:&#123;id&#125;:&#123;filed&#125;
MSET user:1:name zhangsan
MSET user:1:age 2

#组合命令
GETSET [key-value] # 先get再set.如果存在值，获取原来的值并设置新的值
</code></pre>
<p>使用场景：value除了是字符串之外，还可以是数字</p>
<ul>
<li>计数器</li>
<li>统计多单位的数量</li>
<li>粉丝数</li>
<li>对象缓存存储</li>
</ul>
<h3 id="List-列表"><a href="#List-列表" class="headerlink" title="List(列表)"></a>List(列表)</h3><p>在Redis里面，可以把List做成栈、队列、阻塞队列</p>
<p><strong>所有的list命令基本都是L开头的</strong></p>
<pre><code class="bash">LPUSH [key] [element ...] # 放入一个或多个值，插入到列表的头部
RPUSH [key] [element ...] # 放入一个或多个值，插入到列表的尾部
LRANGE [key] [start] [stop] # 取start到stop的值，stop为-1时，取全部值
LSET [key] [index] [value] # 将下标为index的值替换为value，如果key中的index不存在，则ERROR，可以用其修改某个值，不能插入值！
Linsert [key] [BEFORE|AFTER] [pivot] [value] # 在值为&quot;pivot&quot;的(前面|后面)添加一个value 

LPOP [key] [count] # 移除从头部起第count个值，缺省count时默认第一个值
RPOP [key] [count] # 移除从尾部起第count个值，缺省count时默认第一个值
LREM [key] [count] [element] # 移除指定的值。移除key中的count个element值。

LINDEX [key] [index] # 通过下标获得list中的某一个值
LLEN # 获取list长度

TRIM [key] [start] [stop] # 修剪key从start到stop的值，可以做一个截断操作，截取指定的区间内的值，但是这个list已经被改变了，只剩下截取的元素了

RPOPLPUSH [source] [destination] # 将source的尾部第一个值，放入新的列表destination的头部
</code></pre>
<blockquote>
<p>小结</p>
</blockquote>
<p>实际上是一个链表，before Node ，left，right都可以插入值</p>
<p>如果key不存在就创建新的链表</p>
<p>如果key存在就新增内容</p>
<p>如果移除了key，所有的value都会消失</p>
<p>用途：</p>
<ul>
<li>消息队列：Lpush Rpop  </li>
<li> 栈 ： Lpush Lpop</li>
</ul>
<h3 id="Set-集合"><a href="#Set-集合" class="headerlink" title="Set(集合)"></a>Set(集合)</h3><p>set中的值是不能重复的</p>
<pre><code class="bash">Sadd [key] [member] # set集合中插入member

Srem [key] [member] # 移除集合key中的member值
Spop [key] # 随机删除集合中的元素
Smove [source] [destination] [element] # 将element值从集合source移动到集合destination

SMEMBERS [key] #查看key的所有值
SISMEMBER [key] [member] # 查看key中是否包含member值
SRANDMEMBER [key] [value] # 随机抽出集合key中value个元素

Scard [key] # 获取集合key中的元素个数

#### 微博、B站，共同关注！(并集)
#### 数字集合类
# - 差集
# - 交集
# - 并集
SDIFF [key ...] # key1 key2 ... 的差集
SINTER [key ...] # key1 key2 ... 的交集。 共同好友的实现
SUNION [key ...] # key1 key2 ... 的并集
</code></pre>
<blockquote>
<p>用途</p>
</blockquote>
<p>共同关注的实现：将用户所有关注的人放在一个set集合中，将它的粉丝也放在一个集合中</p>
<p>共同关注，共同爱好，二度好友，推荐好友(六度分隔理论)</p>
<h3 id="Hash-哈希"><a href="#Hash-哈希" class="headerlink" title="Hash(哈希)"></a>Hash(哈希)</h3><p>Map集合，key-map 这个值是一个map集合</p>
<pre><code class="bash">HSET [key] [field-value] # 在哈希集合key中放入字段field及其值value
HGET [key] [field] # 取出哈希集合key中的field字段
HMSET [key] [field] [value] [filed value ...] # set多个key-value
HMGET [key] [field ...] # 获取哈希集合key的多个field字段
HGETALL # 获取全部的数据

HDEL [key] [field ...] # 删除哈希集合key中的field字段
HLEN [key] # 获取哈希集合key的字段数量
HEXISTS [key] [field] # 判断哈希集合key中是否存在field字段
HKEYS [key] # 只获得所有的field
HVALS [key] # 只获得所有的value

####Hash的自增 自减
HINCRBY [key] [field] [increment] # 哈希集合key的field字段自增increment

HSETNX [key] [field] [value] # 如果不存在则可以设置，如果存在则不能设置
</code></pre>
<blockquote>
<p>应用</p>
</blockquote>
<p>变更的数据user name age等尤其是用户信息制类的，经常变动的信息！</p>
<p>Hash更适合对象的存储</p>
<p>String更适合字符串存储</p>
<h3 id="Zset-有序集合"><a href="#Zset-有序集合" class="headerlink" title="Zset(有序集合)"></a>Zset(有序集合)</h3><p>在Set的基础上，增加了一个值</p>
<pre><code class="bash">Zadd [key] [NX|XX] [GT|LT] [CH] [INCR] [score member ...] # 
ZRANGEBYSCORE [key] [min] [max] [withscores] [limit offset count] #
#inf 代表无穷
ZRANGEBYSCORE [key] -inf +inf # 显示全部用户，从小到大
ZRANGEBYSCORE [key] -inf +inf withscores # 显示全部用户，从小到大,并附带score值
ZREVRANGE [key] [start] [stop] [withscores] # 排序
ZREVRANGE [key] 0 -1 [withscores] # 从大到小
Zrem [key] [member ...] # 移除有序集合key中的member元素
Zcard [key] # 获取有序集合key中的个数

Zcount [key] [min] [max] # 获取Key中指定区间的成员数量
</code></pre>
<blockquote>
<p>案例思路</p>
</blockquote>
<p>set 排序 存储班级成绩表，工资表排序</p>
<p>普通消息：1.重要消息 2.带权重进行判断</p>
<p>排行榜应用Top榜</p>
<h2 id="2-2-三大特殊数据类型"><a href="#2-2-三大特殊数据类型" class="headerlink" title="2.2 三大特殊数据类型"></a>2.2 三大特殊数据类型</h2><h3 id="geospatial-地理位置"><a href="#geospatial-地理位置" class="headerlink" title="geospatial 地理位置"></a>geospatial 地理位置</h3><blockquote>
<p>用途</p>
</blockquote>
<p>Redis的Geo：可以推算地理位置的信息，两地之间的距离，方圆几里内的人 </p>
<ul>
<li><p>朋友的定位</p>
</li>
<li><p>附近的人</p>
</li>
<li><p>打车距离计算</p>
</li>
</ul>
<p>可以查询一些测试数据</p>
<pre><code class="bash"># 添加地理位置，规则：两级无法直接添加，我们一般会下载城市数据，直接通过Java程序一次性导入
# 参数: key 纬度 经度 名称
GEOADD
# 获取指定的城市的精度和维度
# 参数: key element
GEOPOS
# m：米  km：千米  mi：英里 ft：为英尺。
# 参数: [key] [element1] [element2] [unit]
GEODIST
# 以一个经纬度为中心，半径radius内的元素
# 参数: key 经度 纬度 radius withdist(显示到中心距离的位置) withcoord(显示他人的定位信息) count
GEORADIUS
# 以一个元素坐标为中心，半径radius内的元素
# 参数: key element radius withdist withcoord count
GEORADIUSBYMEMBER
# 了解,返回11个字符的Geohash字符串。将二位的经纬度转换为以为的字符串，如果两个字符串越接近，那么距离越近
GEOHASH
</code></pre>
<blockquote>
<p>GEO底层实现原理其实就是Zset，我们可以使用Zset命令操作GEO</p>
</blockquote>
<h3 id="Hyperloglog"><a href="#Hyperloglog" class="headerlink" title="Hyperloglog"></a>Hyperloglog</h3><blockquote>
<p>什么是基数</p>
</blockquote>
<p>A{1,3,5,7,8,9,}  </p>
<p>B{1,3,5,7,8}</p>
<p>基数(不重复的元素)： = 5 </p>
<blockquote>
<p>简介</p>
</blockquote>
<p>Redis Hyperloglog基数统计的算法!</p>
<p>网页的UV ( 一个人访问一个网站多次,但是还是算作一个人! )<br>传统的方式，set 保存用户的id ,然后就可以统计set中的元素数量作为标准怕段</p>
<p>这个方式如果保存大量的用户id ,就会比较麻烦!我们的目的是为了计数，而不是保存用户Id</p>
<pre><code class="bash">PFadd [key] [element ...] # 加入元素
PFCOUNT [key] # 统计key中的基数数量
PFMERGE [key1] [key2] [newkey] # 合并key1和key2为key3
</code></pre>
<p>但Hyperloglog不会特别精确。精确率在81%左右</p>
<p>原理：HyperLogLog基于概率论中伯努利试验并结合了极大似然估算方法，并做了分桶优化。</p>
<p>Redis中，12KB的桶，共16384(2^14^)个桶，每个桶6bit</p>
<p>64位的bit串，14bit定位桶，假设</p>
<blockquote>
<p>用途</p>
</blockquote>
<p>允许一定的容错</p>
<ul>
<li>网页UV 计数<ol>
<li>转化为一个比特串 hash函数</li>
<li>分桶(大的位数组) 如，100100 00 -&gt; 0号桶  100100 11-&gt; 3号桶</li>
<li></li>
</ol>
</li>
</ul>
<p>如果不允许容错，就要使用set或其他自定义的数据类型。</p>
<p>UV（独立访客），需要去重：UV是网站的用户访问量，访问您网站的一台电脑客户端为一个访客</p>
<p>PV：即页面浏览量，或点击量；用户每1次对网站中的每个网页访问均被记录1次。</p>
<h3 id="Bitmap-位存储"><a href="#Bitmap-位存储" class="headerlink" title="Bitmap(位存储)"></a>Bitmap(位存储)</h3><blockquote>
<p>用途</p>
</blockquote>
<p>统计用户信息：活跃、不活跃；登录、未登录；365天的打卡等，涉及到两个状态的都可以使用。</p>
<p>Bitmap位图，数据结构！都是操作二进制位来进行记录，只有0和1两个状态</p>
<pre><code class="bash">setbit
getbit
bitcount
</code></pre>
<h1 id="三、Redis事务"><a href="#三、Redis事务" class="headerlink" title="三、Redis事务"></a>三、Redis事务</h1><p><em>MySQL：ACID 其中，原子性：要么同时成功，要么同时失败</em></p>
<p><strong>Redis的单条指令可以保证原子性，但是事务不保证原子性</strong></p>
<p><strong>Redis事务没有隔离级别的概念</strong> ：所有的命令在事务中，并没有直接被执行，只有发起执行命令的时候才会执行。</p>
<p>Redis事务的本质：一组命令的集合 ！一个事务中的所有命令都会被序列化，在事务执行的过程中，会按照顺序执行！</p>
<p>一次性、顺序性、排他性 –&gt;执行一些列的命令</p>
<h2 id="3-1-事务"><a href="#3-1-事务" class="headerlink" title="3.1 事务"></a>3.1 事务</h2><blockquote>
<p>正常执行事务</p>
</blockquote>
<p>Redis的事务：</p>
<ul>
<li><p>开启事务( Multi )</p>
</li>
<li><p>命令入队( … )</p>
</li>
<li><p>执行事务( Exec )</p>
</li>
<li><p>事务结束</p>
</li>
</ul>
<blockquote>
<p>放弃事务</p>
</blockquote>
<p>DISCARD</p>
<p>放弃后，事务中的队列中的命令都不会执行。</p>
<blockquote>
<p>编译型异常(代码有问题！命令有错) </p>
</blockquote>
<p>事务中所有的命令都不会被执行</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210830200701579.png" alt="image-20210830200701579"></p>
<blockquote>
<p>运行时异常(1/0)</p>
</blockquote>
<p>如果事务队列中存在语法型错误，那么执行命令的时候，其他命令可以正常执行</p>
<p>，错误命令抛出异常。</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210830201004303.png" alt="image-20210830201004303"></p>
<p>虽然第一条命令报错了，但是依旧正常执行成功了。</p>
<h2 id="3-2-乐观锁"><a href="#3-2-乐观锁" class="headerlink" title="3.2 乐观锁"></a>3.2 乐观锁</h2><blockquote>
<p>MySQL的锁</p>
</blockquote>
<p><strong>悲观锁</strong> ：认为什么时候都会出问题，无论做什么都会加锁。</p>
<p><strong>乐观锁</strong> ：认为什么时候都不会出问题，所以不会上锁。更新数据的时候去判断一下，在此期间是否有人修改过数据，version字段。获取version，更新的时候比较version。</p>
<blockquote>
<p>Redis监控</p>
</blockquote>
<p>正常执行成功：</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210830201652688.png" alt="image-20210830201652688"></p>
<p>测试多线程修改值，使用watch可以当作Redis的乐观锁操作</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210830202701786.png" alt="image-20210830202701786"></p>
<p>如果修改失败，获取最新的值即可</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210830202722745.png" alt="image-20210830202722745"></p>
<blockquote>
<p> 面试常问</p>
</blockquote>
<p>Redis可以写乐观锁</p>
<h1 id="四、Jedis"><a href="#四、Jedis" class="headerlink" title="四、Jedis"></a>四、Jedis</h1><p>使用Java操作Redis</p>
<blockquote>
<p>Jedis是Redis官方推荐的Java连接开发工具，使用Java操作Redis的中间件，如果使用Java操作Redis，就一定要对Jedis十分的熟悉</p>
</blockquote>
<p>1、导入依赖</p>
<pre><code class="xml">&lt;!--        Jedis--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;redis.clients&lt;/groupId&gt;
    &lt;artifactId&gt;jedis&lt;/artifactId&gt;
    &lt;version&gt;3.2.0&lt;/version&gt;
&lt;/dependency&gt;
&lt;!--        fastjson--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
    &lt;artifactId&gt;fastjson&lt;/artifactId&gt;
    &lt;version&gt;1.2.76&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>2、编码测试</p>
<ul>
<li>连接数据库</li>
<li>操作命令</li>
<li>断开连接</li>
</ul>
<pre><code class="java">//1. new Jedis对象
Jedis jedis = new Jedis(&quot;127.0.0.1&quot;, 6379);
//Jedis所有的命令就是之前的Redis指令
</code></pre>
<h2 id="4-1-常用API"><a href="#4-1-常用API" class="headerlink" title="4.1 常用API"></a>4.1 常用API</h2><ul>
<li>String</li>
<li>List</li>
<li>Set</li>
<li>Hash</li>
<li>Zset</li>
</ul>
<p>同前方指令</p>
<h2 id="4-2-通过Jedis理解事务"><a href="#4-2-通过Jedis理解事务" class="headerlink" title="4.2 通过Jedis理解事务"></a>4.2 通过Jedis理解事务</h2><pre><code class="java">//开启事务
Transaction multi = jedis.multi();

try &#123;
    multi.set(&quot;user1&quot;,result);//测试命令1
    multi.set(&quot;user2&quot;,result);//测试命令2
    multi.exec();//执行事务
&#125;catch (Exception e)&#123;
    multi.discard();//放弃事务
    e.printStackTrace();
&#125;finally &#123;
    jedis.close();//关闭连接
&#125;
</code></pre>
<h1 id="五、SpringBoot整合Redis"><a href="#五、SpringBoot整合Redis" class="headerlink" title="五、SpringBoot整合Redis"></a>五、SpringBoot整合Redis</h1><p>SpringData也是和SpringBoot齐名的项目</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210830221242874.png" alt="image-20210830221242874"></p>
<p>==说明：在SpringBoot2.x之后，原来使用的jedis被替换成了lettuce==</p>
<ul>
<li>jedis ： 采用的直连，多个线程操作的话是不安全的，如果想要避免不安全的，使用jedis pool连接池。更像BIO模式</li>
<li>lettuce：采用netty，实例可以在多个线程中进行共享，不存在线程不安全的情况，可以减少线程数量，更像Nio模式</li>
</ul>
<h2 id="5-1-源码解析"><a href="#5-1-源码解析" class="headerlink" title="5.1 源码解析"></a>5.1 源码解析</h2><ul>
<li><p>SpringBoot所有的配置类，都有一个自动配置类 ：<strong>RedisAutoConfiguration</strong></p>
</li>
<li><p>自动配置类都会绑定一个properties配置文件 ：<strong>RedisProperties</strong></p>
</li>
</ul>
<pre><code class="java">@Bean
@ConditionalOnMissingBean(name = &quot;redisTemplate&quot;)//我们可以自定义一个RedisTemplate来替换这个默认的
@ConditionalOnSingleCandidate(RedisConnectionFactory.class)
public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) &#123;
    //默认的RedisTemplate没有过多的设置，redis对象都是需要序列化！
    //两个泛型都是Object的类型，后面使用需要强制转换成&lt;String,Object&gt;
    RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;();
    template.setConnectionFactory(redisConnectionFactory);
    return template;
&#125;

@Bean
@ConditionalOnMissingBean //由于String是Redis中最常使用的类型，所以单独提出来了一个Bean
@ConditionalOnSingleCandidate(RedisConnectionFactory.class)
public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) &#123;
    StringRedisTemplate template = new StringRedisTemplate();
    template.setConnectionFactory(redisConnectionFactory);
    return template;
&#125;
</code></pre>
<p><em>ConditionalOnMissingBean:当这个方法不存在时，使用这里的方法</em></p>
<h2 id="5-2-整合测试"><a href="#5-2-整合测试" class="headerlink" title="5.2 整合测试"></a>5.2 整合测试</h2><p>1、导入依赖</p>
<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p>2、配置文件</p>
<pre><code class="yaml">spring:
  redis:
    host: 127.0.0.1
    port: 6379
</code></pre>
<p>3、Junit测试</p>
<pre><code class="java">@Test
void contextLoads() &#123;
    /* redisTemplate 操作不同数据类型的API*/
    //opsForValue 操作字符串 类似String
    //opsForList 操作List 类似List
    //....
    //每一个操作对应一个数据类型 opsForXxx
    redisTemplate.opsForValue();

    /* 获取Redis连接 */
    RedisConnection connection = redisTemplate.getConnectionFactory().getConnection();
    //        connection.flushDb();
    //        connection.flushAll();

&#125;
</code></pre>
<p>==在开发中很少使用这些原生的方式去编写代码，通常写一个RedisUtils写一个工具类.==</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210831093100444.png" alt="image-20210831093100444"></p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210831093356666.png" alt="image-20210831093356666"></p>
<p>默认的序列化方式是JDK序列化，我们可能会使用Json来序列化。</p>
<p>所有对象也需要序列化，否则无法进行序列化处理。</p>
<p><strong>所以我们需要自定义一个配置类</strong></p>
<h2 id="5-3-自定义RedisTemplate"><a href="#5-3-自定义RedisTemplate" class="headerlink" title="5.3 自定义RedisTemplate"></a>5.3 自定义RedisTemplate</h2><pre><code class="java">package com.skyfroop.config;

import com.fasterxml.jackson.annotation.JsonAutoDetect;
import com.fasterxml.jackson.annotation.PropertyAccessor;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;
import org.springframework.data.redis.serializer.StringRedisSerializer;

import java.net.UnknownHostException;

/**
 *
 * @Description TODO RedisConfig 固定模板,可直接使用
 * @Create: by SkyFroop
 */
@Configuration
public class RedisConfig &#123;

    @Bean
    public RedisTemplate&lt;String,Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException&#123;
        //为了开发方便，一般直接使用&lt;String,Object&gt;
        RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;();
        template.setConnectionFactory(redisConnectionFactory);

        // Json序列化配置
        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);
        ObjectMapper objectMapper = new ObjectMapper();
        objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY)
                    .enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);
        jackson2JsonRedisSerializer.setObjectMapper(objectMapper);
        //String的序列化
        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();

        //key采用String的序列化方式
        template.setKeySerializer(stringRedisSerializer);
        //Hash的key采用String的序列化方式
        template.setHashKeySerializer(stringRedisSerializer);
        //value序列化方式采用jackson
        template.setValueSerializer(jackson2JsonRedisSerializer);
        //Hash的value序列化方式采用Jackson
        template.setHashValueSerializer(jackson2JsonRedisSerializer);

        template.afterPropertiesSet();// 生效配置

        return template;
    &#125;

&#125;
</code></pre>
<h2 id="5-4-RedisUtil工具包-当前版本仅包含常用命令"><a href="#5-4-RedisUtil工具包-当前版本仅包含常用命令" class="headerlink" title="5.4 RedisUtil工具包(当前版本仅包含常用命令)"></a>5.4 RedisUtil工具包(当前版本仅包含常用命令)</h2><pre><code class="java">import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.stereotype.Component;
import org.springframework.util.CollectionUtils;

import java.util.Collection;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.TimeUnit;

/**
 *
 * @Description TODO Redis工具类
 * @Create: Power By SkyFroop(HAN XIAOJIE)
 *
 */
@Component
public final class RedisUtil &#123;
    @Autowired
    private RedisTemplate&lt;String,Object&gt; redisTemplatel;

    //====================================common====================================

    /**
     * 指定缓存失效时间
     * @param key 键
     * @param time 时间(秒)
     * */
    public boolean expire(String key,long time)&#123;
        try&#123;
            if(time &gt; 0)&#123;
                redisTemplatel.expire(key,time, TimeUnit.SECONDS);
            &#125;
            return true;
        &#125;catch (Exception e)&#123;
            e.printStackTrace();
            return false;
        &#125;
    &#125;

    /**
     * 根据key 获取过期时间
     * @param key 键 NOT NULL
     * @return 时间(秒) 返回0代表永久有效
     * */
    public long getExpire(String key)&#123;
        return redisTemplatel.getExpire(key,TimeUnit.SECONDS);
    &#125;

    /**
     * 判断key是否存在
     * @param key 键
     * @return true 存在 false 不存在
     * */
    public boolean hasKey(String key)&#123;
        try &#123;
            return redisTemplatel.hasKey(key);
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return false;
        &#125;
    &#125;

    /**
     * 删除缓存
     * @param key one or more...
     * */
    public void del(String ...key)&#123;
        if (key != null &amp;&amp; key.length &gt; 0)&#123;
            if(key.length == 1)&#123;
                redisTemplatel.delete(key[0]);
            &#125;else&#123;
                redisTemplatel.delete((Collection&lt;String&gt;) CollectionUtils.arrayToList(key));
            &#125;
        &#125;
    &#125;

    //====================================String====================================

    /**
     * 普通缓存获取
     * @param key 键
     * @return value
     * */
    public Object get(String key)&#123;
        return key == null ? null : redisTemplatel.opsForValue().get(key);
    &#125;

    /**
     * 普通缓存放入
     * @param key 键
     * @param value 值
     * @return true 成功 false 失败
     * */
    public boolean set(String key,Object value)&#123;
        try &#123;
            redisTemplatel.opsForValue().set(key,value);
            return true;
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return false;
        &#125;
    &#125;

    /**
     * 普通缓存放入并设置时间
     * @param key 键
     * @param value 值
     * @param time 时间(秒) time 应大于0，如果time小于等于0将设置无暇去你
     * @return true 成功 false 失败
     * */
    public boolean set(String key,Object value,long time)&#123;
        try &#123;
            if (time &gt; 0)&#123;
                redisTemplatel.opsForValue().set(key,value,time,TimeUnit.SECONDS);
            &#125;else &#123;
                set(key,value);
            &#125;
            return true;
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return false;
        &#125;
    &#125;

    /**
     * 单调递增
     * @param key 键
     * @param delta 步长
     * */
    public long incr(String key,long delta)&#123;
        if (delta &lt; 0)&#123;
            throw new RuntimeException(&quot;递增因子必须大于0&quot;);
        &#125;
        return redisTemplatel.opsForValue().increment(key,delta);
    &#125;

    /**
     * 单调递减
     * @param key 键
     * @param delta 步长
     * */
    public long decr(String key,long delta)&#123;
        if (delta &lt; 0)&#123;
            throw new RuntimeException(&quot;递减因子必须大于0&quot;);
        &#125;
        return redisTemplatel.opsForValue().decrement(key,delta);
    &#125;

    //==================================== Map ====================================

    /**
     * HashGet
     * @param key 键 NOT NULL
     * @param item 项 NOT NULL
     * */
    public Object hget(String key,String item)&#123;
        return redisTemplatel.opsForHash().get(key,item);
    &#125;

    /**
     * 获取HashKey对应的所有键值
     * @param key 键
     * @return 对应的多个键值
     * */
    public Map&lt;Object,Object&gt; hmget(String key)&#123;
        return redisTemplatel.opsForHash().entries(key);
    &#125;

    /**
     * HashSet
     * @param key 值
     * @param map 对应多个键值
     * */
    public boolean hmset(String key,Map&lt;String,Object&gt; map)&#123;
        try &#123;
            redisTemplatel.opsForHash().putAll(key,map);
            return true;
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return false;
        &#125;
    &#125;

    /**
     * HashSet 并设置过期时间
     * @param key 值
     * @param map 对应多个键值
     * @param time 时间(秒)
     * */
    public boolean hmset(String key,Map&lt;String,Object&gt; map,long time)&#123;
        try &#123;
            redisTemplatel.opsForHash().putAll(key,map);
            if(time&gt;0)&#123;
                expire(key,time);
            &#125;
            return true;
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return false;
        &#125;
    &#125;

    /**
     * 向一张Hash放入数据,如果不存在将创建数据
     * @param key 键
     * @param item 项
     * @param value 值
     * */
    public boolean hset(String key,String item,Object value)&#123;
        try &#123;
            redisTemplatel.opsForHash().put(key,item,value);
            return true;
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return false;
        &#125;
    &#125;

    /**
     * 向一张Hash放入数据,如果不存在将创建数据,同时设置过期时间
     * @param key 键
     * @param item 项
     * @param value 值
     * @param time 时间(秒) 注意：如果已存在的Hash表有时间,这里将会是替换原有时间
     * */
    public boolean hset(String key,String item,Object value,long time)&#123;
        try &#123;
            redisTemplatel.opsForHash().put(key,item,value);
            if (time &gt; 0)&#123;
                expire(key,time);
            &#125;
            return true;
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return false;
        &#125;
    &#125;

    /**
     * 删除Hash中的值
     *
     * @param key 键 NOT NULL
     * @param item 项 one or more NOT NULL
     * */
    public void hdel(String key ,Object... item)&#123;
        redisTemplatel.opsForHash().delete(key,item);
    &#125;

    /**
     * 判断Hash中是否有该项的值
     * @param key 键
     * @param item 项
     * */
    public boolean hHasKey(String key,String item)&#123;
        return redisTemplatel.opsForHash().hasKey(key,item);
    &#125;

    /**
     * Hash 单调递增 如果不存在，就会创建一个，并把新增后的值返回
     * @param key 键
     * @param item 项
     * @param by 步长
     * */
    public double hincr(String key,String item,double by)&#123;
        return redisTemplatel.opsForHash().increment(key,item,by);
    &#125;

    /**
     * Hash 单调递减
     * @param key 键
     * @param item 项
     * @param by 步长
     * */
    public double hdecr(String key,String item,double by)&#123;
        return redisTemplatel.opsForHash().increment(key,item,-by);
    &#125;

    //==================================== Set ====================================

    /**
     * 根据key获取Set所有值
     * @param key 键
     * */
    public Set&lt;Object&gt; sGet(String key)&#123;
        try &#123;
            return redisTemplatel.opsForSet().members(key);
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return null;
        &#125;
    &#125;

    /**
     * 从Set中查询是否存在value
     * @param key 键
     * @param value 值
     * */
    public boolean sHasKey(String key,Object value)&#123;
        try &#123;
            return redisTemplatel.opsForSet().isMember(key,value);
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return false;
        &#125;
    &#125;

    /**
     * 将数据放入Set缓存
     * @param key 键
     * @param values 值 one or more
     * @return 成功个数
     * */
    public long sSet(String key,Object... values)&#123;
        try &#123;
            return redisTemplatel.opsForSet().add(key,values);
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return 0;
        &#125;
    &#125;

    /**
     * 将数据放入Set缓存,并设置过期时间
     * @param key 键
     * @param time 时间(秒)
     * @param values 值 one or more
     * @return 成功个数
     * */
    public long sSet(String key,long time,Object... values)&#123;
        try &#123;
            Long count = redisTemplatel.opsForSet().add(key, values);
            if(time &gt; 0)&#123;
                expire(key,time);
            &#125;
            return count;
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return 0;
        &#125;
    &#125;

    /**
     * 获取Set缓存长度
     * @param key 键
     * @return Set缓存长度
     * */
    public long sGetSetSize(String key)&#123;
        try &#123;
            return redisTemplatel.opsForSet().size(key);
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return 0;
        &#125;
    &#125;

    /**
     * 从Set中移除值为value的项
     * @param key 键
     * @param values 值 one or more
     * @return 移除的个数
     * */
    public long setRemove(String key,Object... values)&#123;
        try &#123;
            return redisTemplatel.opsForSet().remove(key, values);
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return 0;
        &#125;
    &#125;

    //==================================== List ====================================

    /**
     * 获取list缓存的长度
     * @param key 键
     * */
    public long lGetListSize(String key)&#123;
        try &#123;
            return redisTemplatel.opsForList().size(key);
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return 0;
        &#125;
    &#125;

    /**
     * 通过索引获取list中的值
     * @param key 键
     * @param index 索引
     * @Description index &gt;= 0时, 0为表头索引,index &lt; 0时,-1为表尾,-2为到数第二个元素...
     * */
    public Object lGetIndex(String key,long index)&#123;
        try &#123;
            return redisTemplatel.opsForList().index(key,index);
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return null;
        &#125;
    &#125;

    /**
     * 将List放入缓存
     * @param key 键
     * @param value 值
     * */
    public boolean lSet(String key,Object value)&#123;
        try &#123;
            redisTemplatel.opsForList().rightPush(key,value);
            return true;
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return false;
        &#125;
    &#125;

    /**
     * 将List放入缓存,并设置过期时间
     * @param key 键
     * @param value 值
     * @param time 时间(秒)
     * */
    public boolean lSet(String key,Object value,long time)&#123;
        try &#123;
            redisTemplatel.opsForList().rightPush(key,value);
            if (time &gt; 0)&#123;
                expire(key,time);
            &#125;
            return true;
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return false;
        &#125;
    &#125;

    /**
     * 将List&lt;&gt;放入缓存
     * @param key 键
     * @param value 值
     * */
    public boolean lSet(String key, List&lt;Object&gt; value)&#123;
        try &#123;
            redisTemplatel.opsForList().rightPushAll(key,value);
            return true;
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return false;
        &#125;
    &#125;

    /**
     * 将List&lt;&gt;放放入缓存,并设置过期时间
     * @param key 键
     * @param value 值
     * @param time 时间(秒)
     * */
    public boolean lSet(String key,List&lt;Object&gt; value,long time)&#123;
        try &#123;
            redisTemplatel.opsForList().rightPush(key,value);
            if (time &gt; 0)&#123;
                expire(key,time);
            &#125;
            return true;
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return false;
        &#125;
    &#125;

    /**
     * 根据索引修改List中的某条数据
     *
     * @param key 键
     * @param index 索引
     * @param value 值
     * */
    public boolean lUpdateIndex(String key,long index,Object value)&#123;
        try &#123;
            redisTemplatel.opsForList().set(key, index, value);
            return true;
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return false;
        &#125;
    &#125;

    /**
     * 移除N个值为value
     * @param key 键
     * @param count 移除数量
     * @param value 值
     * @return 移除的个数
     * */
    public long lRemove(String key,long count,Object value)&#123;
        try &#123;
            Long removeCount = redisTemplatel.opsForList().remove(key, count, value);
            return removeCount;
        &#125; catch (Exception e) &#123;
            e.printStackTrace();
            return 0;
        &#125;
    &#125;

    //==================================== Zset ====================================


    //====================================Geospatial====================================


    //====================================Hyperloglog====================================


    //====================================Bitmap====================================


&#125;
</code></pre>
<h1 id="六、Redis-conf详解"><a href="#六、Redis-conf详解" class="headerlink" title="六、Redis.conf详解"></a>六、Redis.conf详解</h1><p>Redis启动的时候，就通过配置文件来启动。</p>
<blockquote>
<p> <strong>单位</strong></p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210831154709474.png" alt="image-20210831154709474"></p>
<ol>
<li>配置文件unit单位对大小写不敏感，拥有这几种单位</li>
</ol>
<blockquote>
<p><strong>包含</strong></p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210831154814995.png" alt="image-20210831154814995"></p>
<blockquote>
<p><strong>网络</strong></p>
</blockquote>
<pre><code class="bash">bind 127.0.0.1 -::1 # 绑定IP
protected-mode yes # 保护模式
port 6379 # 端口设置
</code></pre>
<blockquote>
<p><strong>通用</strong>( GENERAL)</p>
</blockquote>
<pre><code class="bash">daemonize yes # 以守护进程的方式运行，默认为no，需要修改为yes
pidfile /var/run/redis_6379.pid # 如果以后台的方式运行(守护进程)，我们就需要指定一个pid文件

#日志
# Specify the server verbosity level.
# This can be one of:
# debug (a lot of information, useful for development/testing)
# verbose (many rarely useful info, but not a mess like the debug level)
# notice (moderately verbose, what you want in production probably) 生产环境使用
# warning (only very important / critical messages are logged)
loglevel notice
logfile &quot;&quot; # 日志的输出文件名

databases 16 # 数据库的数量，默认是16个
always-show-logo no # 是否显示Redis的Logo
</code></pre>
<blockquote>
<p><strong>快照</strong> ( SNAPSHOTTING )</p>
</blockquote>
<p>持久化，在规定的时间内，执行了多少次操作，则会持久化到文件(.rdb ; .aof)</p>
<p>Redis是内存数据库，如果没有持久化，那么数据断电即失</p>
<pre><code class="bash"># 如果3600秒内，如果至少有1个key进行了修改，我们即使进行持久化操作
save 3600 1 
#如果300秒内，如果至少有100个key进行了修改，我们即使进行持久化操作
save 300 100
#如果60秒内，如果至少有10000个key进行了修改，我们即使进行持久化操作
save 60 10000

stop-writes-on-bgsave-error yes # 持久化如果出错，是否需要继续工作
rdbcompression yes # 是否压缩rdb资源(需要消耗一些CPU资源)
rdbchecksum yes # 保存rdb文件的时候，进行错误的检查校验
dir ./ # rdb文件默认的保存目录，默认是在当前文件夹下
dbfilename dump.rdb # rdb的默认文件名
</code></pre>
<blockquote>
<p><strong>复制</strong> ( REPLICATION )</p>
</blockquote>
<pre><code class="bash">replicaof &lt;masterip&gt; &lt;masterport&gt; # 从机设置
</code></pre>
<blockquote>
<p><strong>安全</strong> ( SECURITY )</p>
</blockquote>
<pre><code class="bash">requirepass 密码 # 设置密码
##密码设置命令
config set requirepass &quot;密码&quot;
##认证
auth 密码

</code></pre>
<blockquote>
<p><strong>限制</strong> ( CLIENTS )</p>
</blockquote>
<pre><code class="bash">maxclients 10000 # 设置能连接上Redis的最大客户端的数量
</code></pre>
<blockquote>
<p><strong>内存</strong> ( MEMORY MANAGEMENT )</p>
</blockquote>
<pre><code class="bash">maxmemory &lt;bytes&gt; # 最大的内存容量
maxmemory-policy noeviction # 内存达到上限之后的处理策略
                            # 移除一些过期的key 也可能报错
</code></pre>
<p>内存达到上限后的处理策略:</p>
<ul>
<li>volatile-lru:只对设置了过期时间的key进行LRU(默认值)</li>
<li>allkeys-lru :删除1ru算法的key</li>
<li>volatile-random:随机删除即将过期key</li>
<li>allkeys-random:随机删除</li>
<li>volatile-ttl :刮|除即将过期的</li>
<li>noeviction :永不过期,返回错误</li>
</ul>
<blockquote>
<p><strong>APPEND ONLY模式</strong> (AOF)</p>
</blockquote>
<pre><code class="bash">appendonly no # 默认不开启aof模式，默认使用的是rdb方式持久化，在大部分情况下，rdb完全够用
appendfilename &quot;appendonly.aof&quot; # 持久化的文件的名字

# appendfsync always # 每次修改都会sync
appendfsync everysec # 每秒执行一次sync,可能会丢失这1秒的数据,默认
# appendfsync no     # 不同步,这个时候操作系统自己同步数据，速度最快
</code></pre>
<h1 id="七、Redis持久化"><a href="#七、Redis持久化" class="headerlink" title="七、Redis持久化"></a>七、Redis持久化</h1><p>Redis是内存数据库，如果不将内存中的数据库状态保存到磁盘，那么一旦服务器进程退出，服务器中的数据库状态也会消失。所以Redis提供了持久化功能!</p>
<p>==面试和工作，持久化都是重点==</p>
<ul>
<li>AOF :( append only file )持久化以独立日志的方式记录每次写命令，并在 Redis 重启时在重新执行 AOF 文件中的命令以达到恢复数据的目的。AOF 的主要作用是解决数据持久化的实时性。</li>
<li>RDB :把当前 Redis 进程的数据生成时间点快照( point-in-time snapshot ) 保存到存储设备的过程。</li>
</ul>
<h2 id="7-1-RDB-Redis-DateBase"><a href="#7-1-RDB-Redis-DateBase" class="headerlink" title="7.1 RDB ( Redis DateBase )"></a>7.1 RDB ( Redis DateBase )</h2><p>在主从复制中rdb就是备用了，从机上面</p>
<blockquote>
<p>什么是RDB</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210831194739533.png" alt="image-20210831194739533"></p>
<p>在指定的时间间隔内将内存中的数据集快照写入磁盘.也就是行话讲的Snapshot快照,它恢复时是将快照文件直接读到内存里。<br>Redis会单独创建( fork ) 一个子进程来进行持久化.会先将数据写入到一个临时文件中。待持久化过程都结束了,再用这个临时文件替换上次持久化好的文件。整个过程中,主进程是不进行任何0操作的。这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感,那RDB方式要比AOF方式更加的高效。RDB的缺点是最后- 次持久化后的数据可能丢失。</p>
<p>==rdb保存的文件是dump.rdb==</p>
<p>生产环境，我们会将这个文件进行备份</p>
<blockquote>
<p>触发机制</p>
</blockquote>
<ol>
<li>save 的规则满足的情况下，会自动触发rdb规则</li>
<li>执行flushall命令，也会触发我们的rdb规则</li>
<li>退出redis，也会产生rdb文件</li>
</ol>
<p>备份就会自动生成一个dump.rdb文件</p>
<blockquote>
<p>如何恢复rdb文件</p>
</blockquote>
<p>只需要将rdb文件放到Redis启动目录就可以了，redis启动时会自动检查dump.rdb回符其中的数据</p>
<p>==几乎自己的默认配置就足够用了==</p>
<blockquote>
<p>优点</p>
</blockquote>
<ol>
<li>适合大规模的数据恢复</li>
<li>对数据的完整性不高</li>
</ol>
<blockquote>
<p>缺点</p>
</blockquote>
<ol>
<li>，需要一定的时间间隔，如果redis意外宕机，最后一次修改的数据就没有了</li>
<li>fork进程的时候，会占用一定的内存空间</li>
</ol>
<h2 id="7-2-AOF-Append-Only-File"><a href="#7-2-AOF-Append-Only-File" class="headerlink" title="7.2 AOF ( Append Only File )"></a>7.2 AOF ( Append Only File )</h2><p>将我们的所有命令都记录下来，history，恢复的时候就把这个文件全部进行一遍</p>
<p>以日志的形式来记录每个写操作,将Redis执行过的所有指令记录下来(读操作不记录) ,只许追加文件但不可以改写文件, redis启动之初会读取该文件重新构建数据,换言之. redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作</p>
<p>==aof保存的文件是appendonly.aof==</p>
<blockquote>
<p>流程</p>
</blockquote>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210831200916268.png" alt="image-20210831200916268"></p>
<ol>
<li>写入缓存：每次执行命令后，进行append操作写入AOF缓存</li>
<li>同步磁盘：AOF 缓冲区根据对应的策略向硬盘进行同步操作。</li>
<li>AOF重写：随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。</li>
<li>重启加载： 当 Redis 重启时，可以加载 AOF 文件进行数据恢复。</li>
</ol>
<h3 id="7-2-1-写入缓存"><a href="#7-2-1-写入缓存" class="headerlink" title="7.2.1 写入缓存"></a>7.2.1 写入缓存</h3><p>每次执行命令都是通过call()，call的时候会把命令写入aof缓存，也就是server.aof_buf</p>
<p>调用链： call() -&gt; propogate() -&gt; feedAppendOnlyFile</p>
<pre><code class="c">void call(client *c, int flags) &#123;
    ...
    propagate(c-&gt;cmd,c-&gt;db-&gt;id,c-&gt;argv,c-&gt;argc,propagate_flags);
&#125;

void propagate(struct redisCommand *cmd, int dbid, robj **argv, int argc,
               int flags)
&#123;
    ...
    if (server.aof_state != AOF_OFF &amp;&amp; flags &amp; PROPAGATE_AOF)
        feedAppendOnlyFile(cmd,dbid,argv,argc);
    ...
&#125;
</code></pre>
<blockquote>
<p>feedAppendOnlyFile()</p>
</blockquote>
<pre><code class="c">void feedAppendOnlyFile(struct redisCommand *cmd, int dictid, robj **argv, int argc) &#123;
    // 把命令解析编码，比较复杂，
    buf = catAppendOnlyGenericCommand(buf,argc,argv);
    // 然后存入server.aof_buf
    server.aof_buf = sdscatlen(server.aof_buf,buf,sdslen(buf));
   // 如果子进程正在重写AOF，就把buf写入server.aof_rewrite_buf_blocks链表
    if (server.child_type == CHILD_TYPE_AOF)
        aofRewriteBufferAppend((unsigned char*)buf,sdslen(buf));
&#125;
</code></pre>
<ol>
<li><p>解析命令</p>
<pre><code class="c\">buf = catAppendOnlyGenericCommand(buf,argc,argv);
</code></pre>
<p>该函数主要工作就是解析命令，把传入的cmd和argv，argc解析成<code>&quot;*3\r\n3\r\nSET\r\n5\r\nmykey\r\n$7\r\nmyvalue\r\n&quot;</code>的样子，存储在buff里</p>
</li>
<li><p>写入缓存</p>
<p><code>server.aof_buf = sdscatlen(server.aof_buf,buf,sdslen(buf));</code></p>
<p>把解析好的命令写入缓存，同步给磁盘</p>
</li>
<li><p>如果子进程正在重写AOF文件，则把解析好的命令写入server.aof_rewrite_buf_blocks链表</p>
<p>server.child_type表示子进程正在进行什么工作，在AOF重写(rewrite)过程中会创建子进程执行重写工作，这个在下面介绍AOF重写的时候会解释这里</p>
</li>
</ol>
<h3 id="7-2-2-同步磁盘"><a href="#7-2-2-同步磁盘" class="headerlink" title="7.2.2 同步磁盘"></a>7.2.2 同步磁盘</h3><p>同步磁盘的操作在函数<strong>flushAppendOnlyFike()</strong></p>
<p><code>flushAppendOnlyFile</code>函数的行为由redis.conf配置中的appendfsync选项的值来决定。该选项有三个可选值，分别是<code>always</code>,<code>everysec</code>和<code>no</code>:</p>
<ul>
<li><strong>always:</strong> Redis在每个事件循环都要将AOF缓冲区中的所有内容写入到AOF文件，并且同不AOF文件，所以always的效率是最差的一个，但从安全性来说也是最安全的，当发生故障停机时，AOF持久化也只会丢失一个事件循环中所产生的命令数据。</li>
<li><strong>everysec:</strong> Redis 在每个事件循环都要将AOF缓冲区中的所有内容写入到AOF</li>
</ul>
<p>如果AOF文件有错位，Redis则无法启动，此时需要修复这个AOF文件，Redis提供的修复工具:<code>redis-check-aof --fix</code></p>
<blockquote>
<p>重写规则</p>
</blockquote>
<p>aof默认就是文件的无限追加，文件会越来越大</p>
<pre><code class="bash">auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb
</code></pre>
<p>如果AOF文件大于64M，太大了，fork一个新的进程会对我们的文件进行重写</p>
<blockquote>
<p>优点</p>
</blockquote>
<ol>
<li>每一次修改都同步，文件的完整性会更加好</li>
<li>每秒同步一次，可能会丢失一秒的数据</li>
<li>从不同步。效率最高</li>
</ol>
<blockquote>
<p>缺点</p>
</blockquote>
<ol>
<li>相对于数据文件来说，aof远远大于rdb，修复的速度也比rdb慢</li>
<li>AOF运行效率也要比RDB慢，所以Redis默认的配置就是RDB</li>
</ol>
<h2 id="7-3-小结"><a href="#7-3-小结" class="headerlink" title="7.3 小结"></a>7.3 小结</h2><ol>
<li>RDB持久化方式能够在指定的时间间隔内对你的数据进行快照存储</li>
<li>AOF 持久化方式记录每次对服务器写的操作。当服务器重启的时候会重新执行这些命令来恢复原始的数据, AOF命令以Redis协议追加保存每次写的操作到文件末尾, Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大。</li>
<li>只做缓存.如果你只希望你的数据在服务器运行的时候存在.你也可以不使用任何持久化</li>
<li>同时开启两种持久化方式<ul>
<li>在这种情况下。当redis重启的时候会优先载入A0F文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。</li>
<li>RDB的数据不实时,同时使用两者时服务器重启也只会找AOF文件,那要不要只使用AOF呢?作者建议不要,因为RDB更适合用于备份数据库( AOF在不断变化不好备份) , 快速重启,而且不会有AOF可能潜在的Bug ,留着作为一个万一的手段。</li>
</ul>
</li>
<li>性能建议<ul>
<li>因为RDB文件只用作后备用途,建议只在Slave.上持久化RDB文件,而且只要15分钟备份一次就够了,只保留save 900 1这条规则。</li>
<li>如果Enable AOF . 好处是在最恶劣情况下也只会丢失不超过两秒数据.启动脚本较简单只load自己的AOF文件就可以了,代价一是带来了持续的IO ，.二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可,应该尽量减少AOF rewrite的频率,AOF重写的基础大小默认值64M太了,可以设到5G以上,默认超过原大小100%大小重写可以改到适当的数值。</li>
<li>如果不Enable AOF , 仅靠Master-Slave Repllcation实现高可用性也可以,能省掉一大笔I0 ,也减少了rewrite时带来的系统波动。代价是如果Master/Slave 同时倒掉,会丢失十几分钟的数据,启动脚本也要比较两个Master/Slave中的RDB文件,载入较新的那个,微博就是这种架构。</li>
</ul>
</li>
</ol>
<h1 id="八、Redis发布订阅"><a href="#八、Redis发布订阅" class="headerlink" title="八、Redis发布订阅"></a>八、Redis发布订阅</h1><p>Redis 发布订阅(pub/sub)是一种==消息通信模式==︰发送者(pub)发送消息，订阅者(sub)接收消息。Redis客户端可以订阅任意数量的频道。<br>订阅/发布消息图:</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210901145241295.png" alt="image-20210901145241295"></p>
<pre><code class="bash">PUBLISH [name] [message] # 发布消息到频道[name]SUBSCRIBE [name ...] # 订阅频道nameUNSUBSCRIBE [name] # 取消订阅频道name
</code></pre>
<blockquote>
<p>原理</p>
</blockquote>
<p>Redis是使用C实现的，通过分析Redis源码里的pubsut.c文件，了解发布和订阅机制的底层实现，籍此加深对Redis的理解。Redis 通过UBLISH、SUBSCRIBE 和PSUBSCRIBE等命令实现发布和订阅功能。<br>通过SUBSCRIBE命令订阅某频道后，redis-server里维护了一个字典，字典的键就是一个个channel，而字典的值则是一个链表，链表中保存了所有订阅这个channel的客户端。SUBSCRIBE命令的关键，就是将客户端添加到给定channel的订阅链表中。通过PUBLlSH命令向订阅者发送消息，redis-server 会使用给定的频道作为键，在它所维护的channel 字典中查找记录了订阅这个频道的所有客户端的链表，遍历这个链表，将消息发布给所有订阅者。<br>Pub/Sub从字面上理解就是发布( Publish )与订阅 (Subscribe )，在Redis中，你可以设定对某一个key值进行消息发布及消息订阅，当一个key值上进行了消息发布后，所有订阅它的客户端都会收到相应的消息。这一功能最明显的用法就是用作实时消息系统，比如普通的即时聊天，群聊等功能。</p>
<p>微信：</p>
<p>通过SUBSCRIBE命令订阅某频道后, |redis-server里维护了一个字典,字典的键就是一一个个 频道! , 而字典的值则是一个链表链表中保存了所有订阅这个channel的客户端。SUBSCRIBE 命令的关键,就是将客户端添加到给定channel的订阅链表中。</p>
<p>Pub/Sub从字面.上理解就是发布( Publish )与订阅( Subscribe) , 在Redis中,你可以设定对某一-个key值进行消息发布及消息订阅，当一个key值上进行了消息发布后,所有订阅它的客户端都会收到相应的消息。</p>
<blockquote>
<p>用途</p>
</blockquote>
<ul>
<li>实时消息系统，比如普通的即时聊天,群聊等功能。</li>
<li>实时聊天 ( 频道当作聊天室，将信息回显给所有人即可 )</li>
<li>订阅，关注系统都是可以的</li>
</ul>
<h1 id="下述部分在《Redis高级》中详解"><a href="#下述部分在《Redis高级》中详解" class="headerlink" title="= = = = 下述部分在《Redis高级》中详解 = = = = ="></a>= = = = 下述部分在《Redis高级》中详解 = = = = =</h1><h1 id="九、Redis主从复制"><a href="#九、Redis主从复制" class="headerlink" title="九、Redis主从复制"></a>九、Redis主从复制</h1><h2 id="9-1-概念"><a href="#9-1-概念" class="headerlink" title="9.1 概念"></a>9.1 概念</h2><p>主从复制,是指将一台Redis服务器的数据,复制到其他的Redis服务器。前者称为主节点(master/leader) ,后者称为从节点(slave/follower) ;数据的复制是单向的,只能由主节点到从节点。Master以写为主, Slave以读为主。<br>默认情况下,每台Redis服务器都是主节点;且一个主节点可以有多个从节点(或没有从节点) ,但一个从节点只能有一个主节点。</p>
<blockquote>
<p><strong>主从复制的主要作用</strong></p>
</blockquote>
<ol>
<li>数据冗余:主从复制实现了数据的热备份,是持久化之外的一种数据冗余方式。</li>
<li>故障恢复:当主节点出现问题时,可以由从节点提供服务,实现快速的故障恢复;实际上是- -种服务的冗余。</li>
<li>负载均衡:在主从复制的基础上,配合读写分离,可以由主节点提供写服务,由从节点提供读服务(即写Redis数据时应用连接主节点,读Redis数据时应用连接从节点) , 分担服务器负载;尤其是在写少读多的场景下,通过多个从节点分担读负载,可以大大提高Redis服务器的并发量。</li>
<li>高可用(高可用—&gt;集群)基石:除了上述作用以外,主从复制还是哨兵和集群能够实施的基础,因此说主从复制是Redis高可用的基础。</li>
</ol>
<blockquote>
<p>一般来说,要将Redis运用于工程项目中,只使用一台Redis是万万不能的,原因如下</p>
</blockquote>
<ol>
<li>从结构上,单个Redis服务器会发生单点故障,并且一台服务器需要处理所有的请求负载,压力较大;</li>
<li>从容量上,单个Redis服务器内存容量有限,就算一台Redis服务 器内存容量为256G ,也不能将所有内存用作Redis存储内存,一般来说,==单台Redis最大使用内存不应该超过20G==。</li>
</ol>
<p>电商网站上的商品，一般都是一次上传，无数次浏览的，也就是多读少写，对于这种场景，通常使用这种架构：</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210901162443186.png" alt="image-20210901162443186"></p>
<p>主从复制，读写分离。80%的情况都是进行读操作，减缓服务器的压力，架构中经常使用，最低配置：一主二从</p>
<p>只要在公司中，主从复制时必须要使用的，在真实的项目中不可能单机使用Redis</p>
<h2 id="9-2-环境配置"><a href="#9-2-环境配置" class="headerlink" title="9.2 环境配置"></a>9.2 环境配置</h2><p>配置主机</p>
<pre><code class="bash">127.0.0.1:6379&gt; info replication # 查看当前库的信息# Replicationrole:master # 角色 masterconnected_slaves:0 # 没有从机master_failover_state:no-failovermaster_replid:2e0dbfc18702474129a88e972702b9ef903eafddmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:0second_repl_offset:-1repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0
</code></pre>
<p>修改从机：</p>
<ol>
<li>端口</li>
<li>pid名字</li>
<li>log文件名字</li>
<li>dump.db的名字</li>
</ol>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210901165123038.png" alt="image-20210901165123038"></p>
<h2 id="9-3-一主二从"><a href="#9-3-一主二从" class="headerlink" title="9.3 一主二从"></a>9.3 一主二从</h2><p>==默认情况下，每台Redis服务器都是主节点== 所以需要修改从机配置</p>
<p>一主(79) 二从(80、81)</p>
<p>从机中配置：</p>
<pre><code class="bash">SLAVEOF [host] [port] # 从机的指定的主机的host和port#信息127.0.0.1:6380&gt; INFO replication# Replicationrole:slavemaster_host:127.0.0.1master_port:6379master_link_status:upmaster_last_io_seconds_ago:7master_sync_in_progress:0slave_repl_offset:14slave_priority:100slave_read_only:1replica_announced:1connected_slaves:0master_failover_state:no-failovermaster_replid:13242a5fc3d3f219f26d6913b64fba0fe25d5572master_replid2:0000000000000000000000000000000000000000master_repl_offset:14second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:14
</code></pre>
<p>真实的从主配置应该在配置文件中配置，这样的话是永久的</p>
<blockquote>
<p>细节</p>
</blockquote>
<ul>
<li>主机可以写，从机不能写，只能读</li>
<li>如果主机断开连接，此时从机依然旧链接到主机(没有配置哨兵的情况下)，但是没有写操作，这个时候如果主机回来了，从机依旧可以读新写入的信息。</li>
<li>如果是使用命令行来配置的主从，此时如果重启了从机，从机就会变成主机。再恢复为从机时，数据就可以立马从主机中获取值</li>
</ul>
<blockquote>
<p>复制原理</p>
</blockquote>
<ol>
<li>Slave启动成功连接到master后会发送一个sync命令</li>
<li>Master接到命令，启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，==master将传送整个数据文件到slave， 并完成次完全同步。==</li>
</ol>
<ul>
<li>全量复制:而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。</li>
<li>增量复制: Master继续将新的所有收集到的修改命令依次传给slave，完成同步</li>
</ul>
<p>但是只要是重新连接master ,一次完全同步 (全量复制)将被自动执行。数据一定可以在从机中看到</p>
<blockquote>
<p>层层链路 (了解)</p>
</blockquote>
<p>上一个master 连接下一个SLAVER</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210901171619088.png" alt="image-20210901171619088"></p>
<p>此时也可以完成主从复制</p>
<p>如果丢失的了主节点，可以使用<code>SLAVEOF no one</code>让自己变成主机，其他的节点就可以<strong>手动</strong>连接到最新的主节点</p>
<h2 id="9-4-哨兵模式"><a href="#9-4-哨兵模式" class="headerlink" title="9.4 哨兵模式"></a><strong>9.4 哨兵模式</strong></h2><p><code>redis-sentinel</code></p>
<blockquote>
<p>概述</p>
</blockquote>
<p>主从切换技术的方法是:当主服务器宕机后，需要手动把一-台从服务器切换为主服务器,这就需要人工干预,费事费力,还会造成一段时间内服务不可用。这不是一种推荐的方式,更多时候,我们优先考虑哨兵模式。Redis从2.8开始正式提供了Sentinel (哨兵)架构来解决这个问题。</p>
<p>能够后台监控主机是否故障,如果故障了根据投票数==自动将从库转换为主库。==</p>
<p>哨兵模式是一种特殊的模式,首先Redis提供了哨兵的命令,哨兵是一个独立的进程,作为进程，它会独立运行。其原理是<strong>哨兵通过发送命令,等待Redis服务器响应,从而监控运行的多个Redis实例</strong>。</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210901173757791.png" alt="image-20210901173757791"></p>
<p>然而一个哨兵进程对Redis服务器进行监控,可能会出现问题,为此,我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控,这样就形成了多哨兵模式。</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210901185816883.png" alt="image-20210901185816883"></p>
<p>假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行failover过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为<strong>主观下线</strong>。</p>
<p>当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行ailover[故障转移]操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为<strong>客观下线</strong>。</p>
<p><font size="5em"><strong>如果主机宕机后，新的主机选举出来后，之前的主机恢复也只能作为新主机的从机</strong></font></p>
<blockquote>
<p>哨兵配置文件</p>
</blockquote>
<pre><code class="bash"># sentinel monitor 被监控的名称 host port 1 
# 数字1表示主机挂了，slave投票看让谁接替成为主机，票数最多的就会成为主机
sentinel monitor myredis 127.0.0.1 6379 1
</code></pre>
<blockquote>
<p>优点</p>
</blockquote>
<ol>
<li>哨兵集群，基于主从复制模式，所有的主从配置优点他都有</li>
<li>主从可以切换，故障可以转移，系统的可用性更好</li>
<li>哨兵模式就是主从模式的升级，手动到自动更加健壮</li>
</ol>
<blockquote>
<p>缺点</p>
</blockquote>
<ol>
<li>Redis不容易在线扩容，集群容量一旦达到上限，在线扩容就十分的麻烦</li>
<li>实现哨兵模式的配置其实是很麻烦的，里面有很多选择</li>
</ol>
<blockquote>
<p>哨兵模式的全部配置</p>
</blockquote>
<pre><code class="bash"># Example sentinel.conf

# 哨兵[sentine]实例运行的端口默认26379
port 26379

#哨兵sentinel的工作目录
dir /tmp

# 哨兵sentinel监控的redis主节点的ip port
# master-name 可以自己命名的主节点名字只能由字A-z、数字0-9、&quot;.-_&quot;组成。
# quorum 配置多少个sentinel哨兵统一认为master主节点失联，那么这时客观上认为主节点失联了
# sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;
sentine] monitor mymaster 127.0.0.1 6379 2


#当在Redis实例中开启了requirepass foobared 授权密码这样所有连接Redis实例的客户端都要提供密码
#设置哨兵sentinel连接主从的密码注意必须为主从设置一样的验证密码
# sentinel auth-pass &lt;master-name&gt; &lt;password&gt;
sentine1 auth-pass mymaster MySUPER--secret-0123passwOrd


#指定多少毫秒之后主节点没有应答哨兵sentinel此时哨兵主观上认为主节点下线   默认30秒
# sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt;
sentinel down-after-mi liseconds mymaster 30000


#这个配置项指定了在发生failover主备切换时最多可以有多少个slave同时对新的master进行同步，
##这个数字越小，完成failover所需的时间就越长，
##但是如果这个数字越大，就意味着越多的slave因为replication而不可用。
##可以通过将这个值设为1来保证每次只有一个slave处于不能处理命令请求的状态。
# sentine1 paralle 7-syncs &lt;master-name&gt; &lt;nums 1 aves &gt;
sentine1 paralle 1-syncs mymaster 1

#故障转移的超时时间failover-timeout 可以用在以下这些方面:
#1.同一个sentinel对同一 个master两次failover之间的问隔时间。
#2.当一个slave从一 个错误的master那里同步數据开始计算时间。直到slave被纠正为向正确的master那里同步数据时。
#3.当想要取消一个正在进行的failover所而要的时间。
#4.当进行failover时，配置所有s1aves指向新的master所需的最大时间。不过，即使过了这个超时，slaves 依然会被正确配置为指向master,但是就不按parallel-syncs所配置的规则来了
#默认三分钟
# sentinel failover-timeout &lt;master-name&gt; &lt;milliseconds&gt;
sentine1 failover-timeout mymaster 180000
</code></pre>
<pre><code class="bash"># SCRIPTS EXECUTION

#配置当某一事件发生时所需要执行的脚本，可以通过脚本来通知管理员，例如当系统运行不正常时发邮件通知相关人员。
#对于脚木的运行结果有以下规则: 
#1.若脚本执行后返回1，那么该脚本稍后将会被再次执行，重复次数目前默认为10
#2.若脚本执行后返回2.或者比2更高的一个返回值，脚本将不会重复执行。
#3.如果脚木在执行过程中由于收到系统中断信号被终止了，则同返回值为1时的行为相同。
#4.一个脚木的最大执行时间为60s，如果超过这个时间，脚本将会被- 个SIGKILL信号终止，之后重新执行。

#通知型脚本:当sentinel有任何警告级别的事件发生时( 比如说redis实例的主观失效和客观失效等等)，将会去调用这个脚本，这时这个脚本应该通过邮件，SMS等方式去通知系统管理员关于系统不正常运行的信息。调用该脚本时，将传给脚本两个参数，一个是事件的类型，一个是事件的描述。如果sentinel.conf配置文件中配置了这个脚木路径，那么必须保证这个脚木存在于这个路径，并且是可执行的，否则sentinel无法正常启动成功。

#通知脚本
#邮件的Shell编程
# sentinel notification-script &lt;master-name&gt; &lt;script-path&gt;
sentinel notification-script mymafter /var/redis/notify.sh 

#客户端重新配置主节点参数脚本
#当一个master由于failover而发生改变时，这个脚木将会被调用，通知相关的客户端关于master地址已经发生改变的信息。
#以下多数将会在调用脚本时传给脚本:
# &lt;master-name&gt; &lt;role&gt; &lt;state&gt; &lt;from-ip&gt; &lt;from-port&gt; &lt;to-ip&gt; &lt;to-port&gt;
#目前&lt;state&gt;总是&quot;failover&quot;,
# &lt;role&gt; 是&quot;leader&quot;或者“observer&quot;中的一个。
#参数from-ip, from-port, to-ip, to-port是用来和旧的master和新的master (即H的sTave)通信的
#这个脚本应该是通用的，能被多次调用，不是针对性的。
# sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt;
sentinel client-reconfig-script mymaster /var/redis/reconfig.sh #一般都是运维来控制
</code></pre>
<h1 id="十、Redis缓存穿透和雪崩-重要"><a href="#十、Redis缓存穿透和雪崩-重要" class="headerlink" title="十、Redis缓存穿透和雪崩(重要)"></a><strong>十、Redis缓存穿透和雪崩</strong>(重要)</h1><p>Redis缓存的使用，极大的提升了应用程序的性能和效率,特别是数据查询方面。但同时，它也带来了一些问题。其中，最要害的问题，就是数据的一致性问题,从严格意义。上讲,这个问题无解。如果对数据的一致性要求很高，那么就不能使用缓存。<br>另外的一些典型问题就是，缓存穿透、缓存雪崩和缓存击穿。目前，业界也都有比较流行的解决方案。</p>
<h2 id="10-1-缓存穿透"><a href="#10-1-缓存穿透" class="headerlink" title="10.1 缓存穿透"></a>10.1 缓存穿透</h2><blockquote>
<p>概念</p>
</blockquote>
<p>用户想要查询一个数据,发现redis内存数据库没有,也就是缓存没有命中,于是向持久层数据库查询。发<br>现也没有,于是本次查询失败。当用户很多的时候,缓存都没有命中，于是都去请求了持久层数据库。这会给持久层数据库造成很大的压力,这时候就相当于出现了缓存穿透。</p>
<blockquote>
<p>解决方案</p>
</blockquote>
<p>方法一：使用<strong>布隆过滤器</strong></p>
<p>布隆过滤器是一种数据结构,对所有可能查询的参数以Hash形式存储,在控制层先进行校验,不符合则丢弃,从而避免了对底层存储系统的查询压力;</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210901215146437.png" alt="image-20210901215146437"></p>
<p>方法二：<strong>缓存空对象</strong></p>
<p>当存储层不命中后,即使返回的空对象也将其缓存起来,同时会设置一个过期时间 ,之后再访问这个数据将会从缓存中获取，保护了后端数据源;</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210901222252770.png" alt="image-20210901222252770"></p>
<p>但是这种方法会存在两个问题:<br>1、如果空值能够被缓存起来,这就意味着缓存需要更多的空间存储更多的键,因为这当中可能会有很多的空值的键;<br>2、即使对空值设置了过期时间,还是会存在缓存层和存储层的数据会有一-段时间窗口的不一-致 ,这对于需要保持一致性的业务会有影响。</p>
<h2 id="10-2-缓存击穿"><a href="#10-2-缓存击穿" class="headerlink" title="10.2 缓存击穿"></a>10.2 缓存击穿</h2><p>量太大，缓存过期</p>
<blockquote>
<p>概述</p>
</blockquote>
<p>这里需要注意和缓存击穿的区别,缓存击穿,是指一个key非常热点;在不停的扛着大并发,大并发集中对这一个点进行访问,当这个key在失效的瞬间,持续的大并发就穿破缓存，直接请求数据库,就像在一个屏障上凿开了一个洞。</p>
<p>当某个key在过期的瞬间,有大量的请求并发访问这类数据一般是热点数据,由于缓存过期 ,会同时访问数据库来查询最新数据，并且回写缓存,会导使数据库瞬间压力过大。</p>
<blockquote>
<p>解决方案</p>
</blockquote>
<p><strong>设置热点数据永不过期</strong></p>
<p>从缓存层面来看，没有设置过期时间，所以不会出现热点key过期后产生的问题。</p>
<p><strong>加互斥锁</strong></p>
<p>分布式锁：使用分布式锁，保证对于每个key同时只有一个线程去查询后端服务，其他线程没有获得分布式锁的权限，因此只需要等待即可。这种方式将高并发的压力转移到了分布式锁，因此分布式锁的考验很大</p>
<h2 id="10-3-缓存雪崩"><a href="#10-3-缓存雪崩" class="headerlink" title="10.3 缓存雪崩"></a>10.3 缓存雪崩</h2><blockquote>
<p>概念</p>
</blockquote>
<p>缓存雪崩，是指在某一个时间段，缓存集中过期失效，Redis宕机</p>
<p>产生雪崩的原因之一 ,比如在写本文的时候，马.上就要到双十二零点,很快就会迎来一波抢购 ,这波商品时间比较集中的放入了缓存,假设缓存一个小时。那么到了凌晨一点钟的时候 ,这批商品的缓存就都过期了。而对这批商品的访问查询,都落到了数据库上,对于数据库而言,就会产生周期性的压力波峰。于是所有的请求都会达到存储层,存储层的调用量会暴增,造成存储层也会挂掉的情况。</p>
<p><img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20210901223354610.png" alt="image-20210901223354610"></p>
<p>其实集中过期,倒不是非常致命,比较致命的缓存雪崩,是缓存服务器某个节点宕机或断网。因为自然形成的缓存雪崩,一定是在某个时间段集中创建缓存,这个时候,数据库也是可以顶住压力的。无非就是对数据库产生周期性的压力而已。而缓存服务节点的宕机，对数据库服务器造成的压力是不可预知的,很有可能瞬间就把数据库压垮。</p>
<blockquote>
<p>解决方案</p>
</blockquote>
<p><strong>Redis的高可用</strong></p>
<p>这个思想的含义是,既然redis有可能挂掉,那我多增设几台redis ,这样一台挂掉之后其他的还可以继续工作,其实就是搭建的集群。</p>
<p>如 <em>双十一：停掉一些服务(保证主要的服务可用)</em></p>
<p><strong>限流降级</strong></p>
<p>这个解决方案的思想是,在缓存失效后,通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存,其他线程等待。</p>
<p><strong>数据预热</strong></p>
<p>数据加热的含义就是在正式部署之前,我先把可能的数据先预先访问-遍,这样部分可能大量访问的数据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的key ,设置不同的过期时间,让缓存失效的时间点尽量均匀。</p>

            
        </div>
    </div>

    <div class="post-tags">
        
        <span class="icon">
            <a-icon type="tags" theme="filled" />
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/Java" style=color:#ff7d73>
                Java
            </a>
        </span>
        
    </div>

    <a href="/2020/06/01/Redis/ " class="go-post">
        阅读全文
    </a>
</div>


             
<div class="page-current">

    <div class="prev">
        
    </div>

    <div class="page-index">

        

        <span class="current">
            1
        </span>

        
        <span>
            <a href="/page/2/">
                <span class="page-num">
                    2
                </span>
            </a>
            

            

        </span>
        

    </div>

    <div class="next">
        
        <a href="/page/2/ ">
            <span class="page-num">
                <a-icon type="caret-right" theme="filled" />
            </span>
        </a>
        
    </div>

</div>

        </div>
    </div>
    
    <div id="home-card">
        <a-affix :offset-top="card_top">
    <a-card class="card-style" style="width: 300px">
        <div class="avatar">
            <img src="images/avatar.png " alt="头像">
        </div>
        <div class="name">
            John Doe
        </div>
        <div class="descriptions">
            
            <div class="description">
                正しさなんてもの
            </div>
            
            <div class="description">
                人のモノサシによって変わる
            </div>
            
        </div>
        <div class="icon-links">
            
            <span class="icon-link">
                <a target="_blank" rel="noopener" href="https://github.com/korilin">

                    
                    <a-icon type="github"
                        theme="filled" />
                    
                </a>
            </span>
            
            <span class="icon-link">
                <a target="_blank" rel="noopener" href="https://twitter.com/korilin_dev">

                    
                    <a-icon type="twitter"
                        theme="" />
                    
                </a>
            </span>
            
        </div>
        <div class="friend-links">
            
            <div class="friend-link">
                <a target="_blank" rel="noopener" href="https://en.korilin.com">
                    英文技术博客
                </a>
            </div>
            
            <div class="friend-link">
                <a target="_blank" rel="noopener" href="https://jp.korilin.com">
                    日语记录博客
                </a>
            </div>
            
        </div>
    </a-card>
</a-affix>
    </div>
    
</div>
                     
<footer id="footer">
    <div class="footer-wrap">
        <div>
            © 2018 - 2022 Hexo
            <span class="footer-icon">
                <a-icon type="flag" theme="filled" /></span>
            @John Doe
        </div>
        <div></div>
        <div>Based on the <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo Engine</a> & <a
                target="_blank" rel="noopener" href="https://github.com/korilin/hexo-theme-particle">Particle Theme</a></div>
        
    </div>

</footer>

<script src="/js/highlight.min.js"></script>
<script src="/js/particle.js"></script>
                </div>
            </div>
        </transition>
    </div>

    <script>
    new Vue({
        el: "#layout",
        data: {
            show_page: false,
            onload_menu: false,
            menu_show: false,
            card_top: 100
        },
        created: function () {
            var that = this
            window.onload = function () {
                that.show_page = true
                document.getElementById("loadcontent").style.opacity = 0
                setTimeout(function () {
                    document.getElementById("loadleft").style.width = 0
                    document.getElementById("loadright").style.width = 0
                }, 300)
                setTimeout(function () {
                    document.getElementById("loading").style = "display:none"
                }, 600)
            }
        },
        mounted: function () {
            var that = this
            window.addEventListener('scroll', function (e) {
                that.menu_show = false
            })
        },
        methods: {
            home_click: function () {
                window.scrollTo({
                    top: window.innerHeight - 80,
                    behavior: "smooth",
                });
            }
        }
    })
</script>

</body>

</html>